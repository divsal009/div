{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Brats.ipynb",
      "provenance": [],
      "mount_file_id": "1FefRRcYRNt6ZKGzSlB_EcLhn2JgScVqg",
      "authorship_tag": "ABX9TyPwPNndNegvwlZdmsOgomty",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divsal009/div/blob/master/Brats2013_10K.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih5-UKw_G99o"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import random as r\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv1sEn9EHFWc"
      },
      "source": [
        "import glob\n",
        "def create_data(src, mask, label=False, resize=(128,128,128)):\n",
        "    files = glob.glob(src + mask, recursive=True)\n",
        "    imgs = []\n",
        "    for file in files:\n",
        "        img = io.imread(file, plugin='simpleitk')\n",
        "        if label:\n",
        "            img[img == 4] = 1\n",
        "            img[img != 1] = 0\n",
        "            img = img.astype('float32')\n",
        "        else:\n",
        "            img = (img-img.mean()) / img.std()\n",
        "        img = trans.resize(img, resize, mode='constant')\n",
        "        imgs.append(img)\n",
        "    name = 'y' if label else 'x'\n",
        "    np.save(name, np.array(imgs)[..., np.newaxis].astype('float32'))\n",
        "    print('Saved', len(files), 'to', name)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdvg4MiwHLhU"
      },
      "source": [
        "from keras.models import Input, Model\n",
        "from keras.layers import Conv2D, Concatenate, MaxPooling2D, Reshape\n",
        "from keras.layers import UpSampling2D, Activation, Permute\n",
        "\n",
        "def level_block(m, dim, depth, factor, acti):\n",
        "    if depth > 0:\n",
        "        n = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
        "        n = Conv2D(dim, 3, activation=acti, padding='same')(n)\n",
        "        m = MaxPooling2D()(n)\n",
        "        m = level_block(m, int(factor*dim), depth-1, factor, acti)\n",
        "        m = UpSampling2D()(m)\n",
        "        m = Conv2D(dim, 2, activation=acti, padding='same')(m)\n",
        "        m = Concatenate(axis=3)([n, m])\n",
        "    m = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
        "    return Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
        "\n",
        "def UNet(img_shape, n_out=1, dim=64, depth=4, factor=2, acti='elu', flatten=False):\n",
        "    i = Input(shape=img_shape)\n",
        "    o = level_block(i, dim, depth, factor, acti)\n",
        "    o = Conv2D(n_out, (1, 1))(o)\n",
        "    if flatten:\n",
        "        o = Reshape(n_out, img_shape[0] * img_shape[1])(o)\n",
        "        o = Permute((2, 1))(o)\n",
        "    o = Activation('sigmoid')(o)\n",
        "    return Model(inputs=i, outputs=o)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnUT7n4ZHPtl"
      },
      "source": [
        "from keras.models import Input, Model\n",
        "from keras.layers import Conv3D, Concatenate, MaxPooling3D, Reshape\n",
        "from keras.layers import UpSampling3D, Activation, Permute\n",
        "\n",
        "def level_block_3d(m, dim, depth, factor, acti):\n",
        "    if depth > 0:\n",
        "        n = Conv3D(dim, 3, activation=acti, padding='same')(m)\n",
        "        m = MaxPooling3D()(n)\n",
        "        m = level_block_3d(m, int(factor*dim), depth-1, factor, acti)\n",
        "        m = UpSampling3D()(m)\n",
        "        m = Concatenate(axis=4)([n, m])\n",
        "    return Conv3D(dim, 3, activation=acti, padding='same')(m)\n",
        "\n",
        "def UNet_3D(img_shape, n_out=1, dim=64, depth=4, factor=2, acti='elu'):\n",
        "    i = Input(shape=img_shape)\n",
        "    o = level_block_3d(i, dim, depth, factor, acti)\n",
        "    o = Conv3D(n_out, 1, activation='sigmoid')(o)\n",
        "    return Model(inputs=i, outputs=o)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr7cHIGNHUxR"
      },
      "source": [
        "import keras.backend as K\n",
        "def f1_score(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1.) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.)\n",
        "\n",
        "def f1_loss(y_true, y_pred):\n",
        "    return -f1_score(y_true, y_pred)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NonSFPmZOvmB",
        "outputId": "269f00c2-ff41-457a-9fd5-8e1279519166"
      },
      "source": [
        "pip install simpleitk"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: simpleitk in /usr/local/lib/python3.7/dist-packages (2.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnjE8YHIHYbd",
        "outputId": "4fcc62ca-6c6b-42f8-a1da-35fb57f8cf6e"
      },
      "source": [
        "create_data('/content/drive/MyDrive/HGG/', '**/*T1c*.mha', label=False, resize=(32,32,32))\n",
        "create_data('/content/drive/MyDrive/HGG/', '**/*OT*.mha', label=True, resize=(32,32,32))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved 220 to x\n",
            "Saved 220 to y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6m9qMbEI6VF",
        "outputId": "75b710aa-5d57-4e79-ac31-110a32c5a397"
      },
      "source": [
        "x = np.load('x.npy')\n",
        "print('x: ', x.shape)\n",
        "y = np.load('y.npy')\n",
        "print('y:', y.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x:  (220, 32, 32, 32, 1)\n",
            "y: (220, 32, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "Rvz089fxI8Fv",
        "outputId": "5c494c24-7ce3-4322-e6c1-93f7636dbeda"
      },
      "source": [
        "\n",
        "import random as r\n",
        "i = int(r.random() * x.shape[0])\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(121)\n",
        "plt.imshow(x[i, int(x.shape[1]/2), :, :, 0])\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0796c39e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Hv_SYB5VPXov",
        "outputId": "4a21bf6e-552d-4029-a5c9-222ca244f57e"
      },
      "source": [
        "plt.subplot(122)\n",
        "plt.imshow(y[i, int(y.shape[1]/2), :, :, 0])\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPSOT1WYJC77"
      },
      "source": [
        "model = UNet_3D(x.shape[1:], dim=16, factor=1)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opvxKZZMVv-j"
      },
      "source": [
        "model.load_weights('/content/weights.h5')\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D9zagwjXHq9"
      },
      "source": [
        "model.compile(optimizer=Adam(lr=0.000001), loss=f1_loss)\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17kgi_pSYU6s",
        "outputId": "d583536f-defd-4c8b-b994-fc19c8503056"
      },
      "source": [
        "model.fit(x, y, validation_split=0.2, epochs=10000, batch_size=8)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 7501/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6657 - val_loss: -0.5168\n",
            "Epoch 7502/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6731 - val_loss: -0.5167\n",
            "Epoch 7503/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6694 - val_loss: -0.5169\n",
            "Epoch 7504/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5168\n",
            "Epoch 7505/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6708 - val_loss: -0.5164\n",
            "Epoch 7506/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6592 - val_loss: -0.5175\n",
            "Epoch 7507/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6638 - val_loss: -0.5161\n",
            "Epoch 7508/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6594 - val_loss: -0.5180\n",
            "Epoch 7509/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6719 - val_loss: -0.5175\n",
            "Epoch 7510/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6720 - val_loss: -0.5170\n",
            "Epoch 7511/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6634 - val_loss: -0.5173\n",
            "Epoch 7512/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6674 - val_loss: -0.5169\n",
            "Epoch 7513/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6721 - val_loss: -0.5170\n",
            "Epoch 7514/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6656 - val_loss: -0.5171\n",
            "Epoch 7515/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6683 - val_loss: -0.5174\n",
            "Epoch 7516/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6679 - val_loss: -0.5169\n",
            "Epoch 7517/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6731 - val_loss: -0.5171\n",
            "Epoch 7518/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6578 - val_loss: -0.5184\n",
            "Epoch 7519/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6671 - val_loss: -0.5174\n",
            "Epoch 7520/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6663 - val_loss: -0.5174\n",
            "Epoch 7521/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6713 - val_loss: -0.5166\n",
            "Epoch 7522/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6542 - val_loss: -0.5176\n",
            "Epoch 7523/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6530 - val_loss: -0.5169\n",
            "Epoch 7524/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5173\n",
            "Epoch 7525/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6595 - val_loss: -0.5170\n",
            "Epoch 7526/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6672 - val_loss: -0.5168\n",
            "Epoch 7527/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6621 - val_loss: -0.5169\n",
            "Epoch 7528/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6636 - val_loss: -0.5175\n",
            "Epoch 7529/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6653 - val_loss: -0.5171\n",
            "Epoch 7530/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6656 - val_loss: -0.5173\n",
            "Epoch 7531/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6690 - val_loss: -0.5172\n",
            "Epoch 7532/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6731 - val_loss: -0.5164\n",
            "Epoch 7533/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6602 - val_loss: -0.5169\n",
            "Epoch 7534/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6680 - val_loss: -0.5165\n",
            "Epoch 7535/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6588 - val_loss: -0.5179\n",
            "Epoch 7536/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6698 - val_loss: -0.5165\n",
            "Epoch 7537/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6666 - val_loss: -0.5179\n",
            "Epoch 7538/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6655 - val_loss: -0.5177\n",
            "Epoch 7539/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6667 - val_loss: -0.5175\n",
            "Epoch 7540/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6739 - val_loss: -0.5172\n",
            "Epoch 7541/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6711 - val_loss: -0.5163\n",
            "Epoch 7542/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6589 - val_loss: -0.5175\n",
            "Epoch 7543/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6687 - val_loss: -0.5161\n",
            "Epoch 7544/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6682 - val_loss: -0.5176\n",
            "Epoch 7545/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6645 - val_loss: -0.5173\n",
            "Epoch 7546/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6767 - val_loss: -0.5167\n",
            "Epoch 7547/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6713 - val_loss: -0.5176\n",
            "Epoch 7548/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6697 - val_loss: -0.5168\n",
            "Epoch 7549/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6669 - val_loss: -0.5171\n",
            "Epoch 7550/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6616 - val_loss: -0.5167\n",
            "Epoch 7551/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6715 - val_loss: -0.5167\n",
            "Epoch 7552/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6660 - val_loss: -0.5166\n",
            "Epoch 7553/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6697 - val_loss: -0.5174\n",
            "Epoch 7554/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6692 - val_loss: -0.5167\n",
            "Epoch 7555/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6538 - val_loss: -0.5171\n",
            "Epoch 7556/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6705 - val_loss: -0.5164\n",
            "Epoch 7557/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6703 - val_loss: -0.5172\n",
            "Epoch 7558/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6585 - val_loss: -0.5171\n",
            "Epoch 7559/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6664 - val_loss: -0.5170\n",
            "Epoch 7560/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6747 - val_loss: -0.5164\n",
            "Epoch 7561/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6669 - val_loss: -0.5175\n",
            "Epoch 7562/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6622 - val_loss: -0.5165\n",
            "Epoch 7563/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5176\n",
            "Epoch 7564/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6715 - val_loss: -0.5169\n",
            "Epoch 7565/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6622 - val_loss: -0.5176\n",
            "Epoch 7566/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6606 - val_loss: -0.5173\n",
            "Epoch 7567/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6647 - val_loss: -0.5172\n",
            "Epoch 7568/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6717 - val_loss: -0.5162\n",
            "Epoch 7569/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6697 - val_loss: -0.5168\n",
            "Epoch 7570/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6729 - val_loss: -0.5170\n",
            "Epoch 7571/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6686 - val_loss: -0.5169\n",
            "Epoch 7572/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6752 - val_loss: -0.5170\n",
            "Epoch 7573/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6578 - val_loss: -0.5177\n",
            "Epoch 7574/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6666 - val_loss: -0.5161\n",
            "Epoch 7575/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6623 - val_loss: -0.5173\n",
            "Epoch 7576/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6601 - val_loss: -0.5170\n",
            "Epoch 7577/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6599 - val_loss: -0.5170\n",
            "Epoch 7578/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6574 - val_loss: -0.5177\n",
            "Epoch 7579/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6633 - val_loss: -0.5173\n",
            "Epoch 7580/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6705 - val_loss: -0.5167\n",
            "Epoch 7581/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6725 - val_loss: -0.5168\n",
            "Epoch 7582/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6529 - val_loss: -0.5169\n",
            "Epoch 7583/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6654 - val_loss: -0.5173\n",
            "Epoch 7584/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6616 - val_loss: -0.5165\n",
            "Epoch 7585/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6718 - val_loss: -0.5173\n",
            "Epoch 7586/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6675 - val_loss: -0.5168\n",
            "Epoch 7587/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6665 - val_loss: -0.5172\n",
            "Epoch 7588/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6661 - val_loss: -0.5172\n",
            "Epoch 7589/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6669 - val_loss: -0.5167\n",
            "Epoch 7590/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6661 - val_loss: -0.5175\n",
            "Epoch 7591/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6649 - val_loss: -0.5168\n",
            "Epoch 7592/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6696 - val_loss: -0.5167\n",
            "Epoch 7593/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5171\n",
            "Epoch 7594/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6734 - val_loss: -0.5173\n",
            "Epoch 7595/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6570 - val_loss: -0.5172\n",
            "Epoch 7596/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6633 - val_loss: -0.5180\n",
            "Epoch 7597/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6663 - val_loss: -0.5171\n",
            "Epoch 7598/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6647 - val_loss: -0.5174\n",
            "Epoch 7599/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6679 - val_loss: -0.5177\n",
            "Epoch 7600/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6649 - val_loss: -0.5169\n",
            "Epoch 7601/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6618 - val_loss: -0.5176\n",
            "Epoch 7602/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6526 - val_loss: -0.5179\n",
            "Epoch 7603/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6631 - val_loss: -0.5176\n",
            "Epoch 7604/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6738 - val_loss: -0.5167\n",
            "Epoch 7605/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6650 - val_loss: -0.5169\n",
            "Epoch 7606/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6640 - val_loss: -0.5165\n",
            "Epoch 7607/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6533 - val_loss: -0.5173\n",
            "Epoch 7608/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6568 - val_loss: -0.5168\n",
            "Epoch 7609/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6640 - val_loss: -0.5170\n",
            "Epoch 7610/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6750 - val_loss: -0.5172\n",
            "Epoch 7611/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6733 - val_loss: -0.5170\n",
            "Epoch 7612/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5168\n",
            "Epoch 7613/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6730 - val_loss: -0.5173\n",
            "Epoch 7614/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6687 - val_loss: -0.5168\n",
            "Epoch 7615/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6639 - val_loss: -0.5174\n",
            "Epoch 7616/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6691 - val_loss: -0.5175\n",
            "Epoch 7617/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6667 - val_loss: -0.5166\n",
            "Epoch 7618/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6639 - val_loss: -0.5172\n",
            "Epoch 7619/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6632 - val_loss: -0.5167\n",
            "Epoch 7620/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6733 - val_loss: -0.5172\n",
            "Epoch 7621/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6706 - val_loss: -0.5166\n",
            "Epoch 7622/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6640 - val_loss: -0.5180\n",
            "Epoch 7623/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6683 - val_loss: -0.5161\n",
            "Epoch 7624/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6705 - val_loss: -0.5174\n",
            "Epoch 7625/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6679 - val_loss: -0.5172\n",
            "Epoch 7626/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6604 - val_loss: -0.5179\n",
            "Epoch 7627/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6659 - val_loss: -0.5168\n",
            "Epoch 7628/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6686 - val_loss: -0.5165\n",
            "Epoch 7629/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6710 - val_loss: -0.5171\n",
            "Epoch 7630/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6627 - val_loss: -0.5186\n",
            "Epoch 7631/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6657 - val_loss: -0.5171\n",
            "Epoch 7632/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6723 - val_loss: -0.5170\n",
            "Epoch 7633/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6610 - val_loss: -0.5170\n",
            "Epoch 7634/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6659 - val_loss: -0.5170\n",
            "Epoch 7635/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6655 - val_loss: -0.5174\n",
            "Epoch 7636/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6742 - val_loss: -0.5169\n",
            "Epoch 7637/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6602 - val_loss: -0.5176\n",
            "Epoch 7638/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6678 - val_loss: -0.5165\n",
            "Epoch 7639/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6614 - val_loss: -0.5178\n",
            "Epoch 7640/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6598 - val_loss: -0.5181\n",
            "Epoch 7641/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6653 - val_loss: -0.5168\n",
            "Epoch 7642/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6663 - val_loss: -0.5170\n",
            "Epoch 7643/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6611 - val_loss: -0.5176\n",
            "Epoch 7644/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6694 - val_loss: -0.5172\n",
            "Epoch 7645/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6636 - val_loss: -0.5180\n",
            "Epoch 7646/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6684 - val_loss: -0.5180\n",
            "Epoch 7647/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6613 - val_loss: -0.5178\n",
            "Epoch 7648/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6630 - val_loss: -0.5170\n",
            "Epoch 7649/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6671 - val_loss: -0.5176\n",
            "Epoch 7650/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6663 - val_loss: -0.5171\n",
            "Epoch 7651/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6673 - val_loss: -0.5169\n",
            "Epoch 7652/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6609 - val_loss: -0.5173\n",
            "Epoch 7653/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6735 - val_loss: -0.5167\n",
            "Epoch 7654/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6654 - val_loss: -0.5177\n",
            "Epoch 7655/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6628 - val_loss: -0.5165\n",
            "Epoch 7656/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6711 - val_loss: -0.5168\n",
            "Epoch 7657/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6615 - val_loss: -0.5174\n",
            "Epoch 7658/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6704 - val_loss: -0.5165\n",
            "Epoch 7659/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6685 - val_loss: -0.5177\n",
            "Epoch 7660/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6706 - val_loss: -0.5168\n",
            "Epoch 7661/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6662 - val_loss: -0.5167\n",
            "Epoch 7662/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6658 - val_loss: -0.5179\n",
            "Epoch 7663/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6561 - val_loss: -0.5178\n",
            "Epoch 7664/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6624 - val_loss: -0.5181\n",
            "Epoch 7665/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6685 - val_loss: -0.5176\n",
            "Epoch 7666/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6685 - val_loss: -0.5180\n",
            "Epoch 7667/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6791 - val_loss: -0.5166\n",
            "Epoch 7668/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6617 - val_loss: -0.5178\n",
            "Epoch 7669/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6727 - val_loss: -0.5168\n",
            "Epoch 7670/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6762 - val_loss: -0.5172\n",
            "Epoch 7671/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6763 - val_loss: -0.5172\n",
            "Epoch 7672/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6498 - val_loss: -0.5179\n",
            "Epoch 7673/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6689 - val_loss: -0.5168\n",
            "Epoch 7674/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6697 - val_loss: -0.5175\n",
            "Epoch 7675/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6532 - val_loss: -0.5182\n",
            "Epoch 7676/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5167\n",
            "Epoch 7677/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6702 - val_loss: -0.5176\n",
            "Epoch 7678/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6754 - val_loss: -0.5169\n",
            "Epoch 7679/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6675 - val_loss: -0.5175\n",
            "Epoch 7680/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6691 - val_loss: -0.5183\n",
            "Epoch 7681/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6690 - val_loss: -0.5175\n",
            "Epoch 7682/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6691 - val_loss: -0.5174\n",
            "Epoch 7683/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6667 - val_loss: -0.5166\n",
            "Epoch 7684/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6697 - val_loss: -0.5173\n",
            "Epoch 7685/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6700 - val_loss: -0.5176\n",
            "Epoch 7686/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5172\n",
            "Epoch 7687/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6537 - val_loss: -0.5187\n",
            "Epoch 7688/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6744 - val_loss: -0.5164\n",
            "Epoch 7689/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6712 - val_loss: -0.5176\n",
            "Epoch 7690/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6665 - val_loss: -0.5169\n",
            "Epoch 7691/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6639 - val_loss: -0.5179\n",
            "Epoch 7692/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6556 - val_loss: -0.5170\n",
            "Epoch 7693/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6643 - val_loss: -0.5171\n",
            "Epoch 7694/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5172\n",
            "Epoch 7695/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6578 - val_loss: -0.5176\n",
            "Epoch 7696/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6638 - val_loss: -0.5179\n",
            "Epoch 7697/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6606 - val_loss: -0.5169\n",
            "Epoch 7698/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6605 - val_loss: -0.5174\n",
            "Epoch 7699/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6707 - val_loss: -0.5162\n",
            "Epoch 7700/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6639 - val_loss: -0.5171\n",
            "Epoch 7701/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6679 - val_loss: -0.5174\n",
            "Epoch 7702/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6600 - val_loss: -0.5172\n",
            "Epoch 7703/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5174\n",
            "Epoch 7704/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6537 - val_loss: -0.5183\n",
            "Epoch 7705/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6692 - val_loss: -0.5170\n",
            "Epoch 7706/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6669 - val_loss: -0.5175\n",
            "Epoch 7707/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6618 - val_loss: -0.5176\n",
            "Epoch 7708/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6718 - val_loss: -0.5162\n",
            "Epoch 7709/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6661 - val_loss: -0.5175\n",
            "Epoch 7710/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6623 - val_loss: -0.5161\n",
            "Epoch 7711/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6660 - val_loss: -0.5173\n",
            "Epoch 7712/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6627 - val_loss: -0.5172\n",
            "Epoch 7713/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6599 - val_loss: -0.5180\n",
            "Epoch 7714/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6664 - val_loss: -0.5178\n",
            "Epoch 7715/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6650 - val_loss: -0.5173\n",
            "Epoch 7716/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6662 - val_loss: -0.5180\n",
            "Epoch 7717/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6598 - val_loss: -0.5175\n",
            "Epoch 7718/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6606 - val_loss: -0.5177\n",
            "Epoch 7719/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6623 - val_loss: -0.5173\n",
            "Epoch 7720/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6671 - val_loss: -0.5169\n",
            "Epoch 7721/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6591 - val_loss: -0.5168\n",
            "Epoch 7722/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6734 - val_loss: -0.5176\n",
            "Epoch 7723/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6675 - val_loss: -0.5168\n",
            "Epoch 7724/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6764 - val_loss: -0.5174\n",
            "Epoch 7725/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6611 - val_loss: -0.5177\n",
            "Epoch 7726/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6732 - val_loss: -0.5174\n",
            "Epoch 7727/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6646 - val_loss: -0.5173\n",
            "Epoch 7728/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6668 - val_loss: -0.5178\n",
            "Epoch 7729/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6642 - val_loss: -0.5169\n",
            "Epoch 7730/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6679 - val_loss: -0.5168\n",
            "Epoch 7731/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6664 - val_loss: -0.5174\n",
            "Epoch 7732/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6740 - val_loss: -0.5167\n",
            "Epoch 7733/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6707 - val_loss: -0.5176\n",
            "Epoch 7734/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6697 - val_loss: -0.5171\n",
            "Epoch 7735/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6658 - val_loss: -0.5168\n",
            "Epoch 7736/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6681 - val_loss: -0.5173\n",
            "Epoch 7737/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6599 - val_loss: -0.5180\n",
            "Epoch 7738/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6705 - val_loss: -0.5177\n",
            "Epoch 7739/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6717 - val_loss: -0.5174\n",
            "Epoch 7740/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6656 - val_loss: -0.5181\n",
            "Epoch 7741/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6770 - val_loss: -0.5168\n",
            "Epoch 7742/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6686 - val_loss: -0.5178\n",
            "Epoch 7743/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6690 - val_loss: -0.5166\n",
            "Epoch 7744/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5175\n",
            "Epoch 7745/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6705 - val_loss: -0.5173\n",
            "Epoch 7746/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6666 - val_loss: -0.5176\n",
            "Epoch 7747/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6661 - val_loss: -0.5175\n",
            "Epoch 7748/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6722 - val_loss: -0.5168\n",
            "Epoch 7749/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6644 - val_loss: -0.5179\n",
            "Epoch 7750/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6634 - val_loss: -0.5170\n",
            "Epoch 7751/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6699 - val_loss: -0.5178\n",
            "Epoch 7752/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6682 - val_loss: -0.5171\n",
            "Epoch 7753/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6651 - val_loss: -0.5171\n",
            "Epoch 7754/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6692 - val_loss: -0.5170\n",
            "Epoch 7755/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6690 - val_loss: -0.5174\n",
            "Epoch 7756/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6681 - val_loss: -0.5177\n",
            "Epoch 7757/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6543 - val_loss: -0.5183\n",
            "Epoch 7758/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6687 - val_loss: -0.5165\n",
            "Epoch 7759/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6635 - val_loss: -0.5173\n",
            "Epoch 7760/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6713 - val_loss: -0.5170\n",
            "Epoch 7761/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6641 - val_loss: -0.5176\n",
            "Epoch 7762/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6638 - val_loss: -0.5173\n",
            "Epoch 7763/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6640 - val_loss: -0.5179\n",
            "Epoch 7764/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6689 - val_loss: -0.5169\n",
            "Epoch 7765/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6712 - val_loss: -0.5169\n",
            "Epoch 7766/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6732 - val_loss: -0.5170\n",
            "Epoch 7767/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6600 - val_loss: -0.5172\n",
            "Epoch 7768/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6686 - val_loss: -0.5172\n",
            "Epoch 7769/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6616 - val_loss: -0.5176\n",
            "Epoch 7770/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6727 - val_loss: -0.5164\n",
            "Epoch 7771/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6742 - val_loss: -0.5174\n",
            "Epoch 7772/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6726 - val_loss: -0.5174\n",
            "Epoch 7773/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6709 - val_loss: -0.5178\n",
            "Epoch 7774/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6753 - val_loss: -0.5174\n",
            "Epoch 7775/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6645 - val_loss: -0.5178\n",
            "Epoch 7776/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6629 - val_loss: -0.5180\n",
            "Epoch 7777/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6706 - val_loss: -0.5170\n",
            "Epoch 7778/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6725 - val_loss: -0.5173\n",
            "Epoch 7779/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6686 - val_loss: -0.5177\n",
            "Epoch 7780/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6671 - val_loss: -0.5171\n",
            "Epoch 7781/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6729 - val_loss: -0.5167\n",
            "Epoch 7782/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6695 - val_loss: -0.5168\n",
            "Epoch 7783/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5169\n",
            "Epoch 7784/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6685 - val_loss: -0.5170\n",
            "Epoch 7785/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6673 - val_loss: -0.5179\n",
            "Epoch 7786/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6623 - val_loss: -0.5175\n",
            "Epoch 7787/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6573 - val_loss: -0.5186\n",
            "Epoch 7788/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6535 - val_loss: -0.5173\n",
            "Epoch 7789/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6617 - val_loss: -0.5164\n",
            "Epoch 7790/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6715 - val_loss: -0.5178\n",
            "Epoch 7791/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6750 - val_loss: -0.5169\n",
            "Epoch 7792/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6734 - val_loss: -0.5169\n",
            "Epoch 7793/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6695 - val_loss: -0.5176\n",
            "Epoch 7794/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6616 - val_loss: -0.5168\n",
            "Epoch 7795/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6697 - val_loss: -0.5169\n",
            "Epoch 7796/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6680 - val_loss: -0.5173\n",
            "Epoch 7797/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6526 - val_loss: -0.5178\n",
            "Epoch 7798/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6677 - val_loss: -0.5172\n",
            "Epoch 7799/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6711 - val_loss: -0.5170\n",
            "Epoch 7800/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6657 - val_loss: -0.5178\n",
            "Epoch 7801/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6674 - val_loss: -0.5161\n",
            "Epoch 7802/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6639 - val_loss: -0.5170\n",
            "Epoch 7803/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6637 - val_loss: -0.5170\n",
            "Epoch 7804/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6678 - val_loss: -0.5169\n",
            "Epoch 7805/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6690 - val_loss: -0.5167\n",
            "Epoch 7806/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6740 - val_loss: -0.5172\n",
            "Epoch 7807/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6594 - val_loss: -0.5172\n",
            "Epoch 7808/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6637 - val_loss: -0.5172\n",
            "Epoch 7809/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6603 - val_loss: -0.5175\n",
            "Epoch 7810/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6704 - val_loss: -0.5170\n",
            "Epoch 7811/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6663 - val_loss: -0.5177\n",
            "Epoch 7812/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6721 - val_loss: -0.5170\n",
            "Epoch 7813/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6682 - val_loss: -0.5175\n",
            "Epoch 7814/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6708 - val_loss: -0.5171\n",
            "Epoch 7815/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6639 - val_loss: -0.5173\n",
            "Epoch 7816/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6655 - val_loss: -0.5173\n",
            "Epoch 7817/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6638 - val_loss: -0.5174\n",
            "Epoch 7818/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6546 - val_loss: -0.5174\n",
            "Epoch 7819/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6692 - val_loss: -0.5158\n",
            "Epoch 7820/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6707 - val_loss: -0.5173\n",
            "Epoch 7821/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6704 - val_loss: -0.5171\n",
            "Epoch 7822/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6668 - val_loss: -0.5183\n",
            "Epoch 7823/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6700 - val_loss: -0.5179\n",
            "Epoch 7824/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6643 - val_loss: -0.5174\n",
            "Epoch 7825/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6697 - val_loss: -0.5169\n",
            "Epoch 7826/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6768 - val_loss: -0.5173\n",
            "Epoch 7827/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6758 - val_loss: -0.5169\n",
            "Epoch 7828/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6681 - val_loss: -0.5170\n",
            "Epoch 7829/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6662 - val_loss: -0.5173\n",
            "Epoch 7830/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6751 - val_loss: -0.5166\n",
            "Epoch 7831/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6759 - val_loss: -0.5171\n",
            "Epoch 7832/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6683 - val_loss: -0.5176\n",
            "Epoch 7833/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5168\n",
            "Epoch 7834/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6689 - val_loss: -0.5173\n",
            "Epoch 7835/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6749 - val_loss: -0.5167\n",
            "Epoch 7836/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6728 - val_loss: -0.5172\n",
            "Epoch 7837/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6651 - val_loss: -0.5176\n",
            "Epoch 7838/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6718 - val_loss: -0.5162\n",
            "Epoch 7839/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6666 - val_loss: -0.5178\n",
            "Epoch 7840/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6563 - val_loss: -0.5180\n",
            "Epoch 7841/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6771 - val_loss: -0.5164\n",
            "Epoch 7842/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6661 - val_loss: -0.5181\n",
            "Epoch 7843/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6636 - val_loss: -0.5165\n",
            "Epoch 7844/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6734 - val_loss: -0.5164\n",
            "Epoch 7845/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6652 - val_loss: -0.5172\n",
            "Epoch 7846/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6632 - val_loss: -0.5176\n",
            "Epoch 7847/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6748 - val_loss: -0.5170\n",
            "Epoch 7848/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6639 - val_loss: -0.5173\n",
            "Epoch 7849/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6671 - val_loss: -0.5174\n",
            "Epoch 7850/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6546 - val_loss: -0.5181\n",
            "Epoch 7851/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6583 - val_loss: -0.5178\n",
            "Epoch 7852/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6736 - val_loss: -0.5174\n",
            "Epoch 7853/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6713 - val_loss: -0.5173\n",
            "Epoch 7854/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6633 - val_loss: -0.5172\n",
            "Epoch 7855/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6729 - val_loss: -0.5166\n",
            "Epoch 7856/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6763 - val_loss: -0.5172\n",
            "Epoch 7857/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6759 - val_loss: -0.5166\n",
            "Epoch 7858/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6596 - val_loss: -0.5179\n",
            "Epoch 7859/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6676 - val_loss: -0.5171\n",
            "Epoch 7860/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6557 - val_loss: -0.5171\n",
            "Epoch 7861/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6703 - val_loss: -0.5170\n",
            "Epoch 7862/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6727 - val_loss: -0.5173\n",
            "Epoch 7863/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6639 - val_loss: -0.5178\n",
            "Epoch 7864/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6702 - val_loss: -0.5169\n",
            "Epoch 7865/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6688 - val_loss: -0.5164\n",
            "Epoch 7866/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6649 - val_loss: -0.5173\n",
            "Epoch 7867/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6670 - val_loss: -0.5169\n",
            "Epoch 7868/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6697 - val_loss: -0.5168\n",
            "Epoch 7869/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6639 - val_loss: -0.5172\n",
            "Epoch 7870/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6617 - val_loss: -0.5173\n",
            "Epoch 7871/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6580 - val_loss: -0.5179\n",
            "Epoch 7872/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6571 - val_loss: -0.5169\n",
            "Epoch 7873/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6540 - val_loss: -0.5184\n",
            "Epoch 7874/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6570 - val_loss: -0.5169\n",
            "Epoch 7875/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6632 - val_loss: -0.5170\n",
            "Epoch 7876/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6580 - val_loss: -0.5165\n",
            "Epoch 7877/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6683 - val_loss: -0.5166\n",
            "Epoch 7878/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6633 - val_loss: -0.5172\n",
            "Epoch 7879/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6644 - val_loss: -0.5177\n",
            "Epoch 7880/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6607 - val_loss: -0.5177\n",
            "Epoch 7881/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6706 - val_loss: -0.5166\n",
            "Epoch 7882/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6720 - val_loss: -0.5166\n",
            "Epoch 7883/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6674 - val_loss: -0.5175\n",
            "Epoch 7884/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6721 - val_loss: -0.5170\n",
            "Epoch 7885/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6676 - val_loss: -0.5169\n",
            "Epoch 7886/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6630 - val_loss: -0.5172\n",
            "Epoch 7887/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6686 - val_loss: -0.5172\n",
            "Epoch 7888/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6727 - val_loss: -0.5167\n",
            "Epoch 7889/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6655 - val_loss: -0.5170\n",
            "Epoch 7890/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6644 - val_loss: -0.5170\n",
            "Epoch 7891/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6718 - val_loss: -0.5169\n",
            "Epoch 7892/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6705 - val_loss: -0.5168\n",
            "Epoch 7893/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6724 - val_loss: -0.5166\n",
            "Epoch 7894/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6572 - val_loss: -0.5183\n",
            "Epoch 7895/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6659 - val_loss: -0.5159\n",
            "Epoch 7896/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6746 - val_loss: -0.5172\n",
            "Epoch 7897/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6794 - val_loss: -0.5170\n",
            "Epoch 7898/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6568 - val_loss: -0.5176\n",
            "Epoch 7899/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6730 - val_loss: -0.5159\n",
            "Epoch 7900/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6669 - val_loss: -0.5172\n",
            "Epoch 7901/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6678 - val_loss: -0.5163\n",
            "Epoch 7902/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5174\n",
            "Epoch 7903/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6720 - val_loss: -0.5165\n",
            "Epoch 7904/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5169\n",
            "Epoch 7905/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6668 - val_loss: -0.5173\n",
            "Epoch 7906/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6734 - val_loss: -0.5167\n",
            "Epoch 7907/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6651 - val_loss: -0.5176\n",
            "Epoch 7908/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6650 - val_loss: -0.5168\n",
            "Epoch 7909/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6664 - val_loss: -0.5173\n",
            "Epoch 7910/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6634 - val_loss: -0.5175\n",
            "Epoch 7911/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6589 - val_loss: -0.5180\n",
            "Epoch 7912/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6599 - val_loss: -0.5177\n",
            "Epoch 7913/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6635 - val_loss: -0.5167\n",
            "Epoch 7914/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6725 - val_loss: -0.5174\n",
            "Epoch 7915/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6625 - val_loss: -0.5170\n",
            "Epoch 7916/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6755 - val_loss: -0.5172\n",
            "Epoch 7917/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6675 - val_loss: -0.5169\n",
            "Epoch 7918/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6786 - val_loss: -0.5165\n",
            "Epoch 7919/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6623 - val_loss: -0.5174\n",
            "Epoch 7920/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6678 - val_loss: -0.5170\n",
            "Epoch 7921/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6708 - val_loss: -0.5175\n",
            "Epoch 7922/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6674 - val_loss: -0.5175\n",
            "Epoch 7923/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6661 - val_loss: -0.5173\n",
            "Epoch 7924/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6583 - val_loss: -0.5172\n",
            "Epoch 7925/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6659 - val_loss: -0.5178\n",
            "Epoch 7926/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6695 - val_loss: -0.5175\n",
            "Epoch 7927/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6743 - val_loss: -0.5169\n",
            "Epoch 7928/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6685 - val_loss: -0.5176\n",
            "Epoch 7929/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6691 - val_loss: -0.5170\n",
            "Epoch 7930/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6660 - val_loss: -0.5168\n",
            "Epoch 7931/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6705 - val_loss: -0.5179\n",
            "Epoch 7932/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6600 - val_loss: -0.5176\n",
            "Epoch 7933/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6665 - val_loss: -0.5171\n",
            "Epoch 7934/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6732 - val_loss: -0.5170\n",
            "Epoch 7935/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6579 - val_loss: -0.5176\n",
            "Epoch 7936/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6746 - val_loss: -0.5164\n",
            "Epoch 7937/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6699 - val_loss: -0.5178\n",
            "Epoch 7938/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6706 - val_loss: -0.5174\n",
            "Epoch 7939/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6534 - val_loss: -0.5175\n",
            "Epoch 7940/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6666 - val_loss: -0.5177\n",
            "Epoch 7941/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6604 - val_loss: -0.5178\n",
            "Epoch 7942/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6666 - val_loss: -0.5174\n",
            "Epoch 7943/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6724 - val_loss: -0.5180\n",
            "Epoch 7944/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6673 - val_loss: -0.5163\n",
            "Epoch 7945/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6758 - val_loss: -0.5174\n",
            "Epoch 7946/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6678 - val_loss: -0.5170\n",
            "Epoch 7947/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6660 - val_loss: -0.5168\n",
            "Epoch 7948/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6642 - val_loss: -0.5169\n",
            "Epoch 7949/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6706 - val_loss: -0.5174\n",
            "Epoch 7950/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6685 - val_loss: -0.5173\n",
            "Epoch 7951/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6689 - val_loss: -0.5166\n",
            "Epoch 7952/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6757 - val_loss: -0.5172\n",
            "Epoch 7953/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6643 - val_loss: -0.5170\n",
            "Epoch 7954/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6728 - val_loss: -0.5172\n",
            "Epoch 7955/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6681 - val_loss: -0.5168\n",
            "Epoch 7956/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6705 - val_loss: -0.5173\n",
            "Epoch 7957/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6580 - val_loss: -0.5183\n",
            "Epoch 7958/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6611 - val_loss: -0.5179\n",
            "Epoch 7959/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6602 - val_loss: -0.5165\n",
            "Epoch 7960/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5179\n",
            "Epoch 7961/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6706 - val_loss: -0.5166\n",
            "Epoch 7962/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6675 - val_loss: -0.5179\n",
            "Epoch 7963/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6721 - val_loss: -0.5175\n",
            "Epoch 7964/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6709 - val_loss: -0.5173\n",
            "Epoch 7965/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5173\n",
            "Epoch 7966/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6686 - val_loss: -0.5174\n",
            "Epoch 7967/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6701 - val_loss: -0.5174\n",
            "Epoch 7968/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6756 - val_loss: -0.5173\n",
            "Epoch 7969/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6718 - val_loss: -0.5174\n",
            "Epoch 7970/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6684 - val_loss: -0.5167\n",
            "Epoch 7971/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6704 - val_loss: -0.5165\n",
            "Epoch 7972/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6666 - val_loss: -0.5179\n",
            "Epoch 7973/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6710 - val_loss: -0.5173\n",
            "Epoch 7974/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6481 - val_loss: -0.5173\n",
            "Epoch 7975/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6660 - val_loss: -0.5171\n",
            "Epoch 7976/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6649 - val_loss: -0.5171\n",
            "Epoch 7977/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6709 - val_loss: -0.5171\n",
            "Epoch 7978/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6571 - val_loss: -0.5177\n",
            "Epoch 7979/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6698 - val_loss: -0.5170\n",
            "Epoch 7980/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6779 - val_loss: -0.5170\n",
            "Epoch 7981/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6552 - val_loss: -0.5180\n",
            "Epoch 7982/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6654 - val_loss: -0.5171\n",
            "Epoch 7983/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5164\n",
            "Epoch 7984/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6702 - val_loss: -0.5174\n",
            "Epoch 7985/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6702 - val_loss: -0.5167\n",
            "Epoch 7986/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6713 - val_loss: -0.5177\n",
            "Epoch 7987/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6732 - val_loss: -0.5165\n",
            "Epoch 7988/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6632 - val_loss: -0.5174\n",
            "Epoch 7989/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6682 - val_loss: -0.5173\n",
            "Epoch 7990/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6635 - val_loss: -0.5168\n",
            "Epoch 7991/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6684 - val_loss: -0.5168\n",
            "Epoch 7992/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6630 - val_loss: -0.5168\n",
            "Epoch 7993/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6697 - val_loss: -0.5169\n",
            "Epoch 7994/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6719 - val_loss: -0.5170\n",
            "Epoch 7995/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6617 - val_loss: -0.5175\n",
            "Epoch 7996/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6667 - val_loss: -0.5167\n",
            "Epoch 7997/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6649 - val_loss: -0.5176\n",
            "Epoch 7998/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6673 - val_loss: -0.5168\n",
            "Epoch 7999/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6655 - val_loss: -0.5173\n",
            "Epoch 8000/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6691 - val_loss: -0.5176\n",
            "Epoch 8001/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6707 - val_loss: -0.5173\n",
            "Epoch 8002/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5170\n",
            "Epoch 8003/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6700 - val_loss: -0.5168\n",
            "Epoch 8004/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6706 - val_loss: -0.5171\n",
            "Epoch 8005/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5167\n",
            "Epoch 8006/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6696 - val_loss: -0.5169\n",
            "Epoch 8007/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6729 - val_loss: -0.5168\n",
            "Epoch 8008/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6670 - val_loss: -0.5169\n",
            "Epoch 8009/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6626 - val_loss: -0.5165\n",
            "Epoch 8010/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6722 - val_loss: -0.5172\n",
            "Epoch 8011/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6753 - val_loss: -0.5163\n",
            "Epoch 8012/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6708 - val_loss: -0.5169\n",
            "Epoch 8013/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6749 - val_loss: -0.5166\n",
            "Epoch 8014/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6520 - val_loss: -0.5179\n",
            "Epoch 8015/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6622 - val_loss: -0.5176\n",
            "Epoch 8016/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6684 - val_loss: -0.5159\n",
            "Epoch 8017/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6590 - val_loss: -0.5173\n",
            "Epoch 8018/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6654 - val_loss: -0.5167\n",
            "Epoch 8019/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6621 - val_loss: -0.5172\n",
            "Epoch 8020/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5172\n",
            "Epoch 8021/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6595 - val_loss: -0.5175\n",
            "Epoch 8022/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6631 - val_loss: -0.5166\n",
            "Epoch 8023/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6745 - val_loss: -0.5167\n",
            "Epoch 8024/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6609 - val_loss: -0.5178\n",
            "Epoch 8025/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6672 - val_loss: -0.5168\n",
            "Epoch 8026/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5174\n",
            "Epoch 8027/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6708 - val_loss: -0.5171\n",
            "Epoch 8028/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6710 - val_loss: -0.5176\n",
            "Epoch 8029/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6769 - val_loss: -0.5169\n",
            "Epoch 8030/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5175\n",
            "Epoch 8031/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6711 - val_loss: -0.5178\n",
            "Epoch 8032/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6671 - val_loss: -0.5185\n",
            "Epoch 8033/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6540 - val_loss: -0.5174\n",
            "Epoch 8034/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6731 - val_loss: -0.5168\n",
            "Epoch 8035/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6669 - val_loss: -0.5179\n",
            "Epoch 8036/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6738 - val_loss: -0.5169\n",
            "Epoch 8037/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6605 - val_loss: -0.5179\n",
            "Epoch 8038/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6674 - val_loss: -0.5170\n",
            "Epoch 8039/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6725 - val_loss: -0.5170\n",
            "Epoch 8040/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6628 - val_loss: -0.5179\n",
            "Epoch 8041/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6685 - val_loss: -0.5169\n",
            "Epoch 8042/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6649 - val_loss: -0.5178\n",
            "Epoch 8043/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6614 - val_loss: -0.5180\n",
            "Epoch 8044/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6621 - val_loss: -0.5170\n",
            "Epoch 8045/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6638 - val_loss: -0.5170\n",
            "Epoch 8046/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6733 - val_loss: -0.5173\n",
            "Epoch 8047/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6646 - val_loss: -0.5180\n",
            "Epoch 8048/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6629 - val_loss: -0.5175\n",
            "Epoch 8049/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6731 - val_loss: -0.5167\n",
            "Epoch 8050/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6757 - val_loss: -0.5172\n",
            "Epoch 8051/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6713 - val_loss: -0.5168\n",
            "Epoch 8052/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6712 - val_loss: -0.5171\n",
            "Epoch 8053/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6748 - val_loss: -0.5172\n",
            "Epoch 8054/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6583 - val_loss: -0.5176\n",
            "Epoch 8055/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6625 - val_loss: -0.5175\n",
            "Epoch 8056/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6673 - val_loss: -0.5179\n",
            "Epoch 8057/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6720 - val_loss: -0.5173\n",
            "Epoch 8058/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6702 - val_loss: -0.5174\n",
            "Epoch 8059/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6753 - val_loss: -0.5170\n",
            "Epoch 8060/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6611 - val_loss: -0.5177\n",
            "Epoch 8061/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6677 - val_loss: -0.5163\n",
            "Epoch 8062/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6748 - val_loss: -0.5169\n",
            "Epoch 8063/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6579 - val_loss: -0.5179\n",
            "Epoch 8064/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6567 - val_loss: -0.5178\n",
            "Epoch 8065/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6661 - val_loss: -0.5175\n",
            "Epoch 8066/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6677 - val_loss: -0.5163\n",
            "Epoch 8067/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6724 - val_loss: -0.5170\n",
            "Epoch 8068/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6669 - val_loss: -0.5173\n",
            "Epoch 8069/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6742 - val_loss: -0.5170\n",
            "Epoch 8070/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6682 - val_loss: -0.5165\n",
            "Epoch 8071/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6678 - val_loss: -0.5176\n",
            "Epoch 8072/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6652 - val_loss: -0.5171\n",
            "Epoch 8073/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6599 - val_loss: -0.5169\n",
            "Epoch 8074/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6661 - val_loss: -0.5168\n",
            "Epoch 8075/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6579 - val_loss: -0.5179\n",
            "Epoch 8076/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6735 - val_loss: -0.5175\n",
            "Epoch 8077/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6575 - val_loss: -0.5179\n",
            "Epoch 8078/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6720 - val_loss: -0.5166\n",
            "Epoch 8079/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6710 - val_loss: -0.5169\n",
            "Epoch 8080/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6726 - val_loss: -0.5170\n",
            "Epoch 8081/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6750 - val_loss: -0.5176\n",
            "Epoch 8082/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6626 - val_loss: -0.5168\n",
            "Epoch 8083/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6725 - val_loss: -0.5168\n",
            "Epoch 8084/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5176\n",
            "Epoch 8085/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6669 - val_loss: -0.5166\n",
            "Epoch 8086/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6609 - val_loss: -0.5172\n",
            "Epoch 8087/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6593 - val_loss: -0.5171\n",
            "Epoch 8088/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6599 - val_loss: -0.5168\n",
            "Epoch 8089/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6620 - val_loss: -0.5171\n",
            "Epoch 8090/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6697 - val_loss: -0.5168\n",
            "Epoch 8091/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6653 - val_loss: -0.5176\n",
            "Epoch 8092/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6729 - val_loss: -0.5164\n",
            "Epoch 8093/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6618 - val_loss: -0.5172\n",
            "Epoch 8094/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6717 - val_loss: -0.5166\n",
            "Epoch 8095/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6756 - val_loss: -0.5172\n",
            "Epoch 8096/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6650 - val_loss: -0.5165\n",
            "Epoch 8097/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6657 - val_loss: -0.5172\n",
            "Epoch 8098/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5171\n",
            "Epoch 8099/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6685 - val_loss: -0.5169\n",
            "Epoch 8100/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6743 - val_loss: -0.5173\n",
            "Epoch 8101/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6652 - val_loss: -0.5176\n",
            "Epoch 8102/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6725 - val_loss: -0.5164\n",
            "Epoch 8103/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6783 - val_loss: -0.5162\n",
            "Epoch 8104/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5169\n",
            "Epoch 8105/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6636 - val_loss: -0.5174\n",
            "Epoch 8106/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6750 - val_loss: -0.5170\n",
            "Epoch 8107/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6743 - val_loss: -0.5169\n",
            "Epoch 8108/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6642 - val_loss: -0.5174\n",
            "Epoch 8109/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6697 - val_loss: -0.5170\n",
            "Epoch 8110/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6742 - val_loss: -0.5167\n",
            "Epoch 8111/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6659 - val_loss: -0.5173\n",
            "Epoch 8112/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5170\n",
            "Epoch 8113/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6672 - val_loss: -0.5169\n",
            "Epoch 8114/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6739 - val_loss: -0.5163\n",
            "Epoch 8115/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6686 - val_loss: -0.5170\n",
            "Epoch 8116/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6645 - val_loss: -0.5178\n",
            "Epoch 8117/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6734 - val_loss: -0.5170\n",
            "Epoch 8118/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6658 - val_loss: -0.5178\n",
            "Epoch 8119/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6705 - val_loss: -0.5163\n",
            "Epoch 8120/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6692 - val_loss: -0.5161\n",
            "Epoch 8121/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6607 - val_loss: -0.5178\n",
            "Epoch 8122/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5172\n",
            "Epoch 8123/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6752 - val_loss: -0.5173\n",
            "Epoch 8124/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6661 - val_loss: -0.5169\n",
            "Epoch 8125/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6553 - val_loss: -0.5185\n",
            "Epoch 8126/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6711 - val_loss: -0.5169\n",
            "Epoch 8127/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6745 - val_loss: -0.5167\n",
            "Epoch 8128/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6739 - val_loss: -0.5162\n",
            "Epoch 8129/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6712 - val_loss: -0.5174\n",
            "Epoch 8130/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6729 - val_loss: -0.5172\n",
            "Epoch 8131/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6636 - val_loss: -0.5177\n",
            "Epoch 8132/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6736 - val_loss: -0.5171\n",
            "Epoch 8133/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6722 - val_loss: -0.5176\n",
            "Epoch 8134/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6750 - val_loss: -0.5163\n",
            "Epoch 8135/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6619 - val_loss: -0.5174\n",
            "Epoch 8136/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6784 - val_loss: -0.5170\n",
            "Epoch 8137/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6730 - val_loss: -0.5172\n",
            "Epoch 8138/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6724 - val_loss: -0.5173\n",
            "Epoch 8139/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6630 - val_loss: -0.5181\n",
            "Epoch 8140/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6691 - val_loss: -0.5169\n",
            "Epoch 8141/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6747 - val_loss: -0.5172\n",
            "Epoch 8142/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6746 - val_loss: -0.5170\n",
            "Epoch 8143/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6764 - val_loss: -0.5168\n",
            "Epoch 8144/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6702 - val_loss: -0.5169\n",
            "Epoch 8145/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6729 - val_loss: -0.5168\n",
            "Epoch 8146/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6613 - val_loss: -0.5171\n",
            "Epoch 8147/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6717 - val_loss: -0.5170\n",
            "Epoch 8148/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6736 - val_loss: -0.5167\n",
            "Epoch 8149/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6596 - val_loss: -0.5170\n",
            "Epoch 8150/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6702 - val_loss: -0.5165\n",
            "Epoch 8151/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6602 - val_loss: -0.5165\n",
            "Epoch 8152/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6674 - val_loss: -0.5170\n",
            "Epoch 8153/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6703 - val_loss: -0.5170\n",
            "Epoch 8154/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6760 - val_loss: -0.5166\n",
            "Epoch 8155/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6671 - val_loss: -0.5173\n",
            "Epoch 8156/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6630 - val_loss: -0.5161\n",
            "Epoch 8157/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6574 - val_loss: -0.5176\n",
            "Epoch 8158/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6724 - val_loss: -0.5171\n",
            "Epoch 8159/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6598 - val_loss: -0.5183\n",
            "Epoch 8160/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5165\n",
            "Epoch 8161/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6705 - val_loss: -0.5177\n",
            "Epoch 8162/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6538 - val_loss: -0.5182\n",
            "Epoch 8163/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6728 - val_loss: -0.5155\n",
            "Epoch 8164/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6755 - val_loss: -0.5176\n",
            "Epoch 8165/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6745 - val_loss: -0.5175\n",
            "Epoch 8166/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6704 - val_loss: -0.5170\n",
            "Epoch 8167/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6691 - val_loss: -0.5176\n",
            "Epoch 8168/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6773 - val_loss: -0.5169\n",
            "Epoch 8169/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6599 - val_loss: -0.5175\n",
            "Epoch 8170/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6651 - val_loss: -0.5174\n",
            "Epoch 8171/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6657 - val_loss: -0.5167\n",
            "Epoch 8172/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6690 - val_loss: -0.5175\n",
            "Epoch 8173/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6642 - val_loss: -0.5175\n",
            "Epoch 8174/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6743 - val_loss: -0.5164\n",
            "Epoch 8175/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6652 - val_loss: -0.5178\n",
            "Epoch 8176/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5170\n",
            "Epoch 8177/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6724 - val_loss: -0.5165\n",
            "Epoch 8178/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6614 - val_loss: -0.5174\n",
            "Epoch 8179/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6636 - val_loss: -0.5167\n",
            "Epoch 8180/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6727 - val_loss: -0.5173\n",
            "Epoch 8181/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6638 - val_loss: -0.5173\n",
            "Epoch 8182/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6729 - val_loss: -0.5174\n",
            "Epoch 8183/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6641 - val_loss: -0.5174\n",
            "Epoch 8184/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6712 - val_loss: -0.5167\n",
            "Epoch 8185/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6683 - val_loss: -0.5179\n",
            "Epoch 8186/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6694 - val_loss: -0.5178\n",
            "Epoch 8187/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6726 - val_loss: -0.5169\n",
            "Epoch 8188/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6746 - val_loss: -0.5162\n",
            "Epoch 8189/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6683 - val_loss: -0.5179\n",
            "Epoch 8190/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6643 - val_loss: -0.5176\n",
            "Epoch 8191/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6576 - val_loss: -0.5178\n",
            "Epoch 8192/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6647 - val_loss: -0.5175\n",
            "Epoch 8193/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6637 - val_loss: -0.5169\n",
            "Epoch 8194/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6590 - val_loss: -0.5167\n",
            "Epoch 8195/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6625 - val_loss: -0.5163\n",
            "Epoch 8196/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6735 - val_loss: -0.5166\n",
            "Epoch 8197/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6689 - val_loss: -0.5164\n",
            "Epoch 8198/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6746 - val_loss: -0.5172\n",
            "Epoch 8199/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6703 - val_loss: -0.5171\n",
            "Epoch 8200/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6754 - val_loss: -0.5162\n",
            "Epoch 8201/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6727 - val_loss: -0.5169\n",
            "Epoch 8202/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6640 - val_loss: -0.5170\n",
            "Epoch 8203/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6701 - val_loss: -0.5173\n",
            "Epoch 8204/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6743 - val_loss: -0.5167\n",
            "Epoch 8205/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6578 - val_loss: -0.5178\n",
            "Epoch 8206/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6674 - val_loss: -0.5168\n",
            "Epoch 8207/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6669 - val_loss: -0.5169\n",
            "Epoch 8208/10000\n",
            "22/22 [==============================] - 1s 29ms/step - loss: -0.6590 - val_loss: -0.5173\n",
            "Epoch 8209/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6622 - val_loss: -0.5166\n",
            "Epoch 8210/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6635 - val_loss: -0.5179\n",
            "Epoch 8211/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6651 - val_loss: -0.5172\n",
            "Epoch 8212/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6777 - val_loss: -0.5169\n",
            "Epoch 8213/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6724 - val_loss: -0.5174\n",
            "Epoch 8214/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6712 - val_loss: -0.5171\n",
            "Epoch 8215/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6694 - val_loss: -0.5168\n",
            "Epoch 8216/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6741 - val_loss: -0.5171\n",
            "Epoch 8217/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6728 - val_loss: -0.5171\n",
            "Epoch 8218/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5170\n",
            "Epoch 8219/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6663 - val_loss: -0.5169\n",
            "Epoch 8220/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6738 - val_loss: -0.5167\n",
            "Epoch 8221/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6723 - val_loss: -0.5171\n",
            "Epoch 8222/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6700 - val_loss: -0.5179\n",
            "Epoch 8223/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6698 - val_loss: -0.5170\n",
            "Epoch 8224/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6575 - val_loss: -0.5167\n",
            "Epoch 8225/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6761 - val_loss: -0.5177\n",
            "Epoch 8226/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6678 - val_loss: -0.5169\n",
            "Epoch 8227/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6550 - val_loss: -0.5178\n",
            "Epoch 8228/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6655 - val_loss: -0.5162\n",
            "Epoch 8229/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6686 - val_loss: -0.5166\n",
            "Epoch 8230/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6682 - val_loss: -0.5170\n",
            "Epoch 8231/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6713 - val_loss: -0.5177\n",
            "Epoch 8232/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6630 - val_loss: -0.5178\n",
            "Epoch 8233/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6712 - val_loss: -0.5164\n",
            "Epoch 8234/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6679 - val_loss: -0.5167\n",
            "Epoch 8235/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6700 - val_loss: -0.5174\n",
            "Epoch 8236/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6707 - val_loss: -0.5175\n",
            "Epoch 8237/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6694 - val_loss: -0.5168\n",
            "Epoch 8238/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6765 - val_loss: -0.5166\n",
            "Epoch 8239/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6707 - val_loss: -0.5170\n",
            "Epoch 8240/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6769 - val_loss: -0.5169\n",
            "Epoch 8241/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6674 - val_loss: -0.5175\n",
            "Epoch 8242/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6603 - val_loss: -0.5181\n",
            "Epoch 8243/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6620 - val_loss: -0.5168\n",
            "Epoch 8244/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6676 - val_loss: -0.5180\n",
            "Epoch 8245/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6726 - val_loss: -0.5175\n",
            "Epoch 8246/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6711 - val_loss: -0.5176\n",
            "Epoch 8247/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6684 - val_loss: -0.5176\n",
            "Epoch 8248/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6748 - val_loss: -0.5167\n",
            "Epoch 8249/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6732 - val_loss: -0.5168\n",
            "Epoch 8250/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6742 - val_loss: -0.5177\n",
            "Epoch 8251/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6740 - val_loss: -0.5169\n",
            "Epoch 8252/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6754 - val_loss: -0.5168\n",
            "Epoch 8253/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6610 - val_loss: -0.5175\n",
            "Epoch 8254/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6702 - val_loss: -0.5158\n",
            "Epoch 8255/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6741 - val_loss: -0.5169\n",
            "Epoch 8256/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6648 - val_loss: -0.5175\n",
            "Epoch 8257/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6661 - val_loss: -0.5173\n",
            "Epoch 8258/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6718 - val_loss: -0.5171\n",
            "Epoch 8259/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6639 - val_loss: -0.5171\n",
            "Epoch 8260/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6698 - val_loss: -0.5172\n",
            "Epoch 8261/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6616 - val_loss: -0.5172\n",
            "Epoch 8262/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6748 - val_loss: -0.5173\n",
            "Epoch 8263/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6627 - val_loss: -0.5173\n",
            "Epoch 8264/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6665 - val_loss: -0.5179\n",
            "Epoch 8265/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6741 - val_loss: -0.5166\n",
            "Epoch 8266/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6540 - val_loss: -0.5182\n",
            "Epoch 8267/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6706 - val_loss: -0.5174\n",
            "Epoch 8268/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6763 - val_loss: -0.5173\n",
            "Epoch 8269/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6736 - val_loss: -0.5170\n",
            "Epoch 8270/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6653 - val_loss: -0.5178\n",
            "Epoch 8271/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6691 - val_loss: -0.5174\n",
            "Epoch 8272/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6703 - val_loss: -0.5173\n",
            "Epoch 8273/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6751 - val_loss: -0.5168\n",
            "Epoch 8274/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6714 - val_loss: -0.5175\n",
            "Epoch 8275/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6657 - val_loss: -0.5175\n",
            "Epoch 8276/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6764 - val_loss: -0.5167\n",
            "Epoch 8277/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6725 - val_loss: -0.5180\n",
            "Epoch 8278/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6763 - val_loss: -0.5177\n",
            "Epoch 8279/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6673 - val_loss: -0.5169\n",
            "Epoch 8280/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6673 - val_loss: -0.5175\n",
            "Epoch 8281/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6670 - val_loss: -0.5166\n",
            "Epoch 8282/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6657 - val_loss: -0.5173\n",
            "Epoch 8283/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6625 - val_loss: -0.5173\n",
            "Epoch 8284/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6775 - val_loss: -0.5167\n",
            "Epoch 8285/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6723 - val_loss: -0.5176\n",
            "Epoch 8286/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6615 - val_loss: -0.5176\n",
            "Epoch 8287/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6653 - val_loss: -0.5173\n",
            "Epoch 8288/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6599 - val_loss: -0.5175\n",
            "Epoch 8289/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6594 - val_loss: -0.5175\n",
            "Epoch 8290/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6732 - val_loss: -0.5167\n",
            "Epoch 8291/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6638 - val_loss: -0.5168\n",
            "Epoch 8292/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6654 - val_loss: -0.5179\n",
            "Epoch 8293/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6691 - val_loss: -0.5175\n",
            "Epoch 8294/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6667 - val_loss: -0.5167\n",
            "Epoch 8295/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6744 - val_loss: -0.5172\n",
            "Epoch 8296/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6636 - val_loss: -0.5175\n",
            "Epoch 8297/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6704 - val_loss: -0.5164\n",
            "Epoch 8298/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6497 - val_loss: -0.5181\n",
            "Epoch 8299/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6771 - val_loss: -0.5170\n",
            "Epoch 8300/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6631 - val_loss: -0.5172\n",
            "Epoch 8301/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6721 - val_loss: -0.5167\n",
            "Epoch 8302/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6718 - val_loss: -0.5170\n",
            "Epoch 8303/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6748 - val_loss: -0.5172\n",
            "Epoch 8304/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5171\n",
            "Epoch 8305/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6679 - val_loss: -0.5172\n",
            "Epoch 8306/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6696 - val_loss: -0.5179\n",
            "Epoch 8307/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6686 - val_loss: -0.5176\n",
            "Epoch 8308/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6667 - val_loss: -0.5169\n",
            "Epoch 8309/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6630 - val_loss: -0.5171\n",
            "Epoch 8310/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6717 - val_loss: -0.5167\n",
            "Epoch 8311/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6727 - val_loss: -0.5174\n",
            "Epoch 8312/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6525 - val_loss: -0.5163\n",
            "Epoch 8313/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6735 - val_loss: -0.5167\n",
            "Epoch 8314/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6724 - val_loss: -0.5171\n",
            "Epoch 8315/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6707 - val_loss: -0.5164\n",
            "Epoch 8316/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6726 - val_loss: -0.5176\n",
            "Epoch 8317/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6655 - val_loss: -0.5178\n",
            "Epoch 8318/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6758 - val_loss: -0.5170\n",
            "Epoch 8319/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5173\n",
            "Epoch 8320/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6743 - val_loss: -0.5171\n",
            "Epoch 8321/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6588 - val_loss: -0.5171\n",
            "Epoch 8322/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6765 - val_loss: -0.5159\n",
            "Epoch 8323/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6730 - val_loss: -0.5172\n",
            "Epoch 8324/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6718 - val_loss: -0.5165\n",
            "Epoch 8325/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6650 - val_loss: -0.5171\n",
            "Epoch 8326/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6708 - val_loss: -0.5170\n",
            "Epoch 8327/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6789 - val_loss: -0.5163\n",
            "Epoch 8328/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6621 - val_loss: -0.5174\n",
            "Epoch 8329/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6698 - val_loss: -0.5162\n",
            "Epoch 8330/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6684 - val_loss: -0.5173\n",
            "Epoch 8331/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6706 - val_loss: -0.5163\n",
            "Epoch 8332/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6730 - val_loss: -0.5173\n",
            "Epoch 8333/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5173\n",
            "Epoch 8334/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6604 - val_loss: -0.5179\n",
            "Epoch 8335/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6687 - val_loss: -0.5174\n",
            "Epoch 8336/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6769 - val_loss: -0.5174\n",
            "Epoch 8337/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6680 - val_loss: -0.5163\n",
            "Epoch 8338/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6740 - val_loss: -0.5173\n",
            "Epoch 8339/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6595 - val_loss: -0.5178\n",
            "Epoch 8340/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6709 - val_loss: -0.5171\n",
            "Epoch 8341/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6750 - val_loss: -0.5174\n",
            "Epoch 8342/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6686 - val_loss: -0.5172\n",
            "Epoch 8343/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6715 - val_loss: -0.5170\n",
            "Epoch 8344/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6641 - val_loss: -0.5172\n",
            "Epoch 8345/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6657 - val_loss: -0.5165\n",
            "Epoch 8346/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6653 - val_loss: -0.5174\n",
            "Epoch 8347/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6781 - val_loss: -0.5167\n",
            "Epoch 8348/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6693 - val_loss: -0.5173\n",
            "Epoch 8349/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6642 - val_loss: -0.5181\n",
            "Epoch 8350/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6701 - val_loss: -0.5173\n",
            "Epoch 8351/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6731 - val_loss: -0.5166\n",
            "Epoch 8352/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5170\n",
            "Epoch 8353/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6753 - val_loss: -0.5168\n",
            "Epoch 8354/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6766 - val_loss: -0.5169\n",
            "Epoch 8355/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6616 - val_loss: -0.5161\n",
            "Epoch 8356/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6572 - val_loss: -0.5176\n",
            "Epoch 8357/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6639 - val_loss: -0.5163\n",
            "Epoch 8358/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6770 - val_loss: -0.5164\n",
            "Epoch 8359/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6660 - val_loss: -0.5171\n",
            "Epoch 8360/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6719 - val_loss: -0.5158\n",
            "Epoch 8361/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5170\n",
            "Epoch 8362/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6598 - val_loss: -0.5170\n",
            "Epoch 8363/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6665 - val_loss: -0.5171\n",
            "Epoch 8364/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6579 - val_loss: -0.5162\n",
            "Epoch 8365/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6763 - val_loss: -0.5171\n",
            "Epoch 8366/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6733 - val_loss: -0.5165\n",
            "Epoch 8367/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6709 - val_loss: -0.5178\n",
            "Epoch 8368/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6777 - val_loss: -0.5159\n",
            "Epoch 8369/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6729 - val_loss: -0.5171\n",
            "Epoch 8370/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6724 - val_loss: -0.5167\n",
            "Epoch 8371/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6746 - val_loss: -0.5170\n",
            "Epoch 8372/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6700 - val_loss: -0.5166\n",
            "Epoch 8373/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6716 - val_loss: -0.5170\n",
            "Epoch 8374/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6652 - val_loss: -0.5174\n",
            "Epoch 8375/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6581 - val_loss: -0.5172\n",
            "Epoch 8376/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6670 - val_loss: -0.5166\n",
            "Epoch 8377/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6689 - val_loss: -0.5169\n",
            "Epoch 8378/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6745 - val_loss: -0.5168\n",
            "Epoch 8379/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6711 - val_loss: -0.5171\n",
            "Epoch 8380/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6675 - val_loss: -0.5163\n",
            "Epoch 8381/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6667 - val_loss: -0.5171\n",
            "Epoch 8382/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6640 - val_loss: -0.5169\n",
            "Epoch 8383/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6737 - val_loss: -0.5169\n",
            "Epoch 8384/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6666 - val_loss: -0.5164\n",
            "Epoch 8385/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6739 - val_loss: -0.5170\n",
            "Epoch 8386/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6751 - val_loss: -0.5168\n",
            "Epoch 8387/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5174\n",
            "Epoch 8388/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6705 - val_loss: -0.5169\n",
            "Epoch 8389/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6584 - val_loss: -0.5174\n",
            "Epoch 8390/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6695 - val_loss: -0.5168\n",
            "Epoch 8391/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6634 - val_loss: -0.5168\n",
            "Epoch 8392/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6574 - val_loss: -0.5182\n",
            "Epoch 8393/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6701 - val_loss: -0.5162\n",
            "Epoch 8394/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6653 - val_loss: -0.5173\n",
            "Epoch 8395/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6790 - val_loss: -0.5168\n",
            "Epoch 8396/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6666 - val_loss: -0.5169\n",
            "Epoch 8397/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6696 - val_loss: -0.5167\n",
            "Epoch 8398/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5165\n",
            "Epoch 8399/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6718 - val_loss: -0.5174\n",
            "Epoch 8400/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5176\n",
            "Epoch 8401/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6753 - val_loss: -0.5163\n",
            "Epoch 8402/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6766 - val_loss: -0.5167\n",
            "Epoch 8403/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6552 - val_loss: -0.5166\n",
            "Epoch 8404/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6665 - val_loss: -0.5168\n",
            "Epoch 8405/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6679 - val_loss: -0.5171\n",
            "Epoch 8406/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6726 - val_loss: -0.5163\n",
            "Epoch 8407/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6619 - val_loss: -0.5171\n",
            "Epoch 8408/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6686 - val_loss: -0.5170\n",
            "Epoch 8409/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6741 - val_loss: -0.5167\n",
            "Epoch 8410/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6715 - val_loss: -0.5172\n",
            "Epoch 8411/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6772 - val_loss: -0.5168\n",
            "Epoch 8412/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6721 - val_loss: -0.5169\n",
            "Epoch 8413/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6657 - val_loss: -0.5173\n",
            "Epoch 8414/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6711 - val_loss: -0.5154\n",
            "Epoch 8415/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5181\n",
            "Epoch 8416/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6785 - val_loss: -0.5167\n",
            "Epoch 8417/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6709 - val_loss: -0.5169\n",
            "Epoch 8418/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6717 - val_loss: -0.5170\n",
            "Epoch 8419/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6759 - val_loss: -0.5170\n",
            "Epoch 8420/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6695 - val_loss: -0.5169\n",
            "Epoch 8421/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6739 - val_loss: -0.5173\n",
            "Epoch 8422/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6743 - val_loss: -0.5178\n",
            "Epoch 8423/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6654 - val_loss: -0.5171\n",
            "Epoch 8424/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6722 - val_loss: -0.5166\n",
            "Epoch 8425/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6695 - val_loss: -0.5171\n",
            "Epoch 8426/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6656 - val_loss: -0.5171\n",
            "Epoch 8427/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6701 - val_loss: -0.5161\n",
            "Epoch 8428/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6680 - val_loss: -0.5168\n",
            "Epoch 8429/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6734 - val_loss: -0.5166\n",
            "Epoch 8430/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6601 - val_loss: -0.5169\n",
            "Epoch 8431/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6664 - val_loss: -0.5171\n",
            "Epoch 8432/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6726 - val_loss: -0.5166\n",
            "Epoch 8433/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6656 - val_loss: -0.5165\n",
            "Epoch 8434/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6704 - val_loss: -0.5176\n",
            "Epoch 8435/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6724 - val_loss: -0.5167\n",
            "Epoch 8436/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6725 - val_loss: -0.5164\n",
            "Epoch 8437/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6701 - val_loss: -0.5172\n",
            "Epoch 8438/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6705 - val_loss: -0.5158\n",
            "Epoch 8439/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6679 - val_loss: -0.5165\n",
            "Epoch 8440/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6743 - val_loss: -0.5164\n",
            "Epoch 8441/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6654 - val_loss: -0.5173\n",
            "Epoch 8442/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6728 - val_loss: -0.5165\n",
            "Epoch 8443/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6527 - val_loss: -0.5183\n",
            "Epoch 8444/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6579 - val_loss: -0.5160\n",
            "Epoch 8445/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6690 - val_loss: -0.5171\n",
            "Epoch 8446/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6767 - val_loss: -0.5157\n",
            "Epoch 8447/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6715 - val_loss: -0.5168\n",
            "Epoch 8448/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6725 - val_loss: -0.5173\n",
            "Epoch 8449/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6703 - val_loss: -0.5165\n",
            "Epoch 8450/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6752 - val_loss: -0.5171\n",
            "Epoch 8451/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6715 - val_loss: -0.5166\n",
            "Epoch 8452/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6685 - val_loss: -0.5171\n",
            "Epoch 8453/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6777 - val_loss: -0.5166\n",
            "Epoch 8454/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6755 - val_loss: -0.5163\n",
            "Epoch 8455/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5172\n",
            "Epoch 8456/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6711 - val_loss: -0.5174\n",
            "Epoch 8457/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6660 - val_loss: -0.5171\n",
            "Epoch 8458/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6753 - val_loss: -0.5163\n",
            "Epoch 8459/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6750 - val_loss: -0.5169\n",
            "Epoch 8460/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6749 - val_loss: -0.5163\n",
            "Epoch 8461/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6615 - val_loss: -0.5172\n",
            "Epoch 8462/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6755 - val_loss: -0.5161\n",
            "Epoch 8463/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6761 - val_loss: -0.5171\n",
            "Epoch 8464/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6657 - val_loss: -0.5162\n",
            "Epoch 8465/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6689 - val_loss: -0.5168\n",
            "Epoch 8466/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6628 - val_loss: -0.5172\n",
            "Epoch 8467/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6714 - val_loss: -0.5169\n",
            "Epoch 8468/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5170\n",
            "Epoch 8469/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6713 - val_loss: -0.5162\n",
            "Epoch 8470/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6805 - val_loss: -0.5168\n",
            "Epoch 8471/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6659 - val_loss: -0.5177\n",
            "Epoch 8472/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6674 - val_loss: -0.5169\n",
            "Epoch 8473/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6694 - val_loss: -0.5171\n",
            "Epoch 8474/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6720 - val_loss: -0.5172\n",
            "Epoch 8475/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6645 - val_loss: -0.5180\n",
            "Epoch 8476/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6675 - val_loss: -0.5164\n",
            "Epoch 8477/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5168\n",
            "Epoch 8478/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6744 - val_loss: -0.5171\n",
            "Epoch 8479/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6763 - val_loss: -0.5167\n",
            "Epoch 8480/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6684 - val_loss: -0.5175\n",
            "Epoch 8481/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6699 - val_loss: -0.5169\n",
            "Epoch 8482/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6649 - val_loss: -0.5167\n",
            "Epoch 8483/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6718 - val_loss: -0.5163\n",
            "Epoch 8484/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6703 - val_loss: -0.5171\n",
            "Epoch 8485/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6707 - val_loss: -0.5169\n",
            "Epoch 8486/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6751 - val_loss: -0.5166\n",
            "Epoch 8487/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6673 - val_loss: -0.5178\n",
            "Epoch 8488/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6645 - val_loss: -0.5162\n",
            "Epoch 8489/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6736 - val_loss: -0.5169\n",
            "Epoch 8490/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6671 - val_loss: -0.5165\n",
            "Epoch 8491/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6632 - val_loss: -0.5172\n",
            "Epoch 8492/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6681 - val_loss: -0.5165\n",
            "Epoch 8493/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6728 - val_loss: -0.5168\n",
            "Epoch 8494/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6715 - val_loss: -0.5167\n",
            "Epoch 8495/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6724 - val_loss: -0.5175\n",
            "Epoch 8496/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6778 - val_loss: -0.5159\n",
            "Epoch 8497/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6647 - val_loss: -0.5174\n",
            "Epoch 8498/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6682 - val_loss: -0.5166\n",
            "Epoch 8499/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6651 - val_loss: -0.5177\n",
            "Epoch 8500/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6722 - val_loss: -0.5172\n",
            "Epoch 8501/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6715 - val_loss: -0.5174\n",
            "Epoch 8502/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6707 - val_loss: -0.5165\n",
            "Epoch 8503/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6721 - val_loss: -0.5174\n",
            "Epoch 8504/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6706 - val_loss: -0.5168\n",
            "Epoch 8505/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6674 - val_loss: -0.5171\n",
            "Epoch 8506/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6791 - val_loss: -0.5166\n",
            "Epoch 8507/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6659 - val_loss: -0.5161\n",
            "Epoch 8508/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6618 - val_loss: -0.5180\n",
            "Epoch 8509/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6662 - val_loss: -0.5156\n",
            "Epoch 8510/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6739 - val_loss: -0.5165\n",
            "Epoch 8511/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6600 - val_loss: -0.5178\n",
            "Epoch 8512/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6746 - val_loss: -0.5154\n",
            "Epoch 8513/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6762 - val_loss: -0.5170\n",
            "Epoch 8514/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6739 - val_loss: -0.5167\n",
            "Epoch 8515/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6725 - val_loss: -0.5169\n",
            "Epoch 8516/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6724 - val_loss: -0.5170\n",
            "Epoch 8517/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6762 - val_loss: -0.5165\n",
            "Epoch 8518/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6784 - val_loss: -0.5169\n",
            "Epoch 8519/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6645 - val_loss: -0.5166\n",
            "Epoch 8520/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6686 - val_loss: -0.5168\n",
            "Epoch 8521/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6739 - val_loss: -0.5164\n",
            "Epoch 8522/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6715 - val_loss: -0.5167\n",
            "Epoch 8523/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6713 - val_loss: -0.5170\n",
            "Epoch 8524/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6725 - val_loss: -0.5171\n",
            "Epoch 8525/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6720 - val_loss: -0.5171\n",
            "Epoch 8526/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6759 - val_loss: -0.5163\n",
            "Epoch 8527/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6739 - val_loss: -0.5175\n",
            "Epoch 8528/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6655 - val_loss: -0.5167\n",
            "Epoch 8529/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6589 - val_loss: -0.5174\n",
            "Epoch 8530/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6613 - val_loss: -0.5168\n",
            "Epoch 8531/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6632 - val_loss: -0.5183\n",
            "Epoch 8532/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6734 - val_loss: -0.5174\n",
            "Epoch 8533/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6716 - val_loss: -0.5170\n",
            "Epoch 8534/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6667 - val_loss: -0.5170\n",
            "Epoch 8535/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6754 - val_loss: -0.5166\n",
            "Epoch 8536/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6716 - val_loss: -0.5174\n",
            "Epoch 8537/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6675 - val_loss: -0.5172\n",
            "Epoch 8538/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6703 - val_loss: -0.5168\n",
            "Epoch 8539/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6749 - val_loss: -0.5169\n",
            "Epoch 8540/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6765 - val_loss: -0.5164\n",
            "Epoch 8541/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6694 - val_loss: -0.5168\n",
            "Epoch 8542/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6670 - val_loss: -0.5171\n",
            "Epoch 8543/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6734 - val_loss: -0.5170\n",
            "Epoch 8544/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6683 - val_loss: -0.5165\n",
            "Epoch 8545/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6594 - val_loss: -0.5180\n",
            "Epoch 8546/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6754 - val_loss: -0.5163\n",
            "Epoch 8547/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6704 - val_loss: -0.5161\n",
            "Epoch 8548/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6762 - val_loss: -0.5167\n",
            "Epoch 8549/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6676 - val_loss: -0.5173\n",
            "Epoch 8550/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6704 - val_loss: -0.5169\n",
            "Epoch 8551/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6642 - val_loss: -0.5172\n",
            "Epoch 8552/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6743 - val_loss: -0.5164\n",
            "Epoch 8553/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6694 - val_loss: -0.5169\n",
            "Epoch 8554/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6712 - val_loss: -0.5162\n",
            "Epoch 8555/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6695 - val_loss: -0.5167\n",
            "Epoch 8556/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6705 - val_loss: -0.5167\n",
            "Epoch 8557/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6565 - val_loss: -0.5163\n",
            "Epoch 8558/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6659 - val_loss: -0.5172\n",
            "Epoch 8559/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6778 - val_loss: -0.5160\n",
            "Epoch 8560/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6747 - val_loss: -0.5171\n",
            "Epoch 8561/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6660 - val_loss: -0.5167\n",
            "Epoch 8562/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6679 - val_loss: -0.5169\n",
            "Epoch 8563/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6780 - val_loss: -0.5168\n",
            "Epoch 8564/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6619 - val_loss: -0.5176\n",
            "Epoch 8565/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6726 - val_loss: -0.5166\n",
            "Epoch 8566/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6741 - val_loss: -0.5162\n",
            "Epoch 8567/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6760 - val_loss: -0.5168\n",
            "Epoch 8568/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6698 - val_loss: -0.5169\n",
            "Epoch 8569/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6743 - val_loss: -0.5168\n",
            "Epoch 8570/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6671 - val_loss: -0.5167\n",
            "Epoch 8571/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5170\n",
            "Epoch 8572/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6663 - val_loss: -0.5169\n",
            "Epoch 8573/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6754 - val_loss: -0.5172\n",
            "Epoch 8574/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6718 - val_loss: -0.5166\n",
            "Epoch 8575/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6642 - val_loss: -0.5175\n",
            "Epoch 8576/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6728 - val_loss: -0.5164\n",
            "Epoch 8577/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6657 - val_loss: -0.5172\n",
            "Epoch 8578/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6721 - val_loss: -0.5169\n",
            "Epoch 8579/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6677 - val_loss: -0.5169\n",
            "Epoch 8580/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6662 - val_loss: -0.5170\n",
            "Epoch 8581/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6711 - val_loss: -0.5168\n",
            "Epoch 8582/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6726 - val_loss: -0.5173\n",
            "Epoch 8583/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6731 - val_loss: -0.5169\n",
            "Epoch 8584/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6720 - val_loss: -0.5168\n",
            "Epoch 8585/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6731 - val_loss: -0.5168\n",
            "Epoch 8586/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6743 - val_loss: -0.5169\n",
            "Epoch 8587/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6750 - val_loss: -0.5169\n",
            "Epoch 8588/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6703 - val_loss: -0.5172\n",
            "Epoch 8589/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6713 - val_loss: -0.5175\n",
            "Epoch 8590/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6723 - val_loss: -0.5166\n",
            "Epoch 8591/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6707 - val_loss: -0.5167\n",
            "Epoch 8592/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6702 - val_loss: -0.5174\n",
            "Epoch 8593/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6751 - val_loss: -0.5168\n",
            "Epoch 8594/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5171\n",
            "Epoch 8595/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6670 - val_loss: -0.5170\n",
            "Epoch 8596/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6553 - val_loss: -0.5171\n",
            "Epoch 8597/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6743 - val_loss: -0.5170\n",
            "Epoch 8598/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6735 - val_loss: -0.5168\n",
            "Epoch 8599/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6664 - val_loss: -0.5170\n",
            "Epoch 8600/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6694 - val_loss: -0.5173\n",
            "Epoch 8601/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6697 - val_loss: -0.5172\n",
            "Epoch 8602/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6755 - val_loss: -0.5164\n",
            "Epoch 8603/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6627 - val_loss: -0.5167\n",
            "Epoch 8604/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6679 - val_loss: -0.5160\n",
            "Epoch 8605/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6735 - val_loss: -0.5163\n",
            "Epoch 8606/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6642 - val_loss: -0.5172\n",
            "Epoch 8607/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6746 - val_loss: -0.5163\n",
            "Epoch 8608/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6817 - val_loss: -0.5174\n",
            "Epoch 8609/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6731 - val_loss: -0.5157\n",
            "Epoch 8610/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6626 - val_loss: -0.5174\n",
            "Epoch 8611/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6708 - val_loss: -0.5161\n",
            "Epoch 8612/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6749 - val_loss: -0.5171\n",
            "Epoch 8613/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6672 - val_loss: -0.5168\n",
            "Epoch 8614/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6635 - val_loss: -0.5168\n",
            "Epoch 8615/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6632 - val_loss: -0.5169\n",
            "Epoch 8616/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6768 - val_loss: -0.5167\n",
            "Epoch 8617/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6728 - val_loss: -0.5169\n",
            "Epoch 8618/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6638 - val_loss: -0.5163\n",
            "Epoch 8619/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6747 - val_loss: -0.5165\n",
            "Epoch 8620/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6754 - val_loss: -0.5169\n",
            "Epoch 8621/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6675 - val_loss: -0.5168\n",
            "Epoch 8622/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6684 - val_loss: -0.5170\n",
            "Epoch 8623/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6681 - val_loss: -0.5173\n",
            "Epoch 8624/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6755 - val_loss: -0.5171\n",
            "Epoch 8625/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6736 - val_loss: -0.5168\n",
            "Epoch 8626/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6709 - val_loss: -0.5170\n",
            "Epoch 8627/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6750 - val_loss: -0.5161\n",
            "Epoch 8628/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6638 - val_loss: -0.5177\n",
            "Epoch 8629/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6575 - val_loss: -0.5171\n",
            "Epoch 8630/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6593 - val_loss: -0.5176\n",
            "Epoch 8631/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6682 - val_loss: -0.5174\n",
            "Epoch 8632/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6762 - val_loss: -0.5165\n",
            "Epoch 8633/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5177\n",
            "Epoch 8634/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6697 - val_loss: -0.5169\n",
            "Epoch 8635/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6752 - val_loss: -0.5166\n",
            "Epoch 8636/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6605 - val_loss: -0.5175\n",
            "Epoch 8637/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6652 - val_loss: -0.5176\n",
            "Epoch 8638/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6694 - val_loss: -0.5159\n",
            "Epoch 8639/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6657 - val_loss: -0.5172\n",
            "Epoch 8640/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6736 - val_loss: -0.5161\n",
            "Epoch 8641/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5163\n",
            "Epoch 8642/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6727 - val_loss: -0.5170\n",
            "Epoch 8643/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6666 - val_loss: -0.5172\n",
            "Epoch 8644/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5162\n",
            "Epoch 8645/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6682 - val_loss: -0.5171\n",
            "Epoch 8646/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6692 - val_loss: -0.5167\n",
            "Epoch 8647/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6685 - val_loss: -0.5167\n",
            "Epoch 8648/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6618 - val_loss: -0.5169\n",
            "Epoch 8649/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6769 - val_loss: -0.5167\n",
            "Epoch 8650/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6631 - val_loss: -0.5165\n",
            "Epoch 8651/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6583 - val_loss: -0.5170\n",
            "Epoch 8652/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6697 - val_loss: -0.5166\n",
            "Epoch 8653/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6681 - val_loss: -0.5169\n",
            "Epoch 8654/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6750 - val_loss: -0.5167\n",
            "Epoch 8655/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6648 - val_loss: -0.5169\n",
            "Epoch 8656/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6662 - val_loss: -0.5171\n",
            "Epoch 8657/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6773 - val_loss: -0.5170\n",
            "Epoch 8658/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6600 - val_loss: -0.5170\n",
            "Epoch 8659/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6569 - val_loss: -0.5173\n",
            "Epoch 8660/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6682 - val_loss: -0.5163\n",
            "Epoch 8661/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6718 - val_loss: -0.5165\n",
            "Epoch 8662/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5168\n",
            "Epoch 8663/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6746 - val_loss: -0.5166\n",
            "Epoch 8664/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6666 - val_loss: -0.5165\n",
            "Epoch 8665/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6696 - val_loss: -0.5162\n",
            "Epoch 8666/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6633 - val_loss: -0.5173\n",
            "Epoch 8667/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6710 - val_loss: -0.5160\n",
            "Epoch 8668/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6728 - val_loss: -0.5171\n",
            "Epoch 8669/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6767 - val_loss: -0.5161\n",
            "Epoch 8670/10000\n",
            "22/22 [==============================] - 1s 29ms/step - loss: -0.6745 - val_loss: -0.5162\n",
            "Epoch 8671/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6724 - val_loss: -0.5164\n",
            "Epoch 8672/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6739 - val_loss: -0.5164\n",
            "Epoch 8673/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6725 - val_loss: -0.5166\n",
            "Epoch 8674/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6628 - val_loss: -0.5168\n",
            "Epoch 8675/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6675 - val_loss: -0.5165\n",
            "Epoch 8676/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6686 - val_loss: -0.5147\n",
            "Epoch 8677/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6745 - val_loss: -0.5167\n",
            "Epoch 8678/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6710 - val_loss: -0.5162\n",
            "Epoch 8679/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6774 - val_loss: -0.5164\n",
            "Epoch 8680/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6770 - val_loss: -0.5166\n",
            "Epoch 8681/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6663 - val_loss: -0.5164\n",
            "Epoch 8682/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6755 - val_loss: -0.5169\n",
            "Epoch 8683/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6638 - val_loss: -0.5159\n",
            "Epoch 8684/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6762 - val_loss: -0.5167\n",
            "Epoch 8685/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6714 - val_loss: -0.5154\n",
            "Epoch 8686/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6593 - val_loss: -0.5164\n",
            "Epoch 8687/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6674 - val_loss: -0.5167\n",
            "Epoch 8688/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6819 - val_loss: -0.5164\n",
            "Epoch 8689/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6654 - val_loss: -0.5158\n",
            "Epoch 8690/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6745 - val_loss: -0.5166\n",
            "Epoch 8691/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6701 - val_loss: -0.5171\n",
            "Epoch 8692/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6675 - val_loss: -0.5164\n",
            "Epoch 8693/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6605 - val_loss: -0.5177\n",
            "Epoch 8694/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6773 - val_loss: -0.5161\n",
            "Epoch 8695/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6653 - val_loss: -0.5178\n",
            "Epoch 8696/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6769 - val_loss: -0.5157\n",
            "Epoch 8697/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6703 - val_loss: -0.5170\n",
            "Epoch 8698/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6703 - val_loss: -0.5168\n",
            "Epoch 8699/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6773 - val_loss: -0.5168\n",
            "Epoch 8700/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6603 - val_loss: -0.5174\n",
            "Epoch 8701/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6761 - val_loss: -0.5159\n",
            "Epoch 8702/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6801 - val_loss: -0.5169\n",
            "Epoch 8703/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5170\n",
            "Epoch 8704/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6722 - val_loss: -0.5164\n",
            "Epoch 8705/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6723 - val_loss: -0.5170\n",
            "Epoch 8706/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6725 - val_loss: -0.5167\n",
            "Epoch 8707/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6738 - val_loss: -0.5164\n",
            "Epoch 8708/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6719 - val_loss: -0.5162\n",
            "Epoch 8709/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6699 - val_loss: -0.5158\n",
            "Epoch 8710/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6653 - val_loss: -0.5167\n",
            "Epoch 8711/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6767 - val_loss: -0.5159\n",
            "Epoch 8712/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6696 - val_loss: -0.5166\n",
            "Epoch 8713/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6690 - val_loss: -0.5171\n",
            "Epoch 8714/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6665 - val_loss: -0.5161\n",
            "Epoch 8715/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6600 - val_loss: -0.5170\n",
            "Epoch 8716/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6778 - val_loss: -0.5163\n",
            "Epoch 8717/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6714 - val_loss: -0.5171\n",
            "Epoch 8718/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6723 - val_loss: -0.5165\n",
            "Epoch 8719/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6676 - val_loss: -0.5172\n",
            "Epoch 8720/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6726 - val_loss: -0.5160\n",
            "Epoch 8721/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6704 - val_loss: -0.5169\n",
            "Epoch 8722/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6703 - val_loss: -0.5163\n",
            "Epoch 8723/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6644 - val_loss: -0.5166\n",
            "Epoch 8724/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6793 - val_loss: -0.5157\n",
            "Epoch 8725/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6647 - val_loss: -0.5168\n",
            "Epoch 8726/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6769 - val_loss: -0.5160\n",
            "Epoch 8727/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6727 - val_loss: -0.5164\n",
            "Epoch 8728/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6808 - val_loss: -0.5160\n",
            "Epoch 8729/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6761 - val_loss: -0.5169\n",
            "Epoch 8730/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6704 - val_loss: -0.5168\n",
            "Epoch 8731/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6687 - val_loss: -0.5164\n",
            "Epoch 8732/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5157\n",
            "Epoch 8733/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6708 - val_loss: -0.5164\n",
            "Epoch 8734/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6693 - val_loss: -0.5160\n",
            "Epoch 8735/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6757 - val_loss: -0.5163\n",
            "Epoch 8736/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6745 - val_loss: -0.5168\n",
            "Epoch 8737/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5168\n",
            "Epoch 8738/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6727 - val_loss: -0.5167\n",
            "Epoch 8739/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6715 - val_loss: -0.5161\n",
            "Epoch 8740/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6658 - val_loss: -0.5168\n",
            "Epoch 8741/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6708 - val_loss: -0.5169\n",
            "Epoch 8742/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5162\n",
            "Epoch 8743/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6697 - val_loss: -0.5165\n",
            "Epoch 8744/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6817 - val_loss: -0.5161\n",
            "Epoch 8745/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6700 - val_loss: -0.5164\n",
            "Epoch 8746/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6679 - val_loss: -0.5165\n",
            "Epoch 8747/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6634 - val_loss: -0.5170\n",
            "Epoch 8748/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6698 - val_loss: -0.5164\n",
            "Epoch 8749/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6710 - val_loss: -0.5172\n",
            "Epoch 8750/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6739 - val_loss: -0.5167\n",
            "Epoch 8751/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6697 - val_loss: -0.5166\n",
            "Epoch 8752/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5164\n",
            "Epoch 8753/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6664 - val_loss: -0.5167\n",
            "Epoch 8754/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6686 - val_loss: -0.5160\n",
            "Epoch 8755/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6758 - val_loss: -0.5162\n",
            "Epoch 8756/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6731 - val_loss: -0.5165\n",
            "Epoch 8757/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6603 - val_loss: -0.5164\n",
            "Epoch 8758/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6768 - val_loss: -0.5163\n",
            "Epoch 8759/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6616 - val_loss: -0.5159\n",
            "Epoch 8760/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6655 - val_loss: -0.5168\n",
            "Epoch 8761/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6739 - val_loss: -0.5161\n",
            "Epoch 8762/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6765 - val_loss: -0.5162\n",
            "Epoch 8763/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6733 - val_loss: -0.5168\n",
            "Epoch 8764/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6778 - val_loss: -0.5158\n",
            "Epoch 8765/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6730 - val_loss: -0.5159\n",
            "Epoch 8766/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6761 - val_loss: -0.5161\n",
            "Epoch 8767/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6697 - val_loss: -0.5167\n",
            "Epoch 8768/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6789 - val_loss: -0.5157\n",
            "Epoch 8769/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6713 - val_loss: -0.5167\n",
            "Epoch 8770/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6723 - val_loss: -0.5159\n",
            "Epoch 8771/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6719 - val_loss: -0.5156\n",
            "Epoch 8772/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6777 - val_loss: -0.5157\n",
            "Epoch 8773/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6764 - val_loss: -0.5162\n",
            "Epoch 8774/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6625 - val_loss: -0.5169\n",
            "Epoch 8775/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6620 - val_loss: -0.5164\n",
            "Epoch 8776/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6560 - val_loss: -0.5161\n",
            "Epoch 8777/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6744 - val_loss: -0.5166\n",
            "Epoch 8778/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6648 - val_loss: -0.5173\n",
            "Epoch 8779/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6762 - val_loss: -0.5160\n",
            "Epoch 8780/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6752 - val_loss: -0.5163\n",
            "Epoch 8781/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6741 - val_loss: -0.5165\n",
            "Epoch 8782/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6781 - val_loss: -0.5163\n",
            "Epoch 8783/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6686 - val_loss: -0.5166\n",
            "Epoch 8784/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5163\n",
            "Epoch 8785/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6766 - val_loss: -0.5164\n",
            "Epoch 8786/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6769 - val_loss: -0.5163\n",
            "Epoch 8787/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6747 - val_loss: -0.5162\n",
            "Epoch 8788/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6768 - val_loss: -0.5163\n",
            "Epoch 8789/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6634 - val_loss: -0.5165\n",
            "Epoch 8790/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6687 - val_loss: -0.5165\n",
            "Epoch 8791/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6741 - val_loss: -0.5158\n",
            "Epoch 8792/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6701 - val_loss: -0.5170\n",
            "Epoch 8793/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6780 - val_loss: -0.5159\n",
            "Epoch 8794/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6694 - val_loss: -0.5169\n",
            "Epoch 8795/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6617 - val_loss: -0.5169\n",
            "Epoch 8796/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6685 - val_loss: -0.5172\n",
            "Epoch 8797/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6606 - val_loss: -0.5177\n",
            "Epoch 8798/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6759 - val_loss: -0.5163\n",
            "Epoch 8799/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6690 - val_loss: -0.5171\n",
            "Epoch 8800/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6681 - val_loss: -0.5176\n",
            "Epoch 8801/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6680 - val_loss: -0.5166\n",
            "Epoch 8802/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6704 - val_loss: -0.5173\n",
            "Epoch 8803/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6616 - val_loss: -0.5171\n",
            "Epoch 8804/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6728 - val_loss: -0.5169\n",
            "Epoch 8805/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6686 - val_loss: -0.5171\n",
            "Epoch 8806/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6766 - val_loss: -0.5164\n",
            "Epoch 8807/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6604 - val_loss: -0.5178\n",
            "Epoch 8808/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6625 - val_loss: -0.5171\n",
            "Epoch 8809/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6694 - val_loss: -0.5163\n",
            "Epoch 8810/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6698 - val_loss: -0.5166\n",
            "Epoch 8811/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6694 - val_loss: -0.5169\n",
            "Epoch 8812/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6727 - val_loss: -0.5171\n",
            "Epoch 8813/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6739 - val_loss: -0.5163\n",
            "Epoch 8814/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6707 - val_loss: -0.5167\n",
            "Epoch 8815/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6590 - val_loss: -0.5175\n",
            "Epoch 8816/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6757 - val_loss: -0.5162\n",
            "Epoch 8817/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6787 - val_loss: -0.5162\n",
            "Epoch 8818/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6665 - val_loss: -0.5172\n",
            "Epoch 8819/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6704 - val_loss: -0.5162\n",
            "Epoch 8820/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6795 - val_loss: -0.5157\n",
            "Epoch 8821/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5169\n",
            "Epoch 8822/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6633 - val_loss: -0.5165\n",
            "Epoch 8823/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6618 - val_loss: -0.5174\n",
            "Epoch 8824/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6728 - val_loss: -0.5157\n",
            "Epoch 8825/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6655 - val_loss: -0.5173\n",
            "Epoch 8826/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6701 - val_loss: -0.5163\n",
            "Epoch 8827/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6661 - val_loss: -0.5167\n",
            "Epoch 8828/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6778 - val_loss: -0.5163\n",
            "Epoch 8829/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6758 - val_loss: -0.5163\n",
            "Epoch 8830/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6753 - val_loss: -0.5162\n",
            "Epoch 8831/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6690 - val_loss: -0.5173\n",
            "Epoch 8832/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6706 - val_loss: -0.5164\n",
            "Epoch 8833/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5167\n",
            "Epoch 8834/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6735 - val_loss: -0.5161\n",
            "Epoch 8835/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6762 - val_loss: -0.5166\n",
            "Epoch 8836/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6818 - val_loss: -0.5163\n",
            "Epoch 8837/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6772 - val_loss: -0.5158\n",
            "Epoch 8838/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6704 - val_loss: -0.5159\n",
            "Epoch 8839/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6675 - val_loss: -0.5161\n",
            "Epoch 8840/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6788 - val_loss: -0.5164\n",
            "Epoch 8841/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6677 - val_loss: -0.5168\n",
            "Epoch 8842/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6777 - val_loss: -0.5156\n",
            "Epoch 8843/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6621 - val_loss: -0.5164\n",
            "Epoch 8844/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6734 - val_loss: -0.5163\n",
            "Epoch 8845/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6828 - val_loss: -0.5158\n",
            "Epoch 8846/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6625 - val_loss: -0.5163\n",
            "Epoch 8847/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6770 - val_loss: -0.5164\n",
            "Epoch 8848/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6754 - val_loss: -0.5155\n",
            "Epoch 8849/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6716 - val_loss: -0.5170\n",
            "Epoch 8850/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6732 - val_loss: -0.5152\n",
            "Epoch 8851/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6761 - val_loss: -0.5170\n",
            "Epoch 8852/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6749 - val_loss: -0.5164\n",
            "Epoch 8853/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6630 - val_loss: -0.5160\n",
            "Epoch 8854/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6760 - val_loss: -0.5160\n",
            "Epoch 8855/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6696 - val_loss: -0.5167\n",
            "Epoch 8856/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6644 - val_loss: -0.5162\n",
            "Epoch 8857/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6779 - val_loss: -0.5153\n",
            "Epoch 8858/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6738 - val_loss: -0.5165\n",
            "Epoch 8859/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6662 - val_loss: -0.5174\n",
            "Epoch 8860/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6712 - val_loss: -0.5163\n",
            "Epoch 8861/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6765 - val_loss: -0.5157\n",
            "Epoch 8862/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6765 - val_loss: -0.5165\n",
            "Epoch 8863/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6679 - val_loss: -0.5160\n",
            "Epoch 8864/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6782 - val_loss: -0.5156\n",
            "Epoch 8865/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6809 - val_loss: -0.5158\n",
            "Epoch 8866/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6691 - val_loss: -0.5169\n",
            "Epoch 8867/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6674 - val_loss: -0.5167\n",
            "Epoch 8868/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6794 - val_loss: -0.5160\n",
            "Epoch 8869/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6709 - val_loss: -0.5162\n",
            "Epoch 8870/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6655 - val_loss: -0.5169\n",
            "Epoch 8871/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6689 - val_loss: -0.5162\n",
            "Epoch 8872/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6777 - val_loss: -0.5168\n",
            "Epoch 8873/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6745 - val_loss: -0.5170\n",
            "Epoch 8874/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6660 - val_loss: -0.5169\n",
            "Epoch 8875/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6812 - val_loss: -0.5155\n",
            "Epoch 8876/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6678 - val_loss: -0.5167\n",
            "Epoch 8877/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5158\n",
            "Epoch 8878/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6565 - val_loss: -0.5179\n",
            "Epoch 8879/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5162\n",
            "Epoch 8880/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6734 - val_loss: -0.5160\n",
            "Epoch 8881/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6719 - val_loss: -0.5162\n",
            "Epoch 8882/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6755 - val_loss: -0.5166\n",
            "Epoch 8883/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6711 - val_loss: -0.5168\n",
            "Epoch 8884/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6649 - val_loss: -0.5171\n",
            "Epoch 8885/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5170\n",
            "Epoch 8886/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6600 - val_loss: -0.5161\n",
            "Epoch 8887/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6742 - val_loss: -0.5165\n",
            "Epoch 8888/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6583 - val_loss: -0.5162\n",
            "Epoch 8889/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6699 - val_loss: -0.5165\n",
            "Epoch 8890/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6660 - val_loss: -0.5161\n",
            "Epoch 8891/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6688 - val_loss: -0.5164\n",
            "Epoch 8892/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6790 - val_loss: -0.5155\n",
            "Epoch 8893/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6765 - val_loss: -0.5157\n",
            "Epoch 8894/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6608 - val_loss: -0.5170\n",
            "Epoch 8895/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6762 - val_loss: -0.5151\n",
            "Epoch 8896/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6693 - val_loss: -0.5159\n",
            "Epoch 8897/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6712 - val_loss: -0.5160\n",
            "Epoch 8898/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6679 - val_loss: -0.5166\n",
            "Epoch 8899/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6701 - val_loss: -0.5157\n",
            "Epoch 8900/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6746 - val_loss: -0.5163\n",
            "Epoch 8901/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6720 - val_loss: -0.5168\n",
            "Epoch 8902/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6728 - val_loss: -0.5161\n",
            "Epoch 8903/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6710 - val_loss: -0.5164\n",
            "Epoch 8904/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6695 - val_loss: -0.5164\n",
            "Epoch 8905/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6755 - val_loss: -0.5164\n",
            "Epoch 8906/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6685 - val_loss: -0.5159\n",
            "Epoch 8907/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6778 - val_loss: -0.5161\n",
            "Epoch 8908/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6633 - val_loss: -0.5170\n",
            "Epoch 8909/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6620 - val_loss: -0.5165\n",
            "Epoch 8910/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6751 - val_loss: -0.5165\n",
            "Epoch 8911/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6739 - val_loss: -0.5164\n",
            "Epoch 8912/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6781 - val_loss: -0.5159\n",
            "Epoch 8913/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6631 - val_loss: -0.5163\n",
            "Epoch 8914/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6602 - val_loss: -0.5162\n",
            "Epoch 8915/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5153\n",
            "Epoch 8916/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6663 - val_loss: -0.5167\n",
            "Epoch 8917/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6592 - val_loss: -0.5174\n",
            "Epoch 8918/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6752 - val_loss: -0.5152\n",
            "Epoch 8919/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6583 - val_loss: -0.5178\n",
            "Epoch 8920/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6791 - val_loss: -0.5163\n",
            "Epoch 8921/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6746 - val_loss: -0.5166\n",
            "Epoch 8922/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6730 - val_loss: -0.5164\n",
            "Epoch 8923/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6708 - val_loss: -0.5164\n",
            "Epoch 8924/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6772 - val_loss: -0.5164\n",
            "Epoch 8925/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6574 - val_loss: -0.5164\n",
            "Epoch 8926/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6718 - val_loss: -0.5162\n",
            "Epoch 8927/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6664 - val_loss: -0.5169\n",
            "Epoch 8928/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6824 - val_loss: -0.5161\n",
            "Epoch 8929/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6756 - val_loss: -0.5163\n",
            "Epoch 8930/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6687 - val_loss: -0.5169\n",
            "Epoch 8931/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6703 - val_loss: -0.5178\n",
            "Epoch 8932/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6734 - val_loss: -0.5165\n",
            "Epoch 8933/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6652 - val_loss: -0.5164\n",
            "Epoch 8934/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6715 - val_loss: -0.5163\n",
            "Epoch 8935/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6683 - val_loss: -0.5168\n",
            "Epoch 8936/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6692 - val_loss: -0.5172\n",
            "Epoch 8937/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6696 - val_loss: -0.5159\n",
            "Epoch 8938/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6704 - val_loss: -0.5175\n",
            "Epoch 8939/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6614 - val_loss: -0.5162\n",
            "Epoch 8940/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6697 - val_loss: -0.5168\n",
            "Epoch 8941/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6806 - val_loss: -0.5160\n",
            "Epoch 8942/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6766 - val_loss: -0.5161\n",
            "Epoch 8943/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6757 - val_loss: -0.5170\n",
            "Epoch 8944/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6680 - val_loss: -0.5170\n",
            "Epoch 8945/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6724 - val_loss: -0.5157\n",
            "Epoch 8946/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6725 - val_loss: -0.5164\n",
            "Epoch 8947/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6767 - val_loss: -0.5157\n",
            "Epoch 8948/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6740 - val_loss: -0.5164\n",
            "Epoch 8949/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6727 - val_loss: -0.5162\n",
            "Epoch 8950/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6677 - val_loss: -0.5167\n",
            "Epoch 8951/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6679 - val_loss: -0.5162\n",
            "Epoch 8952/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6693 - val_loss: -0.5157\n",
            "Epoch 8953/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6698 - val_loss: -0.5168\n",
            "Epoch 8954/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6692 - val_loss: -0.5157\n",
            "Epoch 8955/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6763 - val_loss: -0.5168\n",
            "Epoch 8956/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6724 - val_loss: -0.5168\n",
            "Epoch 8957/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6736 - val_loss: -0.5158\n",
            "Epoch 8958/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6781 - val_loss: -0.5167\n",
            "Epoch 8959/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6704 - val_loss: -0.5156\n",
            "Epoch 8960/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6641 - val_loss: -0.5170\n",
            "Epoch 8961/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6677 - val_loss: -0.5161\n",
            "Epoch 8962/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6734 - val_loss: -0.5169\n",
            "Epoch 8963/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6735 - val_loss: -0.5163\n",
            "Epoch 8964/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6705 - val_loss: -0.5159\n",
            "Epoch 8965/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6723 - val_loss: -0.5165\n",
            "Epoch 8966/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6733 - val_loss: -0.5165\n",
            "Epoch 8967/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6687 - val_loss: -0.5161\n",
            "Epoch 8968/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6646 - val_loss: -0.5176\n",
            "Epoch 8969/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6692 - val_loss: -0.5167\n",
            "Epoch 8970/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6763 - val_loss: -0.5168\n",
            "Epoch 8971/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6775 - val_loss: -0.5164\n",
            "Epoch 8972/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6714 - val_loss: -0.5162\n",
            "Epoch 8973/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6750 - val_loss: -0.5162\n",
            "Epoch 8974/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6646 - val_loss: -0.5154\n",
            "Epoch 8975/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6738 - val_loss: -0.5167\n",
            "Epoch 8976/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6744 - val_loss: -0.5156\n",
            "Epoch 8977/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6676 - val_loss: -0.5168\n",
            "Epoch 8978/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6664 - val_loss: -0.5170\n",
            "Epoch 8979/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6733 - val_loss: -0.5163\n",
            "Epoch 8980/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6713 - val_loss: -0.5160\n",
            "Epoch 8981/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6716 - val_loss: -0.5169\n",
            "Epoch 8982/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6648 - val_loss: -0.5168\n",
            "Epoch 8983/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6681 - val_loss: -0.5162\n",
            "Epoch 8984/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6685 - val_loss: -0.5166\n",
            "Epoch 8985/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6695 - val_loss: -0.5158\n",
            "Epoch 8986/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6730 - val_loss: -0.5165\n",
            "Epoch 8987/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6695 - val_loss: -0.5158\n",
            "Epoch 8988/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6708 - val_loss: -0.5162\n",
            "Epoch 8989/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6744 - val_loss: -0.5161\n",
            "Epoch 8990/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6704 - val_loss: -0.5163\n",
            "Epoch 8991/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6748 - val_loss: -0.5161\n",
            "Epoch 8992/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6717 - val_loss: -0.5164\n",
            "Epoch 8993/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6715 - val_loss: -0.5158\n",
            "Epoch 8994/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6563 - val_loss: -0.5169\n",
            "Epoch 8995/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6692 - val_loss: -0.5164\n",
            "Epoch 8996/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6642 - val_loss: -0.5163\n",
            "Epoch 8997/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6739 - val_loss: -0.5161\n",
            "Epoch 8998/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6680 - val_loss: -0.5167\n",
            "Epoch 8999/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6766 - val_loss: -0.5162\n",
            "Epoch 9000/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6672 - val_loss: -0.5161\n",
            "Epoch 9001/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6662 - val_loss: -0.5158\n",
            "Epoch 9002/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6745 - val_loss: -0.5172\n",
            "Epoch 9003/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6643 - val_loss: -0.5161\n",
            "Epoch 9004/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6703 - val_loss: -0.5160\n",
            "Epoch 9005/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6724 - val_loss: -0.5170\n",
            "Epoch 9006/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6700 - val_loss: -0.5163\n",
            "Epoch 9007/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6613 - val_loss: -0.5171\n",
            "Epoch 9008/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6788 - val_loss: -0.5160\n",
            "Epoch 9009/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6809 - val_loss: -0.5164\n",
            "Epoch 9010/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6741 - val_loss: -0.5163\n",
            "Epoch 9011/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6701 - val_loss: -0.5160\n",
            "Epoch 9012/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6764 - val_loss: -0.5170\n",
            "Epoch 9013/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6683 - val_loss: -0.5160\n",
            "Epoch 9014/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6745 - val_loss: -0.5163\n",
            "Epoch 9015/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6732 - val_loss: -0.5164\n",
            "Epoch 9016/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6762 - val_loss: -0.5154\n",
            "Epoch 9017/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6699 - val_loss: -0.5170\n",
            "Epoch 9018/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6618 - val_loss: -0.5166\n",
            "Epoch 9019/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6707 - val_loss: -0.5165\n",
            "Epoch 9020/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6717 - val_loss: -0.5160\n",
            "Epoch 9021/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6677 - val_loss: -0.5161\n",
            "Epoch 9022/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6695 - val_loss: -0.5160\n",
            "Epoch 9023/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6615 - val_loss: -0.5164\n",
            "Epoch 9024/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6724 - val_loss: -0.5156\n",
            "Epoch 9025/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6812 - val_loss: -0.5160\n",
            "Epoch 9026/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6833 - val_loss: -0.5155\n",
            "Epoch 9027/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6795 - val_loss: -0.5162\n",
            "Epoch 9028/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6700 - val_loss: -0.5161\n",
            "Epoch 9029/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6791 - val_loss: -0.5162\n",
            "Epoch 9030/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6752 - val_loss: -0.5160\n",
            "Epoch 9031/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6737 - val_loss: -0.5169\n",
            "Epoch 9032/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6681 - val_loss: -0.5163\n",
            "Epoch 9033/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6676 - val_loss: -0.5160\n",
            "Epoch 9034/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6744 - val_loss: -0.5155\n",
            "Epoch 9035/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6759 - val_loss: -0.5156\n",
            "Epoch 9036/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6699 - val_loss: -0.5161\n",
            "Epoch 9037/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6772 - val_loss: -0.5158\n",
            "Epoch 9038/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6678 - val_loss: -0.5164\n",
            "Epoch 9039/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6745 - val_loss: -0.5163\n",
            "Epoch 9040/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6694 - val_loss: -0.5166\n",
            "Epoch 9041/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6765 - val_loss: -0.5162\n",
            "Epoch 9042/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6709 - val_loss: -0.5159\n",
            "Epoch 9043/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6784 - val_loss: -0.5152\n",
            "Epoch 9044/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6718 - val_loss: -0.5158\n",
            "Epoch 9045/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6624 - val_loss: -0.5158\n",
            "Epoch 9046/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6776 - val_loss: -0.5160\n",
            "Epoch 9047/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6651 - val_loss: -0.5167\n",
            "Epoch 9048/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6711 - val_loss: -0.5147\n",
            "Epoch 9049/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6772 - val_loss: -0.5155\n",
            "Epoch 9050/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6750 - val_loss: -0.5159\n",
            "Epoch 9051/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6693 - val_loss: -0.5162\n",
            "Epoch 9052/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6738 - val_loss: -0.5160\n",
            "Epoch 9053/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6680 - val_loss: -0.5154\n",
            "Epoch 9054/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6676 - val_loss: -0.5167\n",
            "Epoch 9055/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6756 - val_loss: -0.5154\n",
            "Epoch 9056/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6758 - val_loss: -0.5160\n",
            "Epoch 9057/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6738 - val_loss: -0.5156\n",
            "Epoch 9058/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6612 - val_loss: -0.5173\n",
            "Epoch 9059/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6703 - val_loss: -0.5149\n",
            "Epoch 9060/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6721 - val_loss: -0.5164\n",
            "Epoch 9061/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6735 - val_loss: -0.5154\n",
            "Epoch 9062/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6686 - val_loss: -0.5160\n",
            "Epoch 9063/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6706 - val_loss: -0.5153\n",
            "Epoch 9064/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6683 - val_loss: -0.5161\n",
            "Epoch 9065/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6720 - val_loss: -0.5155\n",
            "Epoch 9066/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6715 - val_loss: -0.5161\n",
            "Epoch 9067/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6741 - val_loss: -0.5159\n",
            "Epoch 9068/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6723 - val_loss: -0.5150\n",
            "Epoch 9069/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6626 - val_loss: -0.5158\n",
            "Epoch 9070/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6564 - val_loss: -0.5161\n",
            "Epoch 9071/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6580 - val_loss: -0.5162\n",
            "Epoch 9072/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6776 - val_loss: -0.5155\n",
            "Epoch 9073/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6631 - val_loss: -0.5162\n",
            "Epoch 9074/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6747 - val_loss: -0.5162\n",
            "Epoch 9075/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6737 - val_loss: -0.5152\n",
            "Epoch 9076/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6703 - val_loss: -0.5155\n",
            "Epoch 9077/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6693 - val_loss: -0.5160\n",
            "Epoch 9078/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6699 - val_loss: -0.5149\n",
            "Epoch 9079/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6743 - val_loss: -0.5162\n",
            "Epoch 9080/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6618 - val_loss: -0.5162\n",
            "Epoch 9081/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6739 - val_loss: -0.5158\n",
            "Epoch 9082/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6788 - val_loss: -0.5161\n",
            "Epoch 9083/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6634 - val_loss: -0.5157\n",
            "Epoch 9084/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6722 - val_loss: -0.5154\n",
            "Epoch 9085/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6798 - val_loss: -0.5157\n",
            "Epoch 9086/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6619 - val_loss: -0.5150\n",
            "Epoch 9087/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6634 - val_loss: -0.5169\n",
            "Epoch 9088/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6670 - val_loss: -0.5166\n",
            "Epoch 9089/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6762 - val_loss: -0.5154\n",
            "Epoch 9090/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6773 - val_loss: -0.5159\n",
            "Epoch 9091/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6740 - val_loss: -0.5155\n",
            "Epoch 9092/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5162\n",
            "Epoch 9093/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6694 - val_loss: -0.5161\n",
            "Epoch 9094/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6685 - val_loss: -0.5144\n",
            "Epoch 9095/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6732 - val_loss: -0.5155\n",
            "Epoch 9096/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6766 - val_loss: -0.5158\n",
            "Epoch 9097/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6685 - val_loss: -0.5156\n",
            "Epoch 9098/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6739 - val_loss: -0.5160\n",
            "Epoch 9099/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6711 - val_loss: -0.5162\n",
            "Epoch 9100/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6626 - val_loss: -0.5159\n",
            "Epoch 9101/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6762 - val_loss: -0.5159\n",
            "Epoch 9102/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6764 - val_loss: -0.5162\n",
            "Epoch 9103/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6769 - val_loss: -0.5154\n",
            "Epoch 9104/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6708 - val_loss: -0.5165\n",
            "Epoch 9105/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6780 - val_loss: -0.5150\n",
            "Epoch 9106/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6812 - val_loss: -0.5155\n",
            "Epoch 9107/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6681 - val_loss: -0.5161\n",
            "Epoch 9108/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6762 - val_loss: -0.5159\n",
            "Epoch 9109/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6765 - val_loss: -0.5150\n",
            "Epoch 9110/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6726 - val_loss: -0.5160\n",
            "Epoch 9111/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5166\n",
            "Epoch 9112/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6803 - val_loss: -0.5155\n",
            "Epoch 9113/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6690 - val_loss: -0.5161\n",
            "Epoch 9114/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6715 - val_loss: -0.5157\n",
            "Epoch 9115/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6760 - val_loss: -0.5164\n",
            "Epoch 9116/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6678 - val_loss: -0.5149\n",
            "Epoch 9117/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6780 - val_loss: -0.5160\n",
            "Epoch 9118/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6789 - val_loss: -0.5154\n",
            "Epoch 9119/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6539 - val_loss: -0.5165\n",
            "Epoch 9120/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6686 - val_loss: -0.5161\n",
            "Epoch 9121/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6842 - val_loss: -0.5151\n",
            "Epoch 9122/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6731 - val_loss: -0.5164\n",
            "Epoch 9123/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6707 - val_loss: -0.5157\n",
            "Epoch 9124/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6649 - val_loss: -0.5152\n",
            "Epoch 9125/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6678 - val_loss: -0.5163\n",
            "Epoch 9126/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6675 - val_loss: -0.5156\n",
            "Epoch 9127/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6695 - val_loss: -0.5150\n",
            "Epoch 9128/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6710 - val_loss: -0.5162\n",
            "Epoch 9129/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6799 - val_loss: -0.5156\n",
            "Epoch 9130/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5165\n",
            "Epoch 9131/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6707 - val_loss: -0.5156\n",
            "Epoch 9132/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6740 - val_loss: -0.5152\n",
            "Epoch 9133/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6716 - val_loss: -0.5152\n",
            "Epoch 9134/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6744 - val_loss: -0.5159\n",
            "Epoch 9135/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6626 - val_loss: -0.5164\n",
            "Epoch 9136/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6675 - val_loss: -0.5165\n",
            "Epoch 9137/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6629 - val_loss: -0.5153\n",
            "Epoch 9138/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6708 - val_loss: -0.5153\n",
            "Epoch 9139/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6727 - val_loss: -0.5168\n",
            "Epoch 9140/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6750 - val_loss: -0.5160\n",
            "Epoch 9141/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6742 - val_loss: -0.5159\n",
            "Epoch 9142/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6632 - val_loss: -0.5162\n",
            "Epoch 9143/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6751 - val_loss: -0.5158\n",
            "Epoch 9144/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6676 - val_loss: -0.5166\n",
            "Epoch 9145/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6746 - val_loss: -0.5159\n",
            "Epoch 9146/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6693 - val_loss: -0.5158\n",
            "Epoch 9147/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6741 - val_loss: -0.5156\n",
            "Epoch 9148/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6690 - val_loss: -0.5170\n",
            "Epoch 9149/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6677 - val_loss: -0.5164\n",
            "Epoch 9150/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6725 - val_loss: -0.5166\n",
            "Epoch 9151/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6694 - val_loss: -0.5155\n",
            "Epoch 9152/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6692 - val_loss: -0.5162\n",
            "Epoch 9153/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6709 - val_loss: -0.5168\n",
            "Epoch 9154/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6786 - val_loss: -0.5151\n",
            "Epoch 9155/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6761 - val_loss: -0.5168\n",
            "Epoch 9156/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6691 - val_loss: -0.5156\n",
            "Epoch 9157/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6694 - val_loss: -0.5163\n",
            "Epoch 9158/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5158\n",
            "Epoch 9159/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6695 - val_loss: -0.5150\n",
            "Epoch 9160/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6751 - val_loss: -0.5160\n",
            "Epoch 9161/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6701 - val_loss: -0.5153\n",
            "Epoch 9162/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6629 - val_loss: -0.5172\n",
            "Epoch 9163/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6740 - val_loss: -0.5159\n",
            "Epoch 9164/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6774 - val_loss: -0.5162\n",
            "Epoch 9165/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6746 - val_loss: -0.5154\n",
            "Epoch 9166/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5159\n",
            "Epoch 9167/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6708 - val_loss: -0.5162\n",
            "Epoch 9168/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6791 - val_loss: -0.5154\n",
            "Epoch 9169/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6738 - val_loss: -0.5155\n",
            "Epoch 9170/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6795 - val_loss: -0.5162\n",
            "Epoch 9171/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6741 - val_loss: -0.5157\n",
            "Epoch 9172/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6728 - val_loss: -0.5164\n",
            "Epoch 9173/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6669 - val_loss: -0.5160\n",
            "Epoch 9174/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6656 - val_loss: -0.5164\n",
            "Epoch 9175/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5153\n",
            "Epoch 9176/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6678 - val_loss: -0.5175\n",
            "Epoch 9177/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6775 - val_loss: -0.5157\n",
            "Epoch 9178/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6729 - val_loss: -0.5164\n",
            "Epoch 9179/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6702 - val_loss: -0.5163\n",
            "Epoch 9180/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6673 - val_loss: -0.5159\n",
            "Epoch 9181/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6715 - val_loss: -0.5159\n",
            "Epoch 9182/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6756 - val_loss: -0.5160\n",
            "Epoch 9183/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6665 - val_loss: -0.5160\n",
            "Epoch 9184/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5154\n",
            "Epoch 9185/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6751 - val_loss: -0.5158\n",
            "Epoch 9186/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6812 - val_loss: -0.5155\n",
            "Epoch 9187/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6719 - val_loss: -0.5158\n",
            "Epoch 9188/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6763 - val_loss: -0.5153\n",
            "Epoch 9189/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6708 - val_loss: -0.5162\n",
            "Epoch 9190/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6743 - val_loss: -0.5151\n",
            "Epoch 9191/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6685 - val_loss: -0.5159\n",
            "Epoch 9192/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6768 - val_loss: -0.5159\n",
            "Epoch 9193/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6776 - val_loss: -0.5155\n",
            "Epoch 9194/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6702 - val_loss: -0.5161\n",
            "Epoch 9195/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6712 - val_loss: -0.5162\n",
            "Epoch 9196/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5154\n",
            "Epoch 9197/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6759 - val_loss: -0.5160\n",
            "Epoch 9198/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6634 - val_loss: -0.5157\n",
            "Epoch 9199/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6694 - val_loss: -0.5164\n",
            "Epoch 9200/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6761 - val_loss: -0.5157\n",
            "Epoch 9201/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6717 - val_loss: -0.5159\n",
            "Epoch 9202/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6806 - val_loss: -0.5155\n",
            "Epoch 9203/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6662 - val_loss: -0.5159\n",
            "Epoch 9204/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6726 - val_loss: -0.5161\n",
            "Epoch 9205/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5161\n",
            "Epoch 9206/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6770 - val_loss: -0.5147\n",
            "Epoch 9207/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6679 - val_loss: -0.5171\n",
            "Epoch 9208/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5158\n",
            "Epoch 9209/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6710 - val_loss: -0.5156\n",
            "Epoch 9210/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6776 - val_loss: -0.5150\n",
            "Epoch 9211/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6752 - val_loss: -0.5154\n",
            "Epoch 9212/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6806 - val_loss: -0.5152\n",
            "Epoch 9213/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6721 - val_loss: -0.5153\n",
            "Epoch 9214/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6827 - val_loss: -0.5159\n",
            "Epoch 9215/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6739 - val_loss: -0.5160\n",
            "Epoch 9216/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6615 - val_loss: -0.5167\n",
            "Epoch 9217/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6798 - val_loss: -0.5150\n",
            "Epoch 9218/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6748 - val_loss: -0.5159\n",
            "Epoch 9219/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6647 - val_loss: -0.5159\n",
            "Epoch 9220/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6593 - val_loss: -0.5163\n",
            "Epoch 9221/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6814 - val_loss: -0.5153\n",
            "Epoch 9222/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6794 - val_loss: -0.5163\n",
            "Epoch 9223/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6678 - val_loss: -0.5158\n",
            "Epoch 9224/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6805 - val_loss: -0.5153\n",
            "Epoch 9225/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6821 - val_loss: -0.5161\n",
            "Epoch 9226/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6713 - val_loss: -0.5165\n",
            "Epoch 9227/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6755 - val_loss: -0.5155\n",
            "Epoch 9228/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6661 - val_loss: -0.5160\n",
            "Epoch 9229/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6757 - val_loss: -0.5160\n",
            "Epoch 9230/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6745 - val_loss: -0.5155\n",
            "Epoch 9231/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6782 - val_loss: -0.5162\n",
            "Epoch 9232/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6716 - val_loss: -0.5158\n",
            "Epoch 9233/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6749 - val_loss: -0.5162\n",
            "Epoch 9234/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6737 - val_loss: -0.5163\n",
            "Epoch 9235/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6795 - val_loss: -0.5159\n",
            "Epoch 9236/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6734 - val_loss: -0.5162\n",
            "Epoch 9237/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6730 - val_loss: -0.5155\n",
            "Epoch 9238/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6757 - val_loss: -0.5160\n",
            "Epoch 9239/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6851 - val_loss: -0.5151\n",
            "Epoch 9240/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6706 - val_loss: -0.5161\n",
            "Epoch 9241/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6739 - val_loss: -0.5157\n",
            "Epoch 9242/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6711 - val_loss: -0.5165\n",
            "Epoch 9243/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6632 - val_loss: -0.5170\n",
            "Epoch 9244/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6731 - val_loss: -0.5157\n",
            "Epoch 9245/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6788 - val_loss: -0.5161\n",
            "Epoch 9246/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6723 - val_loss: -0.5154\n",
            "Epoch 9247/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6581 - val_loss: -0.5168\n",
            "Epoch 9248/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6743 - val_loss: -0.5160\n",
            "Epoch 9249/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6606 - val_loss: -0.5139\n",
            "Epoch 9250/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6777 - val_loss: -0.5154\n",
            "Epoch 9251/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6715 - val_loss: -0.5162\n",
            "Epoch 9252/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6707 - val_loss: -0.5155\n",
            "Epoch 9253/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6679 - val_loss: -0.5163\n",
            "Epoch 9254/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6738 - val_loss: -0.5159\n",
            "Epoch 9255/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5165\n",
            "Epoch 9256/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6750 - val_loss: -0.5159\n",
            "Epoch 9257/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6722 - val_loss: -0.5160\n",
            "Epoch 9258/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6807 - val_loss: -0.5152\n",
            "Epoch 9259/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6819 - val_loss: -0.5160\n",
            "Epoch 9260/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6712 - val_loss: -0.5158\n",
            "Epoch 9261/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6774 - val_loss: -0.5155\n",
            "Epoch 9262/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6677 - val_loss: -0.5158\n",
            "Epoch 9263/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6750 - val_loss: -0.5153\n",
            "Epoch 9264/10000\n",
            "22/22 [==============================] - 1s 34ms/step - loss: -0.6675 - val_loss: -0.5155\n",
            "Epoch 9265/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6661 - val_loss: -0.5156\n",
            "Epoch 9266/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6802 - val_loss: -0.5163\n",
            "Epoch 9267/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6804 - val_loss: -0.5160\n",
            "Epoch 9268/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6731 - val_loss: -0.5162\n",
            "Epoch 9269/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6567 - val_loss: -0.5156\n",
            "Epoch 9270/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6775 - val_loss: -0.5156\n",
            "Epoch 9271/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6692 - val_loss: -0.5156\n",
            "Epoch 9272/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6774 - val_loss: -0.5153\n",
            "Epoch 9273/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6721 - val_loss: -0.5157\n",
            "Epoch 9274/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6709 - val_loss: -0.5151\n",
            "Epoch 9275/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6738 - val_loss: -0.5161\n",
            "Epoch 9276/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6784 - val_loss: -0.5156\n",
            "Epoch 9277/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6656 - val_loss: -0.5163\n",
            "Epoch 9278/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6735 - val_loss: -0.5147\n",
            "Epoch 9279/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6684 - val_loss: -0.5149\n",
            "Epoch 9280/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6789 - val_loss: -0.5156\n",
            "Epoch 9281/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6676 - val_loss: -0.5156\n",
            "Epoch 9282/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6740 - val_loss: -0.5155\n",
            "Epoch 9283/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6744 - val_loss: -0.5162\n",
            "Epoch 9284/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6676 - val_loss: -0.5160\n",
            "Epoch 9285/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6787 - val_loss: -0.5153\n",
            "Epoch 9286/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6766 - val_loss: -0.5156\n",
            "Epoch 9287/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6782 - val_loss: -0.5160\n",
            "Epoch 9288/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6736 - val_loss: -0.5156\n",
            "Epoch 9289/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6731 - val_loss: -0.5156\n",
            "Epoch 9290/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6807 - val_loss: -0.5157\n",
            "Epoch 9291/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6778 - val_loss: -0.5158\n",
            "Epoch 9292/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6673 - val_loss: -0.5166\n",
            "Epoch 9293/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6782 - val_loss: -0.5155\n",
            "Epoch 9294/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6642 - val_loss: -0.5151\n",
            "Epoch 9295/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6593 - val_loss: -0.5160\n",
            "Epoch 9296/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6788 - val_loss: -0.5155\n",
            "Epoch 9297/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6809 - val_loss: -0.5154\n",
            "Epoch 9298/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6701 - val_loss: -0.5147\n",
            "Epoch 9299/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6661 - val_loss: -0.5168\n",
            "Epoch 9300/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5152\n",
            "Epoch 9301/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6806 - val_loss: -0.5155\n",
            "Epoch 9302/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6760 - val_loss: -0.5156\n",
            "Epoch 9303/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6792 - val_loss: -0.5160\n",
            "Epoch 9304/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6763 - val_loss: -0.5151\n",
            "Epoch 9305/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6760 - val_loss: -0.5164\n",
            "Epoch 9306/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6770 - val_loss: -0.5150\n",
            "Epoch 9307/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6723 - val_loss: -0.5154\n",
            "Epoch 9308/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6652 - val_loss: -0.5163\n",
            "Epoch 9309/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6775 - val_loss: -0.5157\n",
            "Epoch 9310/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6534 - val_loss: -0.5148\n",
            "Epoch 9311/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6730 - val_loss: -0.5150\n",
            "Epoch 9312/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6723 - val_loss: -0.5158\n",
            "Epoch 9313/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6792 - val_loss: -0.5152\n",
            "Epoch 9314/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6732 - val_loss: -0.5153\n",
            "Epoch 9315/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6741 - val_loss: -0.5163\n",
            "Epoch 9316/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6764 - val_loss: -0.5158\n",
            "Epoch 9317/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6732 - val_loss: -0.5151\n",
            "Epoch 9318/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6735 - val_loss: -0.5157\n",
            "Epoch 9319/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6651 - val_loss: -0.5165\n",
            "Epoch 9320/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6694 - val_loss: -0.5148\n",
            "Epoch 9321/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6763 - val_loss: -0.5160\n",
            "Epoch 9322/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6710 - val_loss: -0.5158\n",
            "Epoch 9323/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6682 - val_loss: -0.5159\n",
            "Epoch 9324/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6789 - val_loss: -0.5157\n",
            "Epoch 9325/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6763 - val_loss: -0.5157\n",
            "Epoch 9326/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5158\n",
            "Epoch 9327/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6622 - val_loss: -0.5150\n",
            "Epoch 9328/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6654 - val_loss: -0.5157\n",
            "Epoch 9329/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6798 - val_loss: -0.5156\n",
            "Epoch 9330/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6754 - val_loss: -0.5156\n",
            "Epoch 9331/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6701 - val_loss: -0.5161\n",
            "Epoch 9332/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6715 - val_loss: -0.5149\n",
            "Epoch 9333/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6583 - val_loss: -0.5171\n",
            "Epoch 9334/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6740 - val_loss: -0.5156\n",
            "Epoch 9335/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6800 - val_loss: -0.5158\n",
            "Epoch 9336/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6742 - val_loss: -0.5157\n",
            "Epoch 9337/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6720 - val_loss: -0.5163\n",
            "Epoch 9338/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6754 - val_loss: -0.5156\n",
            "Epoch 9339/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6728 - val_loss: -0.5159\n",
            "Epoch 9340/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6784 - val_loss: -0.5158\n",
            "Epoch 9341/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6794 - val_loss: -0.5152\n",
            "Epoch 9342/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6760 - val_loss: -0.5148\n",
            "Epoch 9343/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6726 - val_loss: -0.5158\n",
            "Epoch 9344/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6775 - val_loss: -0.5158\n",
            "Epoch 9345/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6833 - val_loss: -0.5157\n",
            "Epoch 9346/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6769 - val_loss: -0.5158\n",
            "Epoch 9347/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6777 - val_loss: -0.5156\n",
            "Epoch 9348/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6697 - val_loss: -0.5162\n",
            "Epoch 9349/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6743 - val_loss: -0.5156\n",
            "Epoch 9350/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6787 - val_loss: -0.5157\n",
            "Epoch 9351/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6762 - val_loss: -0.5164\n",
            "Epoch 9352/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6729 - val_loss: -0.5154\n",
            "Epoch 9353/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6739 - val_loss: -0.5158\n",
            "Epoch 9354/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6822 - val_loss: -0.5159\n",
            "Epoch 9355/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6715 - val_loss: -0.5160\n",
            "Epoch 9356/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6799 - val_loss: -0.5159\n",
            "Epoch 9357/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6749 - val_loss: -0.5162\n",
            "Epoch 9358/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6698 - val_loss: -0.5160\n",
            "Epoch 9359/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6723 - val_loss: -0.5156\n",
            "Epoch 9360/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6747 - val_loss: -0.5162\n",
            "Epoch 9361/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6713 - val_loss: -0.5161\n",
            "Epoch 9362/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6650 - val_loss: -0.5159\n",
            "Epoch 9363/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6785 - val_loss: -0.5163\n",
            "Epoch 9364/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6847 - val_loss: -0.5156\n",
            "Epoch 9365/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6682 - val_loss: -0.5157\n",
            "Epoch 9366/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6743 - val_loss: -0.5159\n",
            "Epoch 9367/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6669 - val_loss: -0.5162\n",
            "Epoch 9368/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6782 - val_loss: -0.5151\n",
            "Epoch 9369/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6679 - val_loss: -0.5168\n",
            "Epoch 9370/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6759 - val_loss: -0.5159\n",
            "Epoch 9371/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6686 - val_loss: -0.5157\n",
            "Epoch 9372/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6770 - val_loss: -0.5157\n",
            "Epoch 9373/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6773 - val_loss: -0.5156\n",
            "Epoch 9374/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6684 - val_loss: -0.5152\n",
            "Epoch 9375/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6769 - val_loss: -0.5157\n",
            "Epoch 9376/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6822 - val_loss: -0.5157\n",
            "Epoch 9377/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6694 - val_loss: -0.5163\n",
            "Epoch 9378/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6748 - val_loss: -0.5163\n",
            "Epoch 9379/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6682 - val_loss: -0.5151\n",
            "Epoch 9380/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6830 - val_loss: -0.5158\n",
            "Epoch 9381/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6666 - val_loss: -0.5155\n",
            "Epoch 9382/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6797 - val_loss: -0.5158\n",
            "Epoch 9383/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6790 - val_loss: -0.5155\n",
            "Epoch 9384/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6792 - val_loss: -0.5154\n",
            "Epoch 9385/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6754 - val_loss: -0.5161\n",
            "Epoch 9386/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6730 - val_loss: -0.5157\n",
            "Epoch 9387/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6730 - val_loss: -0.5167\n",
            "Epoch 9388/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6670 - val_loss: -0.5169\n",
            "Epoch 9389/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6666 - val_loss: -0.5162\n",
            "Epoch 9390/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6748 - val_loss: -0.5151\n",
            "Epoch 9391/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6724 - val_loss: -0.5160\n",
            "Epoch 9392/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6788 - val_loss: -0.5151\n",
            "Epoch 9393/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6782 - val_loss: -0.5161\n",
            "Epoch 9394/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6769 - val_loss: -0.5153\n",
            "Epoch 9395/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6757 - val_loss: -0.5155\n",
            "Epoch 9396/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6745 - val_loss: -0.5155\n",
            "Epoch 9397/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6693 - val_loss: -0.5157\n",
            "Epoch 9398/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6758 - val_loss: -0.5152\n",
            "Epoch 9399/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6690 - val_loss: -0.5161\n",
            "Epoch 9400/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6808 - val_loss: -0.5142\n",
            "Epoch 9401/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6707 - val_loss: -0.5167\n",
            "Epoch 9402/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6674 - val_loss: -0.5151\n",
            "Epoch 9403/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6736 - val_loss: -0.5161\n",
            "Epoch 9404/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6697 - val_loss: -0.5165\n",
            "Epoch 9405/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6770 - val_loss: -0.5153\n",
            "Epoch 9406/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6791 - val_loss: -0.5155\n",
            "Epoch 9407/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6719 - val_loss: -0.5158\n",
            "Epoch 9408/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6769 - val_loss: -0.5164\n",
            "Epoch 9409/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6721 - val_loss: -0.5154\n",
            "Epoch 9410/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6739 - val_loss: -0.5155\n",
            "Epoch 9411/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6854 - val_loss: -0.5154\n",
            "Epoch 9412/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6708 - val_loss: -0.5167\n",
            "Epoch 9413/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6765 - val_loss: -0.5155\n",
            "Epoch 9414/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6806 - val_loss: -0.5158\n",
            "Epoch 9415/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6774 - val_loss: -0.5155\n",
            "Epoch 9416/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5156\n",
            "Epoch 9417/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6744 - val_loss: -0.5163\n",
            "Epoch 9418/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6768 - val_loss: -0.5155\n",
            "Epoch 9419/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6799 - val_loss: -0.5162\n",
            "Epoch 9420/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6775 - val_loss: -0.5153\n",
            "Epoch 9421/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6786 - val_loss: -0.5154\n",
            "Epoch 9422/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5158\n",
            "Epoch 9423/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6816 - val_loss: -0.5154\n",
            "Epoch 9424/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6702 - val_loss: -0.5156\n",
            "Epoch 9425/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6594 - val_loss: -0.5164\n",
            "Epoch 9426/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6756 - val_loss: -0.5155\n",
            "Epoch 9427/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6672 - val_loss: -0.5155\n",
            "Epoch 9428/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6699 - val_loss: -0.5160\n",
            "Epoch 9429/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6754 - val_loss: -0.5153\n",
            "Epoch 9430/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6736 - val_loss: -0.5153\n",
            "Epoch 9431/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6650 - val_loss: -0.5158\n",
            "Epoch 9432/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6725 - val_loss: -0.5166\n",
            "Epoch 9433/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6701 - val_loss: -0.5163\n",
            "Epoch 9434/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6718 - val_loss: -0.5150\n",
            "Epoch 9435/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6740 - val_loss: -0.5156\n",
            "Epoch 9436/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6682 - val_loss: -0.5163\n",
            "Epoch 9437/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6745 - val_loss: -0.5156\n",
            "Epoch 9438/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6770 - val_loss: -0.5158\n",
            "Epoch 9439/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6669 - val_loss: -0.5167\n",
            "Epoch 9440/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6662 - val_loss: -0.5156\n",
            "Epoch 9441/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6766 - val_loss: -0.5152\n",
            "Epoch 9442/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6641 - val_loss: -0.5164\n",
            "Epoch 9443/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5147\n",
            "Epoch 9444/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6616 - val_loss: -0.5160\n",
            "Epoch 9445/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6813 - val_loss: -0.5158\n",
            "Epoch 9446/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6711 - val_loss: -0.5154\n",
            "Epoch 9447/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6677 - val_loss: -0.5162\n",
            "Epoch 9448/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6697 - val_loss: -0.5162\n",
            "Epoch 9449/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6741 - val_loss: -0.5160\n",
            "Epoch 9450/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6712 - val_loss: -0.5160\n",
            "Epoch 9451/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6724 - val_loss: -0.5159\n",
            "Epoch 9452/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6833 - val_loss: -0.5150\n",
            "Epoch 9453/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6778 - val_loss: -0.5150\n",
            "Epoch 9454/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5164\n",
            "Epoch 9455/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6692 - val_loss: -0.5158\n",
            "Epoch 9456/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6719 - val_loss: -0.5159\n",
            "Epoch 9457/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6701 - val_loss: -0.5161\n",
            "Epoch 9458/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6730 - val_loss: -0.5161\n",
            "Epoch 9459/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6724 - val_loss: -0.5156\n",
            "Epoch 9460/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6801 - val_loss: -0.5153\n",
            "Epoch 9461/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6731 - val_loss: -0.5160\n",
            "Epoch 9462/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6675 - val_loss: -0.5153\n",
            "Epoch 9463/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6703 - val_loss: -0.5159\n",
            "Epoch 9464/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6835 - val_loss: -0.5150\n",
            "Epoch 9465/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6662 - val_loss: -0.5163\n",
            "Epoch 9466/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6720 - val_loss: -0.5161\n",
            "Epoch 9467/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6686 - val_loss: -0.5157\n",
            "Epoch 9468/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6807 - val_loss: -0.5146\n",
            "Epoch 9469/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6702 - val_loss: -0.5158\n",
            "Epoch 9470/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6783 - val_loss: -0.5145\n",
            "Epoch 9471/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6738 - val_loss: -0.5161\n",
            "Epoch 9472/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6779 - val_loss: -0.5157\n",
            "Epoch 9473/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6605 - val_loss: -0.5153\n",
            "Epoch 9474/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6720 - val_loss: -0.5148\n",
            "Epoch 9475/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6721 - val_loss: -0.5163\n",
            "Epoch 9476/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6731 - val_loss: -0.5147\n",
            "Epoch 9477/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6768 - val_loss: -0.5155\n",
            "Epoch 9478/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6771 - val_loss: -0.5154\n",
            "Epoch 9479/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6686 - val_loss: -0.5163\n",
            "Epoch 9480/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6694 - val_loss: -0.5156\n",
            "Epoch 9481/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6719 - val_loss: -0.5154\n",
            "Epoch 9482/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6717 - val_loss: -0.5152\n",
            "Epoch 9483/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6629 - val_loss: -0.5151\n",
            "Epoch 9484/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6798 - val_loss: -0.5151\n",
            "Epoch 9485/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6800 - val_loss: -0.5152\n",
            "Epoch 9486/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6661 - val_loss: -0.5158\n",
            "Epoch 9487/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6506 - val_loss: -0.5161\n",
            "Epoch 9488/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6820 - val_loss: -0.5147\n",
            "Epoch 9489/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6761 - val_loss: -0.5157\n",
            "Epoch 9490/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6801 - val_loss: -0.5157\n",
            "Epoch 9491/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6721 - val_loss: -0.5163\n",
            "Epoch 9492/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6765 - val_loss: -0.5158\n",
            "Epoch 9493/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6752 - val_loss: -0.5163\n",
            "Epoch 9494/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6778 - val_loss: -0.5160\n",
            "Epoch 9495/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6654 - val_loss: -0.5160\n",
            "Epoch 9496/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6795 - val_loss: -0.5155\n",
            "Epoch 9497/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6616 - val_loss: -0.5163\n",
            "Epoch 9498/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6743 - val_loss: -0.5152\n",
            "Epoch 9499/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6632 - val_loss: -0.5158\n",
            "Epoch 9500/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6750 - val_loss: -0.5159\n",
            "Epoch 9501/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6660 - val_loss: -0.5160\n",
            "Epoch 9502/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6783 - val_loss: -0.5157\n",
            "Epoch 9503/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6826 - val_loss: -0.5156\n",
            "Epoch 9504/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6769 - val_loss: -0.5156\n",
            "Epoch 9505/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6801 - val_loss: -0.5157\n",
            "Epoch 9506/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5159\n",
            "Epoch 9507/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6743 - val_loss: -0.5148\n",
            "Epoch 9508/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6831 - val_loss: -0.5157\n",
            "Epoch 9509/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6767 - val_loss: -0.5160\n",
            "Epoch 9510/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6787 - val_loss: -0.5152\n",
            "Epoch 9511/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5151\n",
            "Epoch 9512/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6648 - val_loss: -0.5162\n",
            "Epoch 9513/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6772 - val_loss: -0.5154\n",
            "Epoch 9514/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6748 - val_loss: -0.5157\n",
            "Epoch 9515/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6738 - val_loss: -0.5154\n",
            "Epoch 9516/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6712 - val_loss: -0.5157\n",
            "Epoch 9517/10000\n",
            "22/22 [==============================] - 1s 29ms/step - loss: -0.6781 - val_loss: -0.5156\n",
            "Epoch 9518/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6740 - val_loss: -0.5162\n",
            "Epoch 9519/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6754 - val_loss: -0.5163\n",
            "Epoch 9520/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6647 - val_loss: -0.5158\n",
            "Epoch 9521/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6836 - val_loss: -0.5159\n",
            "Epoch 9522/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6757 - val_loss: -0.5157\n",
            "Epoch 9523/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6653 - val_loss: -0.5159\n",
            "Epoch 9524/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6768 - val_loss: -0.5151\n",
            "Epoch 9525/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5156\n",
            "Epoch 9526/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6805 - val_loss: -0.5154\n",
            "Epoch 9527/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6781 - val_loss: -0.5151\n",
            "Epoch 9528/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6776 - val_loss: -0.5158\n",
            "Epoch 9529/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6807 - val_loss: -0.5150\n",
            "Epoch 9530/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6809 - val_loss: -0.5151\n",
            "Epoch 9531/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6736 - val_loss: -0.5154\n",
            "Epoch 9532/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6778 - val_loss: -0.5156\n",
            "Epoch 9533/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6779 - val_loss: -0.5157\n",
            "Epoch 9534/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6739 - val_loss: -0.5165\n",
            "Epoch 9535/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6790 - val_loss: -0.5152\n",
            "Epoch 9536/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6795 - val_loss: -0.5157\n",
            "Epoch 9537/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6766 - val_loss: -0.5153\n",
            "Epoch 9538/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6805 - val_loss: -0.5159\n",
            "Epoch 9539/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6726 - val_loss: -0.5158\n",
            "Epoch 9540/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6720 - val_loss: -0.5160\n",
            "Epoch 9541/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6770 - val_loss: -0.5155\n",
            "Epoch 9542/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6820 - val_loss: -0.5152\n",
            "Epoch 9543/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6727 - val_loss: -0.5156\n",
            "Epoch 9544/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6794 - val_loss: -0.5158\n",
            "Epoch 9545/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6743 - val_loss: -0.5156\n",
            "Epoch 9546/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6738 - val_loss: -0.5163\n",
            "Epoch 9547/10000\n",
            "22/22 [==============================] - 1s 34ms/step - loss: -0.6769 - val_loss: -0.5149\n",
            "Epoch 9548/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6774 - val_loss: -0.5155\n",
            "Epoch 9549/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6664 - val_loss: -0.5162\n",
            "Epoch 9550/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6718 - val_loss: -0.5151\n",
            "Epoch 9551/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6756 - val_loss: -0.5152\n",
            "Epoch 9552/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6729 - val_loss: -0.5158\n",
            "Epoch 9553/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6752 - val_loss: -0.5152\n",
            "Epoch 9554/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6764 - val_loss: -0.5156\n",
            "Epoch 9555/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6613 - val_loss: -0.5165\n",
            "Epoch 9556/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6678 - val_loss: -0.5161\n",
            "Epoch 9557/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6815 - val_loss: -0.5159\n",
            "Epoch 9558/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6792 - val_loss: -0.5151\n",
            "Epoch 9559/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6642 - val_loss: -0.5162\n",
            "Epoch 9560/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6773 - val_loss: -0.5154\n",
            "Epoch 9561/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6663 - val_loss: -0.5164\n",
            "Epoch 9562/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6722 - val_loss: -0.5153\n",
            "Epoch 9563/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6660 - val_loss: -0.5154\n",
            "Epoch 9564/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6700 - val_loss: -0.5155\n",
            "Epoch 9565/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6752 - val_loss: -0.5153\n",
            "Epoch 9566/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6723 - val_loss: -0.5170\n",
            "Epoch 9567/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6689 - val_loss: -0.5169\n",
            "Epoch 9568/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5163\n",
            "Epoch 9569/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6744 - val_loss: -0.5154\n",
            "Epoch 9570/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6733 - val_loss: -0.5160\n",
            "Epoch 9571/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6757 - val_loss: -0.5157\n",
            "Epoch 9572/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6687 - val_loss: -0.5161\n",
            "Epoch 9573/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6623 - val_loss: -0.5162\n",
            "Epoch 9574/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6621 - val_loss: -0.5163\n",
            "Epoch 9575/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6704 - val_loss: -0.5149\n",
            "Epoch 9576/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6672 - val_loss: -0.5171\n",
            "Epoch 9577/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6769 - val_loss: -0.5156\n",
            "Epoch 9578/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6801 - val_loss: -0.5152\n",
            "Epoch 9579/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6779 - val_loss: -0.5159\n",
            "Epoch 9580/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6714 - val_loss: -0.5158\n",
            "Epoch 9581/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6615 - val_loss: -0.5171\n",
            "Epoch 9582/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6746 - val_loss: -0.5150\n",
            "Epoch 9583/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6718 - val_loss: -0.5162\n",
            "Epoch 9584/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6746 - val_loss: -0.5156\n",
            "Epoch 9585/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6760 - val_loss: -0.5159\n",
            "Epoch 9586/10000\n",
            "22/22 [==============================] - 1s 29ms/step - loss: -0.6711 - val_loss: -0.5152\n",
            "Epoch 9587/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5158\n",
            "Epoch 9588/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6738 - val_loss: -0.5158\n",
            "Epoch 9589/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6748 - val_loss: -0.5166\n",
            "Epoch 9590/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6698 - val_loss: -0.5154\n",
            "Epoch 9591/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6789 - val_loss: -0.5156\n",
            "Epoch 9592/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6797 - val_loss: -0.5163\n",
            "Epoch 9593/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6781 - val_loss: -0.5154\n",
            "Epoch 9594/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6794 - val_loss: -0.5153\n",
            "Epoch 9595/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6784 - val_loss: -0.5162\n",
            "Epoch 9596/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6685 - val_loss: -0.5158\n",
            "Epoch 9597/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6713 - val_loss: -0.5161\n",
            "Epoch 9598/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6751 - val_loss: -0.5160\n",
            "Epoch 9599/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6684 - val_loss: -0.5160\n",
            "Epoch 9600/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6773 - val_loss: -0.5158\n",
            "Epoch 9601/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6742 - val_loss: -0.5154\n",
            "Epoch 9602/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6747 - val_loss: -0.5151\n",
            "Epoch 9603/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6745 - val_loss: -0.5166\n",
            "Epoch 9604/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6739 - val_loss: -0.5164\n",
            "Epoch 9605/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6757 - val_loss: -0.5151\n",
            "Epoch 9606/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6732 - val_loss: -0.5168\n",
            "Epoch 9607/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6659 - val_loss: -0.5164\n",
            "Epoch 9608/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6783 - val_loss: -0.5159\n",
            "Epoch 9609/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6702 - val_loss: -0.5155\n",
            "Epoch 9610/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6753 - val_loss: -0.5160\n",
            "Epoch 9611/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6744 - val_loss: -0.5165\n",
            "Epoch 9612/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6751 - val_loss: -0.5158\n",
            "Epoch 9613/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6794 - val_loss: -0.5153\n",
            "Epoch 9614/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6772 - val_loss: -0.5151\n",
            "Epoch 9615/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6580 - val_loss: -0.5165\n",
            "Epoch 9616/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6770 - val_loss: -0.5156\n",
            "Epoch 9617/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6686 - val_loss: -0.5156\n",
            "Epoch 9618/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6825 - val_loss: -0.5151\n",
            "Epoch 9619/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6748 - val_loss: -0.5162\n",
            "Epoch 9620/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6613 - val_loss: -0.5152\n",
            "Epoch 9621/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6672 - val_loss: -0.5164\n",
            "Epoch 9622/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6718 - val_loss: -0.5143\n",
            "Epoch 9623/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6723 - val_loss: -0.5164\n",
            "Epoch 9624/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6727 - val_loss: -0.5161\n",
            "Epoch 9625/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6823 - val_loss: -0.5155\n",
            "Epoch 9626/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6667 - val_loss: -0.5157\n",
            "Epoch 9627/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6779 - val_loss: -0.5150\n",
            "Epoch 9628/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6761 - val_loss: -0.5154\n",
            "Epoch 9629/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6720 - val_loss: -0.5152\n",
            "Epoch 9630/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6753 - val_loss: -0.5155\n",
            "Epoch 9631/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6735 - val_loss: -0.5160\n",
            "Epoch 9632/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6762 - val_loss: -0.5158\n",
            "Epoch 9633/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6684 - val_loss: -0.5161\n",
            "Epoch 9634/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6738 - val_loss: -0.5159\n",
            "Epoch 9635/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6720 - val_loss: -0.5160\n",
            "Epoch 9636/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6742 - val_loss: -0.5158\n",
            "Epoch 9637/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6764 - val_loss: -0.5163\n",
            "Epoch 9638/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6787 - val_loss: -0.5159\n",
            "Epoch 9639/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6692 - val_loss: -0.5163\n",
            "Epoch 9640/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6782 - val_loss: -0.5147\n",
            "Epoch 9641/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6773 - val_loss: -0.5158\n",
            "Epoch 9642/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6715 - val_loss: -0.5153\n",
            "Epoch 9643/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6747 - val_loss: -0.5155\n",
            "Epoch 9644/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6799 - val_loss: -0.5155\n",
            "Epoch 9645/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6750 - val_loss: -0.5159\n",
            "Epoch 9646/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6779 - val_loss: -0.5156\n",
            "Epoch 9647/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6735 - val_loss: -0.5162\n",
            "Epoch 9648/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6733 - val_loss: -0.5153\n",
            "Epoch 9649/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6649 - val_loss: -0.5160\n",
            "Epoch 9650/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6753 - val_loss: -0.5154\n",
            "Epoch 9651/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6755 - val_loss: -0.5165\n",
            "Epoch 9652/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6665 - val_loss: -0.5149\n",
            "Epoch 9653/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6737 - val_loss: -0.5160\n",
            "Epoch 9654/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6717 - val_loss: -0.5157\n",
            "Epoch 9655/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6760 - val_loss: -0.5154\n",
            "Epoch 9656/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6634 - val_loss: -0.5161\n",
            "Epoch 9657/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6746 - val_loss: -0.5152\n",
            "Epoch 9658/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6803 - val_loss: -0.5150\n",
            "Epoch 9659/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6745 - val_loss: -0.5160\n",
            "Epoch 9660/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6690 - val_loss: -0.5145\n",
            "Epoch 9661/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6767 - val_loss: -0.5152\n",
            "Epoch 9662/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6803 - val_loss: -0.5150\n",
            "Epoch 9663/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6717 - val_loss: -0.5149\n",
            "Epoch 9664/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6724 - val_loss: -0.5156\n",
            "Epoch 9665/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6717 - val_loss: -0.5155\n",
            "Epoch 9666/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6672 - val_loss: -0.5155\n",
            "Epoch 9667/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6737 - val_loss: -0.5159\n",
            "Epoch 9668/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6652 - val_loss: -0.5168\n",
            "Epoch 9669/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6772 - val_loss: -0.5156\n",
            "Epoch 9670/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6732 - val_loss: -0.5153\n",
            "Epoch 9671/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6751 - val_loss: -0.5155\n",
            "Epoch 9672/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6759 - val_loss: -0.5154\n",
            "Epoch 9673/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6752 - val_loss: -0.5149\n",
            "Epoch 9674/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6782 - val_loss: -0.5157\n",
            "Epoch 9675/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6718 - val_loss: -0.5157\n",
            "Epoch 9676/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6803 - val_loss: -0.5152\n",
            "Epoch 9677/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6766 - val_loss: -0.5159\n",
            "Epoch 9678/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6815 - val_loss: -0.5150\n",
            "Epoch 9679/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6823 - val_loss: -0.5162\n",
            "Epoch 9680/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6792 - val_loss: -0.5151\n",
            "Epoch 9681/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6774 - val_loss: -0.5152\n",
            "Epoch 9682/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6790 - val_loss: -0.5159\n",
            "Epoch 9683/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6786 - val_loss: -0.5152\n",
            "Epoch 9684/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6741 - val_loss: -0.5156\n",
            "Epoch 9685/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6666 - val_loss: -0.5159\n",
            "Epoch 9686/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6700 - val_loss: -0.5159\n",
            "Epoch 9687/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6730 - val_loss: -0.5148\n",
            "Epoch 9688/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6774 - val_loss: -0.5158\n",
            "Epoch 9689/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6762 - val_loss: -0.5162\n",
            "Epoch 9690/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6649 - val_loss: -0.5166\n",
            "Epoch 9691/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6772 - val_loss: -0.5156\n",
            "Epoch 9692/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6733 - val_loss: -0.5159\n",
            "Epoch 9693/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6783 - val_loss: -0.5165\n",
            "Epoch 9694/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6754 - val_loss: -0.5159\n",
            "Epoch 9695/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6676 - val_loss: -0.5162\n",
            "Epoch 9696/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6756 - val_loss: -0.5161\n",
            "Epoch 9697/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6727 - val_loss: -0.5162\n",
            "Epoch 9698/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6656 - val_loss: -0.5158\n",
            "Epoch 9699/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6672 - val_loss: -0.5159\n",
            "Epoch 9700/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6699 - val_loss: -0.5163\n",
            "Epoch 9701/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6708 - val_loss: -0.5160\n",
            "Epoch 9702/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6669 - val_loss: -0.5146\n",
            "Epoch 9703/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6772 - val_loss: -0.5162\n",
            "Epoch 9704/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6649 - val_loss: -0.5156\n",
            "Epoch 9705/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6725 - val_loss: -0.5166\n",
            "Epoch 9706/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6726 - val_loss: -0.5161\n",
            "Epoch 9707/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6690 - val_loss: -0.5151\n",
            "Epoch 9708/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6817 - val_loss: -0.5162\n",
            "Epoch 9709/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6718 - val_loss: -0.5167\n",
            "Epoch 9710/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6789 - val_loss: -0.5142\n",
            "Epoch 9711/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6713 - val_loss: -0.5168\n",
            "Epoch 9712/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6664 - val_loss: -0.5156\n",
            "Epoch 9713/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6738 - val_loss: -0.5159\n",
            "Epoch 9714/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6832 - val_loss: -0.5152\n",
            "Epoch 9715/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6807 - val_loss: -0.5152\n",
            "Epoch 9716/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6763 - val_loss: -0.5159\n",
            "Epoch 9717/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6690 - val_loss: -0.5152\n",
            "Epoch 9718/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6653 - val_loss: -0.5160\n",
            "Epoch 9719/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6680 - val_loss: -0.5163\n",
            "Epoch 9720/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6718 - val_loss: -0.5155\n",
            "Epoch 9721/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6806 - val_loss: -0.5165\n",
            "Epoch 9722/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6817 - val_loss: -0.5157\n",
            "Epoch 9723/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6748 - val_loss: -0.5163\n",
            "Epoch 9724/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6764 - val_loss: -0.5156\n",
            "Epoch 9725/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6760 - val_loss: -0.5159\n",
            "Epoch 9726/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6735 - val_loss: -0.5160\n",
            "Epoch 9727/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6725 - val_loss: -0.5165\n",
            "Epoch 9728/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6787 - val_loss: -0.5154\n",
            "Epoch 9729/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6748 - val_loss: -0.5157\n",
            "Epoch 9730/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6790 - val_loss: -0.5159\n",
            "Epoch 9731/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6671 - val_loss: -0.5155\n",
            "Epoch 9732/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6751 - val_loss: -0.5161\n",
            "Epoch 9733/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5163\n",
            "Epoch 9734/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6773 - val_loss: -0.5157\n",
            "Epoch 9735/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6777 - val_loss: -0.5154\n",
            "Epoch 9736/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6735 - val_loss: -0.5161\n",
            "Epoch 9737/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6742 - val_loss: -0.5156\n",
            "Epoch 9738/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6779 - val_loss: -0.5159\n",
            "Epoch 9739/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6753 - val_loss: -0.5158\n",
            "Epoch 9740/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6672 - val_loss: -0.5168\n",
            "Epoch 9741/10000\n",
            "22/22 [==============================] - 1s 29ms/step - loss: -0.6681 - val_loss: -0.5167\n",
            "Epoch 9742/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6774 - val_loss: -0.5159\n",
            "Epoch 9743/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6701 - val_loss: -0.5163\n",
            "Epoch 9744/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6795 - val_loss: -0.5157\n",
            "Epoch 9745/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6764 - val_loss: -0.5161\n",
            "Epoch 9746/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6668 - val_loss: -0.5159\n",
            "Epoch 9747/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6744 - val_loss: -0.5164\n",
            "Epoch 9748/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6684 - val_loss: -0.5160\n",
            "Epoch 9749/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6714 - val_loss: -0.5168\n",
            "Epoch 9750/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6700 - val_loss: -0.5153\n",
            "Epoch 9751/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6774 - val_loss: -0.5148\n",
            "Epoch 9752/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6760 - val_loss: -0.5156\n",
            "Epoch 9753/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6774 - val_loss: -0.5161\n",
            "Epoch 9754/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6612 - val_loss: -0.5149\n",
            "Epoch 9755/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6685 - val_loss: -0.5164\n",
            "Epoch 9756/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6675 - val_loss: -0.5167\n",
            "Epoch 9757/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6692 - val_loss: -0.5160\n",
            "Epoch 9758/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5165\n",
            "Epoch 9759/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6682 - val_loss: -0.5157\n",
            "Epoch 9760/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6771 - val_loss: -0.5160\n",
            "Epoch 9761/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6676 - val_loss: -0.5158\n",
            "Epoch 9762/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6657 - val_loss: -0.5167\n",
            "Epoch 9763/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6774 - val_loss: -0.5155\n",
            "Epoch 9764/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6777 - val_loss: -0.5166\n",
            "Epoch 9765/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6643 - val_loss: -0.5166\n",
            "Epoch 9766/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6776 - val_loss: -0.5156\n",
            "Epoch 9767/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5164\n",
            "Epoch 9768/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6708 - val_loss: -0.5157\n",
            "Epoch 9769/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6728 - val_loss: -0.5159\n",
            "Epoch 9770/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6802 - val_loss: -0.5156\n",
            "Epoch 9771/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6778 - val_loss: -0.5166\n",
            "Epoch 9772/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6746 - val_loss: -0.5152\n",
            "Epoch 9773/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6764 - val_loss: -0.5159\n",
            "Epoch 9774/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6802 - val_loss: -0.5161\n",
            "Epoch 9775/10000\n",
            "22/22 [==============================] - 1s 29ms/step - loss: -0.6755 - val_loss: -0.5159\n",
            "Epoch 9776/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6640 - val_loss: -0.5166\n",
            "Epoch 9777/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6572 - val_loss: -0.5156\n",
            "Epoch 9778/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6775 - val_loss: -0.5149\n",
            "Epoch 9779/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6770 - val_loss: -0.5156\n",
            "Epoch 9780/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6764 - val_loss: -0.5156\n",
            "Epoch 9781/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6787 - val_loss: -0.5151\n",
            "Epoch 9782/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6775 - val_loss: -0.5158\n",
            "Epoch 9783/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6761 - val_loss: -0.5160\n",
            "Epoch 9784/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6675 - val_loss: -0.5169\n",
            "Epoch 9785/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6750 - val_loss: -0.5159\n",
            "Epoch 9786/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6682 - val_loss: -0.5161\n",
            "Epoch 9787/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6723 - val_loss: -0.5162\n",
            "Epoch 9788/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6757 - val_loss: -0.5164\n",
            "Epoch 9789/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6741 - val_loss: -0.5153\n",
            "Epoch 9790/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6734 - val_loss: -0.5161\n",
            "Epoch 9791/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6776 - val_loss: -0.5154\n",
            "Epoch 9792/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6830 - val_loss: -0.5153\n",
            "Epoch 9793/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6813 - val_loss: -0.5157\n",
            "Epoch 9794/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6740 - val_loss: -0.5161\n",
            "Epoch 9795/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6693 - val_loss: -0.5156\n",
            "Epoch 9796/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6731 - val_loss: -0.5160\n",
            "Epoch 9797/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6661 - val_loss: -0.5176\n",
            "Epoch 9798/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6662 - val_loss: -0.5143\n",
            "Epoch 9799/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6702 - val_loss: -0.5163\n",
            "Epoch 9800/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6771 - val_loss: -0.5153\n",
            "Epoch 9801/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6686 - val_loss: -0.5158\n",
            "Epoch 9802/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6767 - val_loss: -0.5146\n",
            "Epoch 9803/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6785 - val_loss: -0.5157\n",
            "Epoch 9804/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6738 - val_loss: -0.5157\n",
            "Epoch 9805/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6709 - val_loss: -0.5158\n",
            "Epoch 9806/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6775 - val_loss: -0.5148\n",
            "Epoch 9807/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6767 - val_loss: -0.5160\n",
            "Epoch 9808/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6761 - val_loss: -0.5149\n",
            "Epoch 9809/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6782 - val_loss: -0.5157\n",
            "Epoch 9810/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6722 - val_loss: -0.5157\n",
            "Epoch 9811/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6823 - val_loss: -0.5155\n",
            "Epoch 9812/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6820 - val_loss: -0.5154\n",
            "Epoch 9813/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6754 - val_loss: -0.5159\n",
            "Epoch 9814/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6794 - val_loss: -0.5160\n",
            "Epoch 9815/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6615 - val_loss: -0.5156\n",
            "Epoch 9816/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6649 - val_loss: -0.5176\n",
            "Epoch 9817/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6813 - val_loss: -0.5158\n",
            "Epoch 9818/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6731 - val_loss: -0.5161\n",
            "Epoch 9819/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6760 - val_loss: -0.5149\n",
            "Epoch 9820/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6666 - val_loss: -0.5161\n",
            "Epoch 9821/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6806 - val_loss: -0.5157\n",
            "Epoch 9822/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6795 - val_loss: -0.5154\n",
            "Epoch 9823/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6780 - val_loss: -0.5163\n",
            "Epoch 9824/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6729 - val_loss: -0.5161\n",
            "Epoch 9825/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6767 - val_loss: -0.5156\n",
            "Epoch 9826/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6827 - val_loss: -0.5157\n",
            "Epoch 9827/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6754 - val_loss: -0.5156\n",
            "Epoch 9828/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6723 - val_loss: -0.5157\n",
            "Epoch 9829/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6775 - val_loss: -0.5157\n",
            "Epoch 9830/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6774 - val_loss: -0.5150\n",
            "Epoch 9831/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6662 - val_loss: -0.5159\n",
            "Epoch 9832/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6749 - val_loss: -0.5164\n",
            "Epoch 9833/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6676 - val_loss: -0.5159\n",
            "Epoch 9834/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6823 - val_loss: -0.5155\n",
            "Epoch 9835/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6737 - val_loss: -0.5160\n",
            "Epoch 9836/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6756 - val_loss: -0.5155\n",
            "Epoch 9837/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6824 - val_loss: -0.5156\n",
            "Epoch 9838/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6710 - val_loss: -0.5156\n",
            "Epoch 9839/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6764 - val_loss: -0.5159\n",
            "Epoch 9840/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6748 - val_loss: -0.5151\n",
            "Epoch 9841/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6786 - val_loss: -0.5157\n",
            "Epoch 9842/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6612 - val_loss: -0.5158\n",
            "Epoch 9843/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6730 - val_loss: -0.5159\n",
            "Epoch 9844/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6712 - val_loss: -0.5156\n",
            "Epoch 9845/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6665 - val_loss: -0.5160\n",
            "Epoch 9846/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6693 - val_loss: -0.5158\n",
            "Epoch 9847/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6709 - val_loss: -0.5160\n",
            "Epoch 9848/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6777 - val_loss: -0.5151\n",
            "Epoch 9849/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6816 - val_loss: -0.5157\n",
            "Epoch 9850/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6768 - val_loss: -0.5161\n",
            "Epoch 9851/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6689 - val_loss: -0.5155\n",
            "Epoch 9852/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6808 - val_loss: -0.5162\n",
            "Epoch 9853/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6795 - val_loss: -0.5152\n",
            "Epoch 9854/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6756 - val_loss: -0.5160\n",
            "Epoch 9855/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6771 - val_loss: -0.5162\n",
            "Epoch 9856/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6761 - val_loss: -0.5160\n",
            "Epoch 9857/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6738 - val_loss: -0.5166\n",
            "Epoch 9858/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6782 - val_loss: -0.5154\n",
            "Epoch 9859/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6747 - val_loss: -0.5153\n",
            "Epoch 9860/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6791 - val_loss: -0.5155\n",
            "Epoch 9861/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6746 - val_loss: -0.5162\n",
            "Epoch 9862/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6744 - val_loss: -0.5154\n",
            "Epoch 9863/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6780 - val_loss: -0.5156\n",
            "Epoch 9864/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6690 - val_loss: -0.5162\n",
            "Epoch 9865/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6647 - val_loss: -0.5162\n",
            "Epoch 9866/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6782 - val_loss: -0.5161\n",
            "Epoch 9867/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6790 - val_loss: -0.5151\n",
            "Epoch 9868/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6768 - val_loss: -0.5155\n",
            "Epoch 9869/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6783 - val_loss: -0.5158\n",
            "Epoch 9870/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6771 - val_loss: -0.5154\n",
            "Epoch 9871/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6711 - val_loss: -0.5149\n",
            "Epoch 9872/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6621 - val_loss: -0.5165\n",
            "Epoch 9873/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6819 - val_loss: -0.5157\n",
            "Epoch 9874/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6802 - val_loss: -0.5164\n",
            "Epoch 9875/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6740 - val_loss: -0.5159\n",
            "Epoch 9876/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6686 - val_loss: -0.5161\n",
            "Epoch 9877/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6724 - val_loss: -0.5160\n",
            "Epoch 9878/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6747 - val_loss: -0.5165\n",
            "Epoch 9879/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6714 - val_loss: -0.5167\n",
            "Epoch 9880/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6763 - val_loss: -0.5153\n",
            "Epoch 9881/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6662 - val_loss: -0.5166\n",
            "Epoch 9882/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6785 - val_loss: -0.5159\n",
            "Epoch 9883/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6775 - val_loss: -0.5156\n",
            "Epoch 9884/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6767 - val_loss: -0.5154\n",
            "Epoch 9885/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6807 - val_loss: -0.5157\n",
            "Epoch 9886/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6774 - val_loss: -0.5161\n",
            "Epoch 9887/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6730 - val_loss: -0.5158\n",
            "Epoch 9888/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6750 - val_loss: -0.5153\n",
            "Epoch 9889/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6831 - val_loss: -0.5156\n",
            "Epoch 9890/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6755 - val_loss: -0.5162\n",
            "Epoch 9891/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6767 - val_loss: -0.5161\n",
            "Epoch 9892/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6668 - val_loss: -0.5159\n",
            "Epoch 9893/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6819 - val_loss: -0.5156\n",
            "Epoch 9894/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5147\n",
            "Epoch 9895/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6798 - val_loss: -0.5164\n",
            "Epoch 9896/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6724 - val_loss: -0.5156\n",
            "Epoch 9897/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6741 - val_loss: -0.5152\n",
            "Epoch 9898/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6823 - val_loss: -0.5157\n",
            "Epoch 9899/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6738 - val_loss: -0.5169\n",
            "Epoch 9900/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6775 - val_loss: -0.5157\n",
            "Epoch 9901/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6800 - val_loss: -0.5153\n",
            "Epoch 9902/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6733 - val_loss: -0.5162\n",
            "Epoch 9903/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6692 - val_loss: -0.5162\n",
            "Epoch 9904/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6796 - val_loss: -0.5158\n",
            "Epoch 9905/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6689 - val_loss: -0.5167\n",
            "Epoch 9906/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6737 - val_loss: -0.5160\n",
            "Epoch 9907/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6716 - val_loss: -0.5158\n",
            "Epoch 9908/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6707 - val_loss: -0.5155\n",
            "Epoch 9909/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6817 - val_loss: -0.5160\n",
            "Epoch 9910/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6785 - val_loss: -0.5158\n",
            "Epoch 9911/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6789 - val_loss: -0.5154\n",
            "Epoch 9912/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6834 - val_loss: -0.5153\n",
            "Epoch 9913/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6741 - val_loss: -0.5163\n",
            "Epoch 9914/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6728 - val_loss: -0.5163\n",
            "Epoch 9915/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6720 - val_loss: -0.5164\n",
            "Epoch 9916/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6779 - val_loss: -0.5156\n",
            "Epoch 9917/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6801 - val_loss: -0.5160\n",
            "Epoch 9918/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6794 - val_loss: -0.5160\n",
            "Epoch 9919/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6710 - val_loss: -0.5153\n",
            "Epoch 9920/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6666 - val_loss: -0.5171\n",
            "Epoch 9921/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6763 - val_loss: -0.5150\n",
            "Epoch 9922/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6747 - val_loss: -0.5165\n",
            "Epoch 9923/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6759 - val_loss: -0.5156\n",
            "Epoch 9924/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6774 - val_loss: -0.5153\n",
            "Epoch 9925/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6792 - val_loss: -0.5157\n",
            "Epoch 9926/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6700 - val_loss: -0.5156\n",
            "Epoch 9927/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6808 - val_loss: -0.5155\n",
            "Epoch 9928/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6778 - val_loss: -0.5159\n",
            "Epoch 9929/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6727 - val_loss: -0.5158\n",
            "Epoch 9930/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6746 - val_loss: -0.5159\n",
            "Epoch 9931/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6744 - val_loss: -0.5157\n",
            "Epoch 9932/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6745 - val_loss: -0.5161\n",
            "Epoch 9933/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6770 - val_loss: -0.5156\n",
            "Epoch 9934/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6736 - val_loss: -0.5167\n",
            "Epoch 9935/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6811 - val_loss: -0.5148\n",
            "Epoch 9936/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6809 - val_loss: -0.5156\n",
            "Epoch 9937/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6742 - val_loss: -0.5164\n",
            "Epoch 9938/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6799 - val_loss: -0.5154\n",
            "Epoch 9939/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6734 - val_loss: -0.5160\n",
            "Epoch 9940/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6789 - val_loss: -0.5165\n",
            "Epoch 9941/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6793 - val_loss: -0.5161\n",
            "Epoch 9942/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6696 - val_loss: -0.5154\n",
            "Epoch 9943/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6772 - val_loss: -0.5159\n",
            "Epoch 9944/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6807 - val_loss: -0.5161\n",
            "Epoch 9945/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6786 - val_loss: -0.5156\n",
            "Epoch 9946/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6805 - val_loss: -0.5153\n",
            "Epoch 9947/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6733 - val_loss: -0.5167\n",
            "Epoch 9948/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6754 - val_loss: -0.5153\n",
            "Epoch 9949/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6744 - val_loss: -0.5161\n",
            "Epoch 9950/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6784 - val_loss: -0.5158\n",
            "Epoch 9951/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6756 - val_loss: -0.5167\n",
            "Epoch 9952/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6738 - val_loss: -0.5149\n",
            "Epoch 9953/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6770 - val_loss: -0.5163\n",
            "Epoch 9954/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6765 - val_loss: -0.5156\n",
            "Epoch 9955/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6746 - val_loss: -0.5145\n",
            "Epoch 9956/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6821 - val_loss: -0.5152\n",
            "Epoch 9957/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6666 - val_loss: -0.5168\n",
            "Epoch 9958/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6785 - val_loss: -0.5158\n",
            "Epoch 9959/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6779 - val_loss: -0.5163\n",
            "Epoch 9960/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6711 - val_loss: -0.5157\n",
            "Epoch 9961/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6833 - val_loss: -0.5155\n",
            "Epoch 9962/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6781 - val_loss: -0.5164\n",
            "Epoch 9963/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6779 - val_loss: -0.5162\n",
            "Epoch 9964/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6798 - val_loss: -0.5155\n",
            "Epoch 9965/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6585 - val_loss: -0.5159\n",
            "Epoch 9966/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6842 - val_loss: -0.5153\n",
            "Epoch 9967/10000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: -0.6757 - val_loss: -0.5156\n",
            "Epoch 9968/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6680 - val_loss: -0.5162\n",
            "Epoch 9969/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6831 - val_loss: -0.5158\n",
            "Epoch 9970/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6792 - val_loss: -0.5158\n",
            "Epoch 9971/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6761 - val_loss: -0.5155\n",
            "Epoch 9972/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6760 - val_loss: -0.5163\n",
            "Epoch 9973/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6712 - val_loss: -0.5153\n",
            "Epoch 9974/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6711 - val_loss: -0.5157\n",
            "Epoch 9975/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6744 - val_loss: -0.5164\n",
            "Epoch 9976/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6712 - val_loss: -0.5166\n",
            "Epoch 9977/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6778 - val_loss: -0.5155\n",
            "Epoch 9978/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6871 - val_loss: -0.5155\n",
            "Epoch 9979/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6729 - val_loss: -0.5160\n",
            "Epoch 9980/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6784 - val_loss: -0.5164\n",
            "Epoch 9981/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6755 - val_loss: -0.5146\n",
            "Epoch 9982/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6686 - val_loss: -0.5164\n",
            "Epoch 9983/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6704 - val_loss: -0.5153\n",
            "Epoch 9984/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6819 - val_loss: -0.5155\n",
            "Epoch 9985/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6723 - val_loss: -0.5165\n",
            "Epoch 9986/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6772 - val_loss: -0.5150\n",
            "Epoch 9987/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6653 - val_loss: -0.5157\n",
            "Epoch 9988/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6688 - val_loss: -0.5164\n",
            "Epoch 9989/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6767 - val_loss: -0.5149\n",
            "Epoch 9990/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6720 - val_loss: -0.5159\n",
            "Epoch 9991/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6773 - val_loss: -0.5159\n",
            "Epoch 9992/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6729 - val_loss: -0.5160\n",
            "Epoch 9993/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6761 - val_loss: -0.5160\n",
            "Epoch 9994/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6813 - val_loss: -0.5152\n",
            "Epoch 9995/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6821 - val_loss: -0.5157\n",
            "Epoch 9996/10000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: -0.6764 - val_loss: -0.5159\n",
            "Epoch 9997/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6684 - val_loss: -0.5159\n",
            "Epoch 9998/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6761 - val_loss: -0.5161\n",
            "Epoch 9999/10000\n",
            "22/22 [==============================] - 1s 32ms/step - loss: -0.6644 - val_loss: -0.5162\n",
            "Epoch 10000/10000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: -0.6784 - val_loss: -0.5158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0796996fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0OxFWo3YZQs"
      },
      "source": [
        "model.save_weights('weights.h5')\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ttCdb_EYcnQ"
      },
      "source": [
        "pred = model.predict(x[:50])\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "1mt_jPnvYid0",
        "outputId": "58a65770-0ad3-46db-b288-4a704162bce0"
      },
      "source": [
        "import random as r\n",
        "num = int(x.shape[1]/2)\n",
        "for n in range(3):\n",
        "    i = int(r.random() * pred.shape[0])\n",
        "    plt.figure(figsize=(15,10))\n",
        "\n",
        "    plt.subplot(131)\n",
        "    plt.title('Input')\n",
        "    plt.imshow(x[i, num, :, :, 0])\n",
        "\n",
        "    plt.subplot(132)\n",
        "    plt.title('Ground Truth')\n",
        "    plt.imshow(y[i, num, :, :, 0])\n",
        "\n",
        "    plt.subplot(133)\n",
        "    plt.title('Prediction')\n",
        "    plt.imshow(pred[i, num, :, :, 0])\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8MDPBOhJ3CX"
      },
      "source": [
        "plt.plot(loss, label='Training loss')\n",
        "plt.plot(val_loss, label='Validation loss')\n",
        "plt.title('Loss Metrics')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}