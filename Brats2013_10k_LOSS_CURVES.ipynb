{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Brats.ipynb",
      "provenance": [],
      "mount_file_id": "1FefRRcYRNt6ZKGzSlB_EcLhn2JgScVqg",
      "authorship_tag": "ABX9TyOmrFrw0JwIFTkDBPfY+PFs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divsal009/div/blob/master/Brats2013_10k_LOSS_CURVES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih5-UKw_G99o"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import random as r\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv1sEn9EHFWc"
      },
      "source": [
        "import glob\n",
        "def create_data(src, mask, label=False, resize=(128,128,128)):\n",
        "    files = glob.glob(src + mask, recursive=True)\n",
        "    imgs = []\n",
        "    for file in files:\n",
        "        img = io.imread(file, plugin='simpleitk')\n",
        "        if label:\n",
        "            img[img == 4] = 1\n",
        "            img[img != 1] = 0\n",
        "            img = img.astype('float32')\n",
        "        else:\n",
        "            img = (img-img.mean()) / img.std()\n",
        "        img = trans.resize(img, resize, mode='constant')\n",
        "        imgs.append(img)\n",
        "    name = 'y' if label else 'x'\n",
        "    np.save(name, np.array(imgs)[..., np.newaxis].astype('float32'))\n",
        "    print('Saved', len(files), 'to', name)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdvg4MiwHLhU"
      },
      "source": [
        "from keras.models import Input, Model\n",
        "from keras.layers import Conv2D, Concatenate, MaxPooling2D, Reshape\n",
        "from keras.layers import UpSampling2D, Activation, Permute\n",
        "\n",
        "def level_block(m, dim, depth, factor, acti):\n",
        "    if depth > 0:\n",
        "        n = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
        "        n = Conv2D(dim, 3, activation=acti, padding='same')(n)\n",
        "        m = MaxPooling2D()(n)\n",
        "        m = level_block(m, int(factor*dim), depth-1, factor, acti)\n",
        "        m = UpSampling2D()(m)\n",
        "        m = Conv2D(dim, 2, activation=acti, padding='same')(m)\n",
        "        m = Concatenate(axis=3)([n, m])\n",
        "    m = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
        "    return Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
        "\n",
        "def UNet(img_shape, n_out=1, dim=64, depth=4, factor=2, acti='elu', flatten=False):\n",
        "    i = Input(shape=img_shape)\n",
        "    o = level_block(i, dim, depth, factor, acti)\n",
        "    o = Conv2D(n_out, (1, 1))(o)\n",
        "    if flatten:\n",
        "        o = Reshape(n_out, img_shape[0] * img_shape[1])(o)\n",
        "        o = Permute((2, 1))(o)\n",
        "    o = Activation('sigmoid')(o)\n",
        "    return Model(inputs=i, outputs=o)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnUT7n4ZHPtl"
      },
      "source": [
        "from keras.models import Input, Model\n",
        "from keras.layers import Conv3D, Concatenate, MaxPooling3D, Reshape\n",
        "from keras.layers import UpSampling3D, Activation, Permute\n",
        "\n",
        "def level_block_3d(m, dim, depth, factor, acti):\n",
        "    if depth > 0:\n",
        "        n = Conv3D(dim, 3, activation=acti, padding='same')(m)\n",
        "        m = MaxPooling3D()(n)\n",
        "        m = level_block_3d(m, int(factor*dim), depth-1, factor, acti)\n",
        "        m = UpSampling3D()(m)\n",
        "        m = Concatenate(axis=4)([n, m])\n",
        "    return Conv3D(dim, 3, activation=acti, padding='same')(m)\n",
        "\n",
        "def UNet_3D(img_shape, n_out=1, dim=64, depth=4, factor=2, acti='elu'):\n",
        "    i = Input(shape=img_shape)\n",
        "    o = level_block_3d(i, dim, depth, factor, acti)\n",
        "    o = Conv3D(n_out, 1, activation='sigmoid')(o)\n",
        "    return Model(inputs=i, outputs=o)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr7cHIGNHUxR"
      },
      "source": [
        "import keras.backend as K\n",
        "def f1_score(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1.) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.)\n",
        "\n",
        "def f1_loss(y_true, y_pred):\n",
        "    return -f1_score(y_true, y_pred)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NonSFPmZOvmB",
        "outputId": "6d4cf281-bb91-4b29-9b1f-7650afc6cca1"
      },
      "source": [
        "pip install simpleitk"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting simpleitk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/6b/85df5eb3a8059b23a53a9f224476e75473f9bcc0a8583ed1a9c34619f372/SimpleITK-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 64kB/s \n",
            "\u001b[?25hInstalling collected packages: simpleitk\n",
            "Successfully installed simpleitk-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnjE8YHIHYbd",
        "outputId": "ecc9667d-4573-4863-dfce-6cf7a2684c42"
      },
      "source": [
        "create_data('/content/drive/MyDrive/HGG/', '**/*T1c*.mha', label=False, resize=(32,32,32))\n",
        "create_data('/content/drive/MyDrive/HGG/', '**/*OT*.mha', label=True, resize=(32,32,32))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved 220 to x\n",
            "Saved 220 to y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6m9qMbEI6VF",
        "outputId": "81cb2bde-ca20-49e5-8f14-2737f4d6b227"
      },
      "source": [
        "x = np.load('x.npy')\n",
        "print('x: ', x.shape)\n",
        "y = np.load('y.npy')\n",
        "print('y:', y.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x:  (220, 32, 32, 32, 1)\n",
            "y: (220, 32, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "Rvz089fxI8Fv",
        "outputId": "c2c5b1d3-61d3-4c40-9794-4e671d81b13f"
      },
      "source": [
        "\n",
        "import random as r\n",
        "i = int(r.random() * x.shape[0])\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(121)\n",
        "plt.imshow(x[i, int(x.shape[1]/2), :, :, 0])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f93e132c610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Hv_SYB5VPXov",
        "outputId": "ecda31fc-8c5e-4a5a-a122-9f0c2e499065"
      },
      "source": [
        "plt.subplot(122)\n",
        "plt.imshow(y[i, int(y.shape[1]/2), :, :, 0])\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPSOT1WYJC77"
      },
      "source": [
        "model = UNet_3D(x.shape[1:], dim=16, factor=1)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opvxKZZMVv-j"
      },
      "source": [
        "model.load_weights('/content/weights.h5')\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D9zagwjXHq9"
      },
      "source": [
        "model.compile(optimizer=Adam(lr=0.000001), loss=f1_loss,metrics=['accuracy'])\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17kgi_pSYU6s",
        "outputId": "91ebd9d3-ad95-4a21-db36-e1547c233dc2"
      },
      "source": [
        "history=model.fit(x, y, validation_split=0.2, epochs=10000, batch_size=8)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 7501/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6610 - accuracy: 0.9729 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7502/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6783 - accuracy: 0.9724 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 7503/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6617 - accuracy: 0.9717 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7504/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6537 - accuracy: 0.9731 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7505/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6704 - accuracy: 0.9731 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7506/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6912 - accuracy: 0.9740 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7507/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6760 - accuracy: 0.9726 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7508/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6789 - accuracy: 0.9720 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7509/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6338 - accuracy: 0.9732 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7510/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6787 - accuracy: 0.9726 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7511/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6876 - accuracy: 0.9719 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7512/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6847 - accuracy: 0.9736 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7513/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6319 - accuracy: 0.9752 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7514/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6604 - accuracy: 0.9724 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7515/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6517 - accuracy: 0.9732 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7516/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6765 - accuracy: 0.9736 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7517/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6650 - accuracy: 0.9735 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7518/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6653 - accuracy: 0.9725 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7519/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6652 - accuracy: 0.9718 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7520/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6594 - accuracy: 0.9728 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 7521/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6781 - accuracy: 0.9728 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7522/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6741 - accuracy: 0.9733 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7523/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6625 - accuracy: 0.9735 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 7524/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6709 - accuracy: 0.9722 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7525/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6670 - accuracy: 0.9735 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7526/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6714 - accuracy: 0.9729 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7527/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6535 - accuracy: 0.9728 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7528/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6519 - accuracy: 0.9738 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7529/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6731 - accuracy: 0.9734 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7530/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6576 - accuracy: 0.9722 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 7531/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6495 - accuracy: 0.9745 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 7532/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6589 - accuracy: 0.9720 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7533/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6563 - accuracy: 0.9731 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7534/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6517 - accuracy: 0.9734 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 7535/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6711 - accuracy: 0.9734 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7536/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6762 - accuracy: 0.9731 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7537/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6604 - accuracy: 0.9731 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 7538/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6707 - accuracy: 0.9742 - val_loss: -0.5177 - val_accuracy: 0.9690\n",
            "Epoch 7539/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6728 - accuracy: 0.9735 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7540/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6665 - accuracy: 0.9720 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7541/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6331 - accuracy: 0.9741 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7542/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6623 - accuracy: 0.9733 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7543/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6676 - accuracy: 0.9730 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7544/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6230 - accuracy: 0.9724 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 7545/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6430 - accuracy: 0.9735 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7546/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6483 - accuracy: 0.9728 - val_loss: -0.5177 - val_accuracy: 0.9690\n",
            "Epoch 7547/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6736 - accuracy: 0.9730 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7548/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6885 - accuracy: 0.9719 - val_loss: -0.5177 - val_accuracy: 0.9690\n",
            "Epoch 7549/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6649 - accuracy: 0.9733 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 7550/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6851 - accuracy: 0.9732 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7551/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6642 - accuracy: 0.9735 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 7552/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6494 - accuracy: 0.9732 - val_loss: -0.5178 - val_accuracy: 0.9690\n",
            "Epoch 7553/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6728 - accuracy: 0.9739 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7554/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6621 - accuracy: 0.9723 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7555/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6377 - accuracy: 0.9725 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7556/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6808 - accuracy: 0.9733 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7557/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6571 - accuracy: 0.9731 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7558/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6612 - accuracy: 0.9724 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7559/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6712 - accuracy: 0.9734 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7560/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6708 - accuracy: 0.9735 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7561/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6560 - accuracy: 0.9721 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7562/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6661 - accuracy: 0.9738 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7563/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6525 - accuracy: 0.9734 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 7564/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6667 - accuracy: 0.9728 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 7565/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6628 - accuracy: 0.9740 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7566/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6737 - accuracy: 0.9730 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7567/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6388 - accuracy: 0.9738 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7568/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6833 - accuracy: 0.9722 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7569/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6837 - accuracy: 0.9735 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7570/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6497 - accuracy: 0.9749 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7571/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6559 - accuracy: 0.9728 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7572/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6789 - accuracy: 0.9732 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7573/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6551 - accuracy: 0.9744 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7574/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6643 - accuracy: 0.9734 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7575/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6337 - accuracy: 0.9735 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7576/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6759 - accuracy: 0.9735 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7577/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6509 - accuracy: 0.9741 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7578/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6780 - accuracy: 0.9722 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7579/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6763 - accuracy: 0.9742 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7580/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6668 - accuracy: 0.9728 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7581/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6687 - accuracy: 0.9721 - val_loss: -0.5188 - val_accuracy: 0.9690\n",
            "Epoch 7582/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6771 - accuracy: 0.9727 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7583/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6797 - accuracy: 0.9727 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7584/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6606 - accuracy: 0.9730 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7585/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6742 - accuracy: 0.9730 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7586/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6662 - accuracy: 0.9732 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7587/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6603 - accuracy: 0.9733 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7588/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6464 - accuracy: 0.9733 - val_loss: -0.5178 - val_accuracy: 0.9690\n",
            "Epoch 7589/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6609 - accuracy: 0.9734 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7590/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6798 - accuracy: 0.9722 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7591/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6487 - accuracy: 0.9739 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 7592/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6790 - accuracy: 0.9724 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7593/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6790 - accuracy: 0.9722 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 7594/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6629 - accuracy: 0.9730 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7595/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6773 - accuracy: 0.9722 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7596/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6390 - accuracy: 0.9730 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 7597/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6495 - accuracy: 0.9729 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7598/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6613 - accuracy: 0.9731 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7599/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6686 - accuracy: 0.9723 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7600/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6749 - accuracy: 0.9724 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7601/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6656 - accuracy: 0.9724 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 7602/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6750 - accuracy: 0.9737 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7603/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6594 - accuracy: 0.9720 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7604/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6680 - accuracy: 0.9737 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7605/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6440 - accuracy: 0.9736 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7606/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6503 - accuracy: 0.9738 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7607/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6554 - accuracy: 0.9723 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7608/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6544 - accuracy: 0.9733 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7609/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6562 - accuracy: 0.9739 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 7610/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6742 - accuracy: 0.9722 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7611/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6667 - accuracy: 0.9729 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7612/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6688 - accuracy: 0.9740 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 7613/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6570 - accuracy: 0.9753 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7614/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6528 - accuracy: 0.9742 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 7615/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6667 - accuracy: 0.9723 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7616/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6784 - accuracy: 0.9738 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7617/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6597 - accuracy: 0.9736 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7618/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6779 - accuracy: 0.9742 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7619/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6393 - accuracy: 0.9740 - val_loss: -0.5180 - val_accuracy: 0.9690\n",
            "Epoch 7620/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6658 - accuracy: 0.9734 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7621/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6471 - accuracy: 0.9720 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7622/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6643 - accuracy: 0.9716 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7623/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6536 - accuracy: 0.9729 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 7624/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6679 - accuracy: 0.9715 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7625/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6675 - accuracy: 0.9730 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7626/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6905 - accuracy: 0.9723 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 7627/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6663 - accuracy: 0.9749 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 7628/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6594 - accuracy: 0.9732 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7629/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6419 - accuracy: 0.9740 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7630/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6815 - accuracy: 0.9727 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7631/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6440 - accuracy: 0.9731 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7632/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6546 - accuracy: 0.9746 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7633/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6652 - accuracy: 0.9724 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7634/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6527 - accuracy: 0.9742 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7635/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6826 - accuracy: 0.9731 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7636/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6796 - accuracy: 0.9725 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7637/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6516 - accuracy: 0.9728 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7638/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6577 - accuracy: 0.9730 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7639/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6501 - accuracy: 0.9727 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7640/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6523 - accuracy: 0.9729 - val_loss: -0.5178 - val_accuracy: 0.9690\n",
            "Epoch 7641/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6676 - accuracy: 0.9738 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7642/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6633 - accuracy: 0.9738 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7643/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6672 - accuracy: 0.9734 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7644/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6682 - accuracy: 0.9720 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7645/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6572 - accuracy: 0.9743 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7646/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6456 - accuracy: 0.9736 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7647/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6749 - accuracy: 0.9726 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7648/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6738 - accuracy: 0.9723 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7649/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6473 - accuracy: 0.9731 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7650/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6733 - accuracy: 0.9722 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7651/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6764 - accuracy: 0.9728 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7652/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6730 - accuracy: 0.9733 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7653/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6637 - accuracy: 0.9717 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7654/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6734 - accuracy: 0.9750 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7655/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6141 - accuracy: 0.9732 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 7656/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6730 - accuracy: 0.9730 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7657/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6644 - accuracy: 0.9733 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7658/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6681 - accuracy: 0.9735 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7659/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6810 - accuracy: 0.9729 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7660/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6653 - accuracy: 0.9732 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7661/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6607 - accuracy: 0.9734 - val_loss: -0.5180 - val_accuracy: 0.9690\n",
            "Epoch 7662/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6672 - accuracy: 0.9726 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7663/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6488 - accuracy: 0.9749 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7664/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6599 - accuracy: 0.9726 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7665/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6621 - accuracy: 0.9741 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7666/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6810 - accuracy: 0.9731 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7667/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6652 - accuracy: 0.9728 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7668/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6773 - accuracy: 0.9744 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7669/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6776 - accuracy: 0.9728 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7670/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6485 - accuracy: 0.9740 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7671/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6892 - accuracy: 0.9733 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7672/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6650 - accuracy: 0.9723 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7673/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6498 - accuracy: 0.9743 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7674/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6625 - accuracy: 0.9720 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7675/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6730 - accuracy: 0.9734 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7676/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6699 - accuracy: 0.9743 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7677/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6564 - accuracy: 0.9736 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 7678/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6732 - accuracy: 0.9729 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7679/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6612 - accuracy: 0.9742 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7680/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6812 - accuracy: 0.9725 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 7681/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6902 - accuracy: 0.9730 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7682/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6648 - accuracy: 0.9727 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7683/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6655 - accuracy: 0.9722 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7684/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6787 - accuracy: 0.9722 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7685/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6860 - accuracy: 0.9741 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7686/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6543 - accuracy: 0.9742 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7687/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6714 - accuracy: 0.9722 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7688/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6914 - accuracy: 0.9734 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7689/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6850 - accuracy: 0.9719 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7690/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6773 - accuracy: 0.9728 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7691/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6682 - accuracy: 0.9733 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7692/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6679 - accuracy: 0.9733 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7693/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6718 - accuracy: 0.9732 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7694/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6729 - accuracy: 0.9739 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7695/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6706 - accuracy: 0.9740 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 7696/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6655 - accuracy: 0.9746 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7697/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6129 - accuracy: 0.9742 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 7698/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6644 - accuracy: 0.9728 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 7699/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6552 - accuracy: 0.9732 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7700/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6227 - accuracy: 0.9744 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7701/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6758 - accuracy: 0.9735 - val_loss: -0.5181 - val_accuracy: 0.9690\n",
            "Epoch 7702/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6495 - accuracy: 0.9731 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7703/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6633 - accuracy: 0.9730 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7704/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6661 - accuracy: 0.9740 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7705/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6695 - accuracy: 0.9732 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 7706/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6769 - accuracy: 0.9729 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7707/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6652 - accuracy: 0.9748 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7708/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6584 - accuracy: 0.9747 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7709/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6755 - accuracy: 0.9734 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 7710/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6681 - accuracy: 0.9738 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7711/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6651 - accuracy: 0.9726 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7712/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6682 - accuracy: 0.9734 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7713/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6613 - accuracy: 0.9751 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7714/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6796 - accuracy: 0.9718 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7715/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6655 - accuracy: 0.9734 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7716/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6580 - accuracy: 0.9715 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7717/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6765 - accuracy: 0.9737 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7718/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6816 - accuracy: 0.9732 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7719/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6669 - accuracy: 0.9732 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7720/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6520 - accuracy: 0.9732 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7721/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6761 - accuracy: 0.9716 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7722/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6689 - accuracy: 0.9733 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7723/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6666 - accuracy: 0.9727 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7724/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6557 - accuracy: 0.9735 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7725/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6586 - accuracy: 0.9743 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7726/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6854 - accuracy: 0.9725 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7727/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6548 - accuracy: 0.9734 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7728/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6395 - accuracy: 0.9740 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7729/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6922 - accuracy: 0.9727 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 7730/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6876 - accuracy: 0.9737 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 7731/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6618 - accuracy: 0.9726 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7732/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6508 - accuracy: 0.9740 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7733/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6786 - accuracy: 0.9740 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7734/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6604 - accuracy: 0.9746 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7735/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6465 - accuracy: 0.9746 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7736/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6671 - accuracy: 0.9741 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7737/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6643 - accuracy: 0.9746 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7738/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6461 - accuracy: 0.9715 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 7739/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6763 - accuracy: 0.9734 - val_loss: -0.5178 - val_accuracy: 0.9690\n",
            "Epoch 7740/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6126 - accuracy: 0.9750 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 7741/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6725 - accuracy: 0.9730 - val_loss: -0.5177 - val_accuracy: 0.9690\n",
            "Epoch 7742/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6861 - accuracy: 0.9725 - val_loss: -0.5181 - val_accuracy: 0.9690\n",
            "Epoch 7743/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6660 - accuracy: 0.9724 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7744/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6769 - accuracy: 0.9731 - val_loss: -0.5179 - val_accuracy: 0.9690\n",
            "Epoch 7745/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6487 - accuracy: 0.9730 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7746/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6907 - accuracy: 0.9737 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 7747/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6436 - accuracy: 0.9736 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 7748/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6613 - accuracy: 0.9729 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7749/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6618 - accuracy: 0.9732 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7750/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6745 - accuracy: 0.9734 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7751/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6788 - accuracy: 0.9731 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7752/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6737 - accuracy: 0.9727 - val_loss: -0.5177 - val_accuracy: 0.9690\n",
            "Epoch 7753/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6593 - accuracy: 0.9742 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7754/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6766 - accuracy: 0.9738 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7755/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6777 - accuracy: 0.9731 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7756/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6576 - accuracy: 0.9727 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7757/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6778 - accuracy: 0.9738 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7758/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6707 - accuracy: 0.9726 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7759/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6689 - accuracy: 0.9728 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7760/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6673 - accuracy: 0.9720 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7761/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6568 - accuracy: 0.9733 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7762/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6629 - accuracy: 0.9727 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7763/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6725 - accuracy: 0.9735 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7764/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6526 - accuracy: 0.9728 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7765/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6843 - accuracy: 0.9727 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7766/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6875 - accuracy: 0.9721 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 7767/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6648 - accuracy: 0.9728 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 7768/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6694 - accuracy: 0.9719 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7769/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6732 - accuracy: 0.9716 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7770/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6811 - accuracy: 0.9732 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7771/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6533 - accuracy: 0.9736 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7772/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6646 - accuracy: 0.9729 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7773/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6457 - accuracy: 0.9741 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7774/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6660 - accuracy: 0.9731 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7775/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6769 - accuracy: 0.9716 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7776/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6853 - accuracy: 0.9738 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7777/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6691 - accuracy: 0.9729 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7778/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6707 - accuracy: 0.9733 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7779/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6827 - accuracy: 0.9732 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7780/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6639 - accuracy: 0.9718 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7781/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6782 - accuracy: 0.9735 - val_loss: -0.5178 - val_accuracy: 0.9690\n",
            "Epoch 7782/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6746 - accuracy: 0.9720 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 7783/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6472 - accuracy: 0.9729 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7784/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6648 - accuracy: 0.9718 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7785/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6681 - accuracy: 0.9726 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 7786/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6569 - accuracy: 0.9748 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 7787/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6745 - accuracy: 0.9736 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 7788/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6647 - accuracy: 0.9722 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 7789/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6757 - accuracy: 0.9734 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7790/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6584 - accuracy: 0.9727 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7791/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6709 - accuracy: 0.9732 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 7792/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6597 - accuracy: 0.9732 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7793/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6550 - accuracy: 0.9731 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 7794/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6641 - accuracy: 0.9735 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7795/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6622 - accuracy: 0.9738 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7796/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6731 - accuracy: 0.9736 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 7797/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6702 - accuracy: 0.9725 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7798/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6843 - accuracy: 0.9729 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7799/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6683 - accuracy: 0.9736 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 7800/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6804 - accuracy: 0.9730 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 7801/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6448 - accuracy: 0.9732 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7802/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6541 - accuracy: 0.9740 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7803/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6654 - accuracy: 0.9748 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7804/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6574 - accuracy: 0.9733 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7805/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6836 - accuracy: 0.9720 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7806/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6510 - accuracy: 0.9726 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 7807/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6537 - accuracy: 0.9742 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7808/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6610 - accuracy: 0.9733 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7809/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6508 - accuracy: 0.9720 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7810/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6785 - accuracy: 0.9727 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7811/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6798 - accuracy: 0.9736 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7812/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6726 - accuracy: 0.9734 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7813/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6717 - accuracy: 0.9730 - val_loss: -0.5179 - val_accuracy: 0.9690\n",
            "Epoch 7814/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6729 - accuracy: 0.9720 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7815/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6645 - accuracy: 0.9721 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 7816/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6760 - accuracy: 0.9723 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7817/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6720 - accuracy: 0.9729 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7818/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6561 - accuracy: 0.9734 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7819/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6661 - accuracy: 0.9733 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 7820/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6576 - accuracy: 0.9724 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7821/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6708 - accuracy: 0.9729 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7822/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6531 - accuracy: 0.9728 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7823/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6770 - accuracy: 0.9736 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 7824/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6687 - accuracy: 0.9726 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7825/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6479 - accuracy: 0.9750 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7826/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6576 - accuracy: 0.9733 - val_loss: -0.5179 - val_accuracy: 0.9690\n",
            "Epoch 7827/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6735 - accuracy: 0.9724 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 7828/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6680 - accuracy: 0.9740 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7829/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6684 - accuracy: 0.9728 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7830/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6257 - accuracy: 0.9744 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7831/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6689 - accuracy: 0.9741 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7832/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6749 - accuracy: 0.9721 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7833/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6317 - accuracy: 0.9737 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7834/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6514 - accuracy: 0.9732 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7835/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6808 - accuracy: 0.9752 - val_loss: -0.5179 - val_accuracy: 0.9690\n",
            "Epoch 7836/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6613 - accuracy: 0.9732 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7837/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6525 - accuracy: 0.9732 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7838/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6827 - accuracy: 0.9720 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7839/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6537 - accuracy: 0.9732 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7840/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6745 - accuracy: 0.9727 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 7841/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6688 - accuracy: 0.9742 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7842/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6837 - accuracy: 0.9738 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7843/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6781 - accuracy: 0.9740 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7844/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6783 - accuracy: 0.9731 - val_loss: -0.5178 - val_accuracy: 0.9690\n",
            "Epoch 7845/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6740 - accuracy: 0.9723 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 7846/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6649 - accuracy: 0.9737 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7847/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6622 - accuracy: 0.9724 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7848/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6591 - accuracy: 0.9738 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7849/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6726 - accuracy: 0.9712 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7850/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6728 - accuracy: 0.9733 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7851/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6816 - accuracy: 0.9721 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7852/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6788 - accuracy: 0.9714 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7853/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6712 - accuracy: 0.9735 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7854/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6796 - accuracy: 0.9718 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7855/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6653 - accuracy: 0.9741 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7856/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6648 - accuracy: 0.9738 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7857/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6520 - accuracy: 0.9745 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 7858/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6869 - accuracy: 0.9741 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7859/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6587 - accuracy: 0.9744 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7860/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6628 - accuracy: 0.9731 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7861/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6562 - accuracy: 0.9720 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7862/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6753 - accuracy: 0.9719 - val_loss: -0.5177 - val_accuracy: 0.9690\n",
            "Epoch 7863/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6730 - accuracy: 0.9721 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7864/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6795 - accuracy: 0.9731 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7865/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6560 - accuracy: 0.9734 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7866/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6674 - accuracy: 0.9735 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 7867/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6342 - accuracy: 0.9733 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7868/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6573 - accuracy: 0.9728 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7869/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6714 - accuracy: 0.9731 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7870/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6434 - accuracy: 0.9733 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 7871/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6610 - accuracy: 0.9731 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7872/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6639 - accuracy: 0.9737 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 7873/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6692 - accuracy: 0.9733 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7874/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6758 - accuracy: 0.9738 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7875/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6592 - accuracy: 0.9740 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7876/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6874 - accuracy: 0.9729 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7877/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6763 - accuracy: 0.9736 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 7878/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6610 - accuracy: 0.9716 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7879/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6814 - accuracy: 0.9714 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7880/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6632 - accuracy: 0.9733 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7881/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6718 - accuracy: 0.9733 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7882/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6598 - accuracy: 0.9722 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7883/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6546 - accuracy: 0.9730 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7884/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6699 - accuracy: 0.9738 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7885/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6250 - accuracy: 0.9733 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7886/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6711 - accuracy: 0.9729 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7887/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6695 - accuracy: 0.9727 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7888/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6858 - accuracy: 0.9735 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 7889/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6802 - accuracy: 0.9730 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7890/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6742 - accuracy: 0.9739 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7891/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6769 - accuracy: 0.9721 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7892/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6732 - accuracy: 0.9732 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7893/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6635 - accuracy: 0.9716 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7894/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6744 - accuracy: 0.9744 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7895/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6823 - accuracy: 0.9730 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7896/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6686 - accuracy: 0.9734 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 7897/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6456 - accuracy: 0.9739 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7898/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6713 - accuracy: 0.9716 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7899/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6611 - accuracy: 0.9735 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 7900/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6416 - accuracy: 0.9735 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7901/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6643 - accuracy: 0.9740 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7902/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6475 - accuracy: 0.9738 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7903/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6716 - accuracy: 0.9728 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7904/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6690 - accuracy: 0.9728 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7905/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6624 - accuracy: 0.9743 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7906/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6708 - accuracy: 0.9711 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7907/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6733 - accuracy: 0.9732 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 7908/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6720 - accuracy: 0.9730 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7909/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6780 - accuracy: 0.9722 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7910/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6755 - accuracy: 0.9732 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7911/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6768 - accuracy: 0.9727 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7912/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6654 - accuracy: 0.9734 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7913/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6675 - accuracy: 0.9730 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7914/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6623 - accuracy: 0.9719 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7915/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6705 - accuracy: 0.9732 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7916/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6650 - accuracy: 0.9720 - val_loss: -0.5180 - val_accuracy: 0.9690\n",
            "Epoch 7917/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6760 - accuracy: 0.9741 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7918/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6765 - accuracy: 0.9715 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7919/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6662 - accuracy: 0.9732 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7920/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6792 - accuracy: 0.9729 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7921/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6764 - accuracy: 0.9735 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7922/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6594 - accuracy: 0.9744 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7923/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6758 - accuracy: 0.9732 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7924/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6715 - accuracy: 0.9729 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7925/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6676 - accuracy: 0.9731 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7926/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6844 - accuracy: 0.9749 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7927/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6608 - accuracy: 0.9737 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7928/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6523 - accuracy: 0.9718 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 7929/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6676 - accuracy: 0.9740 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7930/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6706 - accuracy: 0.9720 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7931/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6521 - accuracy: 0.9744 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7932/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6839 - accuracy: 0.9743 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7933/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6573 - accuracy: 0.9735 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7934/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6608 - accuracy: 0.9731 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7935/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6475 - accuracy: 0.9734 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7936/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6755 - accuracy: 0.9716 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7937/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6690 - accuracy: 0.9743 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7938/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6831 - accuracy: 0.9725 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 7939/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6650 - accuracy: 0.9731 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7940/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6599 - accuracy: 0.9731 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7941/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6803 - accuracy: 0.9723 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7942/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6614 - accuracy: 0.9735 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7943/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6661 - accuracy: 0.9701 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7944/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6635 - accuracy: 0.9743 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7945/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6729 - accuracy: 0.9717 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7946/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6678 - accuracy: 0.9728 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7947/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6636 - accuracy: 0.9734 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7948/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6676 - accuracy: 0.9722 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7949/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6630 - accuracy: 0.9740 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7950/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6717 - accuracy: 0.9731 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7951/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6843 - accuracy: 0.9742 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7952/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6804 - accuracy: 0.9725 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7953/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6400 - accuracy: 0.9746 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 7954/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6562 - accuracy: 0.9736 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7955/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6714 - accuracy: 0.9718 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7956/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6825 - accuracy: 0.9724 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7957/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6647 - accuracy: 0.9714 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7958/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6712 - accuracy: 0.9730 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7959/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6550 - accuracy: 0.9730 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7960/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6641 - accuracy: 0.9744 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7961/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6433 - accuracy: 0.9737 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7962/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6717 - accuracy: 0.9745 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7963/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6534 - accuracy: 0.9733 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7964/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6691 - accuracy: 0.9728 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7965/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6531 - accuracy: 0.9726 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7966/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6545 - accuracy: 0.9733 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7967/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6894 - accuracy: 0.9721 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7968/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6554 - accuracy: 0.9743 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7969/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6613 - accuracy: 0.9748 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7970/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6808 - accuracy: 0.9728 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 7971/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6840 - accuracy: 0.9731 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7972/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6695 - accuracy: 0.9717 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7973/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6713 - accuracy: 0.9732 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7974/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6674 - accuracy: 0.9730 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7975/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6766 - accuracy: 0.9734 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7976/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6643 - accuracy: 0.9724 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7977/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6812 - accuracy: 0.9717 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 7978/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6609 - accuracy: 0.9742 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7979/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6709 - accuracy: 0.9734 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7980/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6685 - accuracy: 0.9731 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7981/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6616 - accuracy: 0.9734 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7982/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6678 - accuracy: 0.9724 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 7983/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6556 - accuracy: 0.9742 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7984/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6638 - accuracy: 0.9729 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7985/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6686 - accuracy: 0.9729 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7986/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6879 - accuracy: 0.9724 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 7987/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6751 - accuracy: 0.9717 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 7988/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6537 - accuracy: 0.9748 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 7989/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6638 - accuracy: 0.9734 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7990/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6783 - accuracy: 0.9731 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 7991/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6718 - accuracy: 0.9720 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7992/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6783 - accuracy: 0.9727 - val_loss: -0.5177 - val_accuracy: 0.9690\n",
            "Epoch 7993/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6451 - accuracy: 0.9739 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 7994/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6503 - accuracy: 0.9740 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 7995/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6562 - accuracy: 0.9734 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 7996/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6627 - accuracy: 0.9726 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 7997/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6759 - accuracy: 0.9735 - val_loss: -0.5178 - val_accuracy: 0.9690\n",
            "Epoch 7998/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6781 - accuracy: 0.9718 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 7999/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6830 - accuracy: 0.9730 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8000/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6925 - accuracy: 0.9734 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8001/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6588 - accuracy: 0.9731 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8002/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6671 - accuracy: 0.9733 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8003/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6594 - accuracy: 0.9755 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8004/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6827 - accuracy: 0.9729 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8005/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6590 - accuracy: 0.9733 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8006/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6918 - accuracy: 0.9727 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8007/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6719 - accuracy: 0.9722 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8008/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6754 - accuracy: 0.9730 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8009/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6554 - accuracy: 0.9743 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 8010/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6804 - accuracy: 0.9735 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8011/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6769 - accuracy: 0.9725 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8012/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6762 - accuracy: 0.9720 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8013/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6610 - accuracy: 0.9743 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8014/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6777 - accuracy: 0.9728 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8015/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6604 - accuracy: 0.9733 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8016/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6739 - accuracy: 0.9728 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8017/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6852 - accuracy: 0.9736 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8018/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6644 - accuracy: 0.9737 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8019/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6653 - accuracy: 0.9730 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8020/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6700 - accuracy: 0.9730 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8021/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6680 - accuracy: 0.9726 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8022/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6753 - accuracy: 0.9731 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8023/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6935 - accuracy: 0.9738 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8024/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6809 - accuracy: 0.9738 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8025/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6567 - accuracy: 0.9725 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8026/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6923 - accuracy: 0.9739 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8027/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6411 - accuracy: 0.9738 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8028/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6894 - accuracy: 0.9725 - val_loss: -0.5180 - val_accuracy: 0.9690\n",
            "Epoch 8029/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6506 - accuracy: 0.9730 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8030/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6674 - accuracy: 0.9737 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8031/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6559 - accuracy: 0.9752 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8032/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6808 - accuracy: 0.9723 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8033/10000\n",
            "22/22 [==============================] - 1s 42ms/step - loss: -0.6731 - accuracy: 0.9736 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8034/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6858 - accuracy: 0.9725 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8035/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6586 - accuracy: 0.9722 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8036/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6787 - accuracy: 0.9732 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8037/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6497 - accuracy: 0.9738 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8038/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6640 - accuracy: 0.9733 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8039/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6566 - accuracy: 0.9740 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8040/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6631 - accuracy: 0.9731 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8041/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6559 - accuracy: 0.9731 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8042/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6545 - accuracy: 0.9726 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8043/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6706 - accuracy: 0.9740 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8044/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6443 - accuracy: 0.9744 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8045/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6651 - accuracy: 0.9722 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8046/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6681 - accuracy: 0.9736 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 8047/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6427 - accuracy: 0.9725 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8048/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6398 - accuracy: 0.9730 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8049/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6746 - accuracy: 0.9735 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8050/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6660 - accuracy: 0.9730 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8051/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6647 - accuracy: 0.9735 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8052/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6505 - accuracy: 0.9736 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 8053/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6713 - accuracy: 0.9742 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8054/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6574 - accuracy: 0.9736 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8055/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6687 - accuracy: 0.9732 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8056/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6323 - accuracy: 0.9734 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8057/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6731 - accuracy: 0.9732 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8058/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6542 - accuracy: 0.9714 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8059/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6819 - accuracy: 0.9718 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8060/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6571 - accuracy: 0.9747 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8061/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6664 - accuracy: 0.9730 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8062/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6597 - accuracy: 0.9736 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8063/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6284 - accuracy: 0.9745 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8064/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6726 - accuracy: 0.9738 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8065/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6785 - accuracy: 0.9733 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8066/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6795 - accuracy: 0.9735 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 8067/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6754 - accuracy: 0.9728 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8068/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6807 - accuracy: 0.9736 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8069/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6663 - accuracy: 0.9741 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8070/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6567 - accuracy: 0.9733 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8071/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6559 - accuracy: 0.9738 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8072/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6365 - accuracy: 0.9727 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8073/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6847 - accuracy: 0.9732 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8074/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6609 - accuracy: 0.9724 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8075/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6825 - accuracy: 0.9723 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8076/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6624 - accuracy: 0.9737 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8077/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6524 - accuracy: 0.9727 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8078/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6646 - accuracy: 0.9736 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8079/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6496 - accuracy: 0.9735 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8080/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6609 - accuracy: 0.9730 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8081/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6797 - accuracy: 0.9731 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 8082/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6314 - accuracy: 0.9756 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 8083/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6683 - accuracy: 0.9729 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8084/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6736 - accuracy: 0.9738 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8085/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6772 - accuracy: 0.9728 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8086/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6799 - accuracy: 0.9727 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8087/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6343 - accuracy: 0.9746 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8088/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6777 - accuracy: 0.9721 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8089/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6732 - accuracy: 0.9739 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8090/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6685 - accuracy: 0.9732 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8091/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6739 - accuracy: 0.9713 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8092/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6494 - accuracy: 0.9730 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8093/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6480 - accuracy: 0.9731 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8094/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6619 - accuracy: 0.9738 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8095/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6533 - accuracy: 0.9731 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8096/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6828 - accuracy: 0.9733 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8097/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6717 - accuracy: 0.9722 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8098/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6523 - accuracy: 0.9746 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8099/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6396 - accuracy: 0.9735 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8100/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6620 - accuracy: 0.9747 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8101/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6512 - accuracy: 0.9732 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8102/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6605 - accuracy: 0.9726 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8103/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6635 - accuracy: 0.9738 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8104/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6639 - accuracy: 0.9746 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8105/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6767 - accuracy: 0.9722 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 8106/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6582 - accuracy: 0.9735 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8107/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6547 - accuracy: 0.9735 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 8108/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6819 - accuracy: 0.9717 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8109/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6738 - accuracy: 0.9727 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8110/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6439 - accuracy: 0.9716 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8111/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6630 - accuracy: 0.9726 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8112/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6711 - accuracy: 0.9722 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8113/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6618 - accuracy: 0.9734 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8114/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6428 - accuracy: 0.9745 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8115/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6673 - accuracy: 0.9717 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8116/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6828 - accuracy: 0.9719 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8117/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6398 - accuracy: 0.9743 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8118/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6701 - accuracy: 0.9718 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8119/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6667 - accuracy: 0.9740 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8120/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6593 - accuracy: 0.9736 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8121/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6612 - accuracy: 0.9732 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8122/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6632 - accuracy: 0.9727 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8123/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6774 - accuracy: 0.9719 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8124/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6672 - accuracy: 0.9741 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8125/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6529 - accuracy: 0.9723 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8126/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6922 - accuracy: 0.9734 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8127/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6729 - accuracy: 0.9720 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8128/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6654 - accuracy: 0.9728 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8129/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6690 - accuracy: 0.9732 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8130/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6619 - accuracy: 0.9734 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8131/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6937 - accuracy: 0.9713 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8132/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6804 - accuracy: 0.9723 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8133/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6679 - accuracy: 0.9730 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8134/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6679 - accuracy: 0.9728 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8135/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6635 - accuracy: 0.9741 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8136/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6832 - accuracy: 0.9723 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8137/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6720 - accuracy: 0.9721 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8138/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6800 - accuracy: 0.9738 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8139/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6682 - accuracy: 0.9728 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8140/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6460 - accuracy: 0.9742 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8141/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6575 - accuracy: 0.9737 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8142/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6661 - accuracy: 0.9728 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8143/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6699 - accuracy: 0.9732 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8144/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6600 - accuracy: 0.9736 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8145/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6836 - accuracy: 0.9723 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8146/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6871 - accuracy: 0.9724 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 8147/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6711 - accuracy: 0.9717 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8148/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6696 - accuracy: 0.9742 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8149/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6726 - accuracy: 0.9745 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8150/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6755 - accuracy: 0.9726 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8151/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6753 - accuracy: 0.9734 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8152/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6518 - accuracy: 0.9738 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 8153/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6709 - accuracy: 0.9724 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8154/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6901 - accuracy: 0.9725 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8155/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6488 - accuracy: 0.9745 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8156/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6619 - accuracy: 0.9738 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8157/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6540 - accuracy: 0.9731 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8158/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6711 - accuracy: 0.9725 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8159/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6782 - accuracy: 0.9726 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8160/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6790 - accuracy: 0.9737 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8161/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6635 - accuracy: 0.9722 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8162/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6443 - accuracy: 0.9731 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8163/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6512 - accuracy: 0.9727 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8164/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6916 - accuracy: 0.9735 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8165/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6812 - accuracy: 0.9727 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8166/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6597 - accuracy: 0.9720 - val_loss: -0.5179 - val_accuracy: 0.9690\n",
            "Epoch 8167/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6901 - accuracy: 0.9724 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8168/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6823 - accuracy: 0.9723 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 8169/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6784 - accuracy: 0.9723 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 8170/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6929 - accuracy: 0.9722 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8171/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6726 - accuracy: 0.9726 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8172/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6845 - accuracy: 0.9725 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8173/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6748 - accuracy: 0.9713 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8174/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6540 - accuracy: 0.9736 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8175/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6443 - accuracy: 0.9749 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 8176/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6770 - accuracy: 0.9730 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8177/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6823 - accuracy: 0.9718 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8178/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6868 - accuracy: 0.9721 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8179/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6362 - accuracy: 0.9743 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8180/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6721 - accuracy: 0.9744 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8181/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6719 - accuracy: 0.9738 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8182/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6662 - accuracy: 0.9730 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8183/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6556 - accuracy: 0.9733 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8184/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6673 - accuracy: 0.9730 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8185/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6209 - accuracy: 0.9745 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8186/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6661 - accuracy: 0.9727 - val_loss: -0.5180 - val_accuracy: 0.9690\n",
            "Epoch 8187/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6646 - accuracy: 0.9730 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8188/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6733 - accuracy: 0.9716 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8189/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6503 - accuracy: 0.9734 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8190/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6683 - accuracy: 0.9736 - val_loss: -0.5177 - val_accuracy: 0.9690\n",
            "Epoch 8191/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6614 - accuracy: 0.9733 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8192/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6716 - accuracy: 0.9737 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8193/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6660 - accuracy: 0.9738 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8194/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6765 - accuracy: 0.9736 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8195/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6714 - accuracy: 0.9729 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8196/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6468 - accuracy: 0.9730 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8197/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6646 - accuracy: 0.9724 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8198/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6561 - accuracy: 0.9748 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8199/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6813 - accuracy: 0.9719 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8200/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6785 - accuracy: 0.9736 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8201/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6578 - accuracy: 0.9724 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8202/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6730 - accuracy: 0.9731 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8203/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6585 - accuracy: 0.9732 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8204/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6286 - accuracy: 0.9737 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8205/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6782 - accuracy: 0.9730 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8206/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6575 - accuracy: 0.9748 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8207/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6730 - accuracy: 0.9737 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8208/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6624 - accuracy: 0.9732 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8209/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6479 - accuracy: 0.9718 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8210/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6266 - accuracy: 0.9737 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8211/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6741 - accuracy: 0.9730 - val_loss: -0.5185 - val_accuracy: 0.9690\n",
            "Epoch 8212/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6773 - accuracy: 0.9719 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8213/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6765 - accuracy: 0.9717 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8214/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6584 - accuracy: 0.9730 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8215/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6728 - accuracy: 0.9733 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8216/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6687 - accuracy: 0.9732 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8217/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6857 - accuracy: 0.9727 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8218/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6634 - accuracy: 0.9728 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8219/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6929 - accuracy: 0.9724 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8220/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6847 - accuracy: 0.9725 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8221/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6795 - accuracy: 0.9737 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8222/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6860 - accuracy: 0.9732 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8223/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6865 - accuracy: 0.9728 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8224/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6622 - accuracy: 0.9720 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8225/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6763 - accuracy: 0.9734 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8226/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6750 - accuracy: 0.9725 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8227/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6812 - accuracy: 0.9724 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8228/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6679 - accuracy: 0.9731 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8229/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6502 - accuracy: 0.9726 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8230/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6602 - accuracy: 0.9750 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8231/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6664 - accuracy: 0.9719 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8232/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6656 - accuracy: 0.9718 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8233/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6708 - accuracy: 0.9726 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8234/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6672 - accuracy: 0.9738 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8235/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6843 - accuracy: 0.9738 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8236/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6757 - accuracy: 0.9723 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8237/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6764 - accuracy: 0.9716 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8238/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6840 - accuracy: 0.9723 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8239/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6898 - accuracy: 0.9731 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8240/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6659 - accuracy: 0.9714 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8241/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6589 - accuracy: 0.9735 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 8242/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6691 - accuracy: 0.9735 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8243/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6581 - accuracy: 0.9739 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8244/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6598 - accuracy: 0.9719 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8245/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6829 - accuracy: 0.9734 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8246/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6498 - accuracy: 0.9744 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8247/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6739 - accuracy: 0.9735 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8248/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6819 - accuracy: 0.9735 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8249/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6633 - accuracy: 0.9734 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8250/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6657 - accuracy: 0.9742 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8251/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6839 - accuracy: 0.9738 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 8252/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6688 - accuracy: 0.9741 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8253/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6681 - accuracy: 0.9738 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8254/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6815 - accuracy: 0.9734 - val_loss: -0.5177 - val_accuracy: 0.9690\n",
            "Epoch 8255/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6472 - accuracy: 0.9741 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8256/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6781 - accuracy: 0.9739 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8257/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6754 - accuracy: 0.9717 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 8258/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6433 - accuracy: 0.9743 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8259/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6550 - accuracy: 0.9733 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8260/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6702 - accuracy: 0.9727 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8261/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6739 - accuracy: 0.9713 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8262/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6457 - accuracy: 0.9734 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8263/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6493 - accuracy: 0.9721 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8264/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6764 - accuracy: 0.9718 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8265/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6603 - accuracy: 0.9728 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8266/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6540 - accuracy: 0.9724 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8267/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6825 - accuracy: 0.9729 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8268/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6768 - accuracy: 0.9727 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8269/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6575 - accuracy: 0.9739 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8270/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6686 - accuracy: 0.9730 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8271/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6513 - accuracy: 0.9728 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8272/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6810 - accuracy: 0.9734 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8273/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6820 - accuracy: 0.9717 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8274/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6604 - accuracy: 0.9735 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8275/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6743 - accuracy: 0.9723 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8276/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6696 - accuracy: 0.9718 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8277/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6704 - accuracy: 0.9721 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 8278/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6880 - accuracy: 0.9712 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8279/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6687 - accuracy: 0.9738 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8280/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6623 - accuracy: 0.9727 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8281/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6801 - accuracy: 0.9723 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8282/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6752 - accuracy: 0.9734 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8283/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6769 - accuracy: 0.9729 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8284/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6713 - accuracy: 0.9728 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8285/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6872 - accuracy: 0.9736 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8286/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6701 - accuracy: 0.9728 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8287/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6762 - accuracy: 0.9726 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8288/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6744 - accuracy: 0.9740 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8289/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6585 - accuracy: 0.9732 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8290/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6757 - accuracy: 0.9743 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8291/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6908 - accuracy: 0.9737 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8292/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6255 - accuracy: 0.9736 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8293/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6724 - accuracy: 0.9729 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 8294/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6437 - accuracy: 0.9728 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8295/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6569 - accuracy: 0.9734 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8296/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6481 - accuracy: 0.9731 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8297/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6524 - accuracy: 0.9727 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8298/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6688 - accuracy: 0.9724 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8299/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6669 - accuracy: 0.9737 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8300/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6740 - accuracy: 0.9720 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8301/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6837 - accuracy: 0.9721 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8302/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6698 - accuracy: 0.9733 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8303/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6769 - accuracy: 0.9733 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8304/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6683 - accuracy: 0.9747 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8305/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6641 - accuracy: 0.9724 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8306/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6709 - accuracy: 0.9746 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8307/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6917 - accuracy: 0.9729 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8308/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6703 - accuracy: 0.9713 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8309/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6810 - accuracy: 0.9728 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8310/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6855 - accuracy: 0.9741 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8311/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6632 - accuracy: 0.9736 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8312/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6728 - accuracy: 0.9722 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8313/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6534 - accuracy: 0.9726 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8314/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6775 - accuracy: 0.9727 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8315/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6803 - accuracy: 0.9742 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8316/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6836 - accuracy: 0.9715 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8317/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6809 - accuracy: 0.9731 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8318/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6559 - accuracy: 0.9735 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8319/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6654 - accuracy: 0.9738 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8320/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6639 - accuracy: 0.9735 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8321/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6451 - accuracy: 0.9724 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8322/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6713 - accuracy: 0.9722 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8323/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6689 - accuracy: 0.9711 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8324/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6841 - accuracy: 0.9734 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8325/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6582 - accuracy: 0.9724 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8326/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6583 - accuracy: 0.9742 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8327/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6562 - accuracy: 0.9721 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8328/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6599 - accuracy: 0.9747 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8329/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6543 - accuracy: 0.9724 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8330/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6726 - accuracy: 0.9737 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8331/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6678 - accuracy: 0.9725 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8332/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6857 - accuracy: 0.9728 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8333/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6631 - accuracy: 0.9737 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8334/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6616 - accuracy: 0.9726 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8335/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6523 - accuracy: 0.9734 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8336/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6723 - accuracy: 0.9732 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8337/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6497 - accuracy: 0.9740 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8338/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6843 - accuracy: 0.9745 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8339/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6698 - accuracy: 0.9729 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8340/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6676 - accuracy: 0.9729 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8341/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6742 - accuracy: 0.9731 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8342/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6632 - accuracy: 0.9737 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8343/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6808 - accuracy: 0.9739 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8344/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6764 - accuracy: 0.9736 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8345/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6592 - accuracy: 0.9735 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8346/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6736 - accuracy: 0.9732 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8347/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6324 - accuracy: 0.9738 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8348/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6627 - accuracy: 0.9727 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8349/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6646 - accuracy: 0.9737 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8350/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6831 - accuracy: 0.9723 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8351/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6705 - accuracy: 0.9735 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 8352/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6753 - accuracy: 0.9726 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8353/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6618 - accuracy: 0.9726 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8354/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6788 - accuracy: 0.9725 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8355/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6596 - accuracy: 0.9728 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8356/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6758 - accuracy: 0.9742 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8357/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6604 - accuracy: 0.9729 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8358/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6865 - accuracy: 0.9724 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8359/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6762 - accuracy: 0.9726 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8360/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6469 - accuracy: 0.9739 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8361/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6776 - accuracy: 0.9719 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8362/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6608 - accuracy: 0.9745 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8363/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6742 - accuracy: 0.9727 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8364/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6454 - accuracy: 0.9734 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8365/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6590 - accuracy: 0.9733 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8366/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6484 - accuracy: 0.9723 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8367/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6671 - accuracy: 0.9722 - val_loss: -0.5174 - val_accuracy: 0.9690\n",
            "Epoch 8368/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6711 - accuracy: 0.9747 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8369/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6563 - accuracy: 0.9739 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8370/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6376 - accuracy: 0.9737 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8371/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6791 - accuracy: 0.9734 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8372/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6545 - accuracy: 0.9734 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8373/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6833 - accuracy: 0.9717 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8374/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6712 - accuracy: 0.9720 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8375/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6654 - accuracy: 0.9734 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8376/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6819 - accuracy: 0.9731 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8377/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6716 - accuracy: 0.9737 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8378/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6819 - accuracy: 0.9735 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8379/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6638 - accuracy: 0.9734 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8380/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6579 - accuracy: 0.9710 - val_loss: -0.5177 - val_accuracy: 0.9690\n",
            "Epoch 8381/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6739 - accuracy: 0.9735 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8382/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6592 - accuracy: 0.9721 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8383/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6691 - accuracy: 0.9736 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8384/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6525 - accuracy: 0.9744 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8385/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6740 - accuracy: 0.9732 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8386/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6709 - accuracy: 0.9735 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8387/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6660 - accuracy: 0.9737 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8388/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6693 - accuracy: 0.9732 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8389/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6646 - accuracy: 0.9719 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8390/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6655 - accuracy: 0.9734 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8391/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6640 - accuracy: 0.9726 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8392/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6660 - accuracy: 0.9738 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8393/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6875 - accuracy: 0.9723 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 8394/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6756 - accuracy: 0.9734 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8395/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6831 - accuracy: 0.9728 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 8396/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6855 - accuracy: 0.9724 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8397/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6548 - accuracy: 0.9748 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8398/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6772 - accuracy: 0.9748 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8399/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6613 - accuracy: 0.9720 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8400/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6532 - accuracy: 0.9742 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8401/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6603 - accuracy: 0.9734 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8402/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6817 - accuracy: 0.9727 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8403/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6720 - accuracy: 0.9738 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8404/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6803 - accuracy: 0.9727 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8405/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6545 - accuracy: 0.9736 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8406/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6540 - accuracy: 0.9726 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8407/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6566 - accuracy: 0.9730 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8408/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6585 - accuracy: 0.9735 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8409/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6641 - accuracy: 0.9723 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8410/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6470 - accuracy: 0.9731 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8411/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6904 - accuracy: 0.9728 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8412/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6798 - accuracy: 0.9733 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8413/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6746 - accuracy: 0.9734 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8414/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6531 - accuracy: 0.9727 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8415/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6825 - accuracy: 0.9741 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8416/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6703 - accuracy: 0.9736 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8417/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6685 - accuracy: 0.9731 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8418/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6693 - accuracy: 0.9744 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8419/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6779 - accuracy: 0.9728 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8420/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6750 - accuracy: 0.9714 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8421/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6559 - accuracy: 0.9742 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8422/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6781 - accuracy: 0.9743 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8423/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6796 - accuracy: 0.9744 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8424/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6677 - accuracy: 0.9727 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8425/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6640 - accuracy: 0.9744 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8426/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6699 - accuracy: 0.9734 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8427/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6651 - accuracy: 0.9731 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8428/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6534 - accuracy: 0.9718 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8429/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6370 - accuracy: 0.9732 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8430/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6354 - accuracy: 0.9739 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8431/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6513 - accuracy: 0.9726 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8432/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6688 - accuracy: 0.9739 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8433/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6505 - accuracy: 0.9731 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8434/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6668 - accuracy: 0.9735 - val_loss: -0.5179 - val_accuracy: 0.9690\n",
            "Epoch 8435/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6591 - accuracy: 0.9720 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8436/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6784 - accuracy: 0.9747 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8437/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6787 - accuracy: 0.9726 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8438/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6432 - accuracy: 0.9735 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8439/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6721 - accuracy: 0.9733 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8440/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6509 - accuracy: 0.9734 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8441/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6696 - accuracy: 0.9733 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8442/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6726 - accuracy: 0.9713 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8443/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6472 - accuracy: 0.9719 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8444/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6806 - accuracy: 0.9723 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8445/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6600 - accuracy: 0.9735 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8446/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6587 - accuracy: 0.9734 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8447/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6685 - accuracy: 0.9744 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8448/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6789 - accuracy: 0.9715 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8449/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6550 - accuracy: 0.9740 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8450/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6550 - accuracy: 0.9739 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8451/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6548 - accuracy: 0.9725 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8452/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6841 - accuracy: 0.9723 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8453/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6818 - accuracy: 0.9740 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8454/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6681 - accuracy: 0.9747 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8455/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6660 - accuracy: 0.9731 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8456/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6799 - accuracy: 0.9717 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8457/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6676 - accuracy: 0.9736 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 8458/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6556 - accuracy: 0.9728 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8459/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6940 - accuracy: 0.9730 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8460/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6861 - accuracy: 0.9741 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8461/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6662 - accuracy: 0.9735 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8462/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6794 - accuracy: 0.9712 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8463/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6788 - accuracy: 0.9730 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8464/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6816 - accuracy: 0.9720 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8465/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6617 - accuracy: 0.9730 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8466/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6759 - accuracy: 0.9744 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8467/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6655 - accuracy: 0.9738 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8468/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6808 - accuracy: 0.9729 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8469/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6704 - accuracy: 0.9736 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8470/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6843 - accuracy: 0.9733 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8471/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6745 - accuracy: 0.9737 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8472/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6680 - accuracy: 0.9736 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8473/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6686 - accuracy: 0.9743 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8474/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6684 - accuracy: 0.9734 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8475/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6783 - accuracy: 0.9733 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8476/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6775 - accuracy: 0.9719 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8477/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6568 - accuracy: 0.9732 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8478/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6644 - accuracy: 0.9725 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8479/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6724 - accuracy: 0.9735 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8480/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6788 - accuracy: 0.9730 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8481/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6646 - accuracy: 0.9750 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8482/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6787 - accuracy: 0.9732 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8483/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6908 - accuracy: 0.9730 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8484/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6810 - accuracy: 0.9730 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8485/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6729 - accuracy: 0.9714 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8486/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6760 - accuracy: 0.9736 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8487/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6718 - accuracy: 0.9731 - val_loss: -0.5178 - val_accuracy: 0.9690\n",
            "Epoch 8488/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6584 - accuracy: 0.9729 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8489/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6476 - accuracy: 0.9752 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8490/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6695 - accuracy: 0.9730 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8491/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6370 - accuracy: 0.9729 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8492/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6729 - accuracy: 0.9741 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8493/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6352 - accuracy: 0.9735 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8494/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6735 - accuracy: 0.9729 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8495/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6796 - accuracy: 0.9733 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8496/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6583 - accuracy: 0.9731 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8497/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6568 - accuracy: 0.9739 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8498/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6617 - accuracy: 0.9723 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8499/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6710 - accuracy: 0.9723 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8500/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6616 - accuracy: 0.9735 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8501/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6701 - accuracy: 0.9742 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8502/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6532 - accuracy: 0.9749 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8503/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6764 - accuracy: 0.9737 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8504/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6916 - accuracy: 0.9721 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8505/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6646 - accuracy: 0.9742 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8506/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6777 - accuracy: 0.9738 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8507/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6426 - accuracy: 0.9739 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8508/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6809 - accuracy: 0.9734 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8509/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6705 - accuracy: 0.9734 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8510/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6652 - accuracy: 0.9730 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8511/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6477 - accuracy: 0.9761 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8512/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6732 - accuracy: 0.9729 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8513/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6809 - accuracy: 0.9727 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8514/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6090 - accuracy: 0.9746 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8515/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6473 - accuracy: 0.9727 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8516/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6454 - accuracy: 0.9731 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8517/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6691 - accuracy: 0.9737 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8518/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6593 - accuracy: 0.9727 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8519/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6690 - accuracy: 0.9742 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8520/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6766 - accuracy: 0.9727 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8521/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6744 - accuracy: 0.9743 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8522/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6796 - accuracy: 0.9751 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8523/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6545 - accuracy: 0.9738 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8524/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6663 - accuracy: 0.9732 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8525/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6788 - accuracy: 0.9724 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8526/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6767 - accuracy: 0.9720 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8527/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6395 - accuracy: 0.9737 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8528/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6602 - accuracy: 0.9721 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8529/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6655 - accuracy: 0.9749 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8530/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6649 - accuracy: 0.9731 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8531/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6553 - accuracy: 0.9737 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8532/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6754 - accuracy: 0.9730 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8533/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6722 - accuracy: 0.9717 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8534/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6717 - accuracy: 0.9731 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8535/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6670 - accuracy: 0.9741 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8536/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6622 - accuracy: 0.9715 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8537/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6706 - accuracy: 0.9731 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8538/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6869 - accuracy: 0.9726 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8539/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6613 - accuracy: 0.9736 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8540/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6723 - accuracy: 0.9741 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8541/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6597 - accuracy: 0.9724 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8542/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6592 - accuracy: 0.9723 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8543/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6775 - accuracy: 0.9738 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8544/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6552 - accuracy: 0.9732 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8545/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6694 - accuracy: 0.9734 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8546/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6752 - accuracy: 0.9711 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8547/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6613 - accuracy: 0.9730 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8548/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6729 - accuracy: 0.9720 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8549/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6507 - accuracy: 0.9740 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8550/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6687 - accuracy: 0.9728 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8551/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6822 - accuracy: 0.9723 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8552/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6656 - accuracy: 0.9711 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8553/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6750 - accuracy: 0.9724 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8554/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6911 - accuracy: 0.9729 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8555/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6755 - accuracy: 0.9735 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8556/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6720 - accuracy: 0.9726 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8557/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6528 - accuracy: 0.9721 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8558/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6879 - accuracy: 0.9728 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8559/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6699 - accuracy: 0.9734 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8560/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6912 - accuracy: 0.9726 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8561/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6835 - accuracy: 0.9733 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8562/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6604 - accuracy: 0.9746 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8563/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6806 - accuracy: 0.9740 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 8564/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6553 - accuracy: 0.9738 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8565/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6534 - accuracy: 0.9724 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8566/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6946 - accuracy: 0.9722 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8567/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6684 - accuracy: 0.9734 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8568/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6579 - accuracy: 0.9730 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8569/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6724 - accuracy: 0.9734 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8570/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6757 - accuracy: 0.9729 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8571/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6272 - accuracy: 0.9728 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8572/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6983 - accuracy: 0.9739 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8573/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6656 - accuracy: 0.9734 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8574/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6739 - accuracy: 0.9736 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8575/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6886 - accuracy: 0.9733 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8576/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6771 - accuracy: 0.9723 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8577/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6705 - accuracy: 0.9738 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8578/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6743 - accuracy: 0.9720 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8579/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6829 - accuracy: 0.9726 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8580/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6973 - accuracy: 0.9745 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8581/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6508 - accuracy: 0.9738 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8582/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6901 - accuracy: 0.9735 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8583/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6690 - accuracy: 0.9716 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8584/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6844 - accuracy: 0.9730 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8585/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6577 - accuracy: 0.9731 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8586/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6605 - accuracy: 0.9724 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8587/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6688 - accuracy: 0.9728 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8588/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6664 - accuracy: 0.9729 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8589/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6363 - accuracy: 0.9748 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8590/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6773 - accuracy: 0.9727 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8591/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6764 - accuracy: 0.9731 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8592/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6741 - accuracy: 0.9742 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8593/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6552 - accuracy: 0.9737 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8594/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6787 - accuracy: 0.9745 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8595/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6429 - accuracy: 0.9737 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8596/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6678 - accuracy: 0.9732 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8597/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6780 - accuracy: 0.9730 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8598/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6813 - accuracy: 0.9737 - val_loss: -0.5173 - val_accuracy: 0.9690\n",
            "Epoch 8599/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6631 - accuracy: 0.9734 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8600/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6662 - accuracy: 0.9731 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8601/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6811 - accuracy: 0.9729 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8602/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6546 - accuracy: 0.9743 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8603/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6558 - accuracy: 0.9733 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8604/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6662 - accuracy: 0.9720 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8605/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6835 - accuracy: 0.9715 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8606/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6938 - accuracy: 0.9727 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8607/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6711 - accuracy: 0.9735 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8608/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6671 - accuracy: 0.9725 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8609/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6628 - accuracy: 0.9742 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8610/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6602 - accuracy: 0.9736 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8611/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6516 - accuracy: 0.9727 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8612/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6596 - accuracy: 0.9725 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8613/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6728 - accuracy: 0.9733 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8614/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6719 - accuracy: 0.9737 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8615/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6762 - accuracy: 0.9727 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8616/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6869 - accuracy: 0.9719 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8617/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6889 - accuracy: 0.9720 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8618/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6676 - accuracy: 0.9731 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8619/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6496 - accuracy: 0.9727 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8620/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6469 - accuracy: 0.9748 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8621/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6898 - accuracy: 0.9735 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8622/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6582 - accuracy: 0.9728 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8623/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6822 - accuracy: 0.9724 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8624/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6775 - accuracy: 0.9727 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8625/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6609 - accuracy: 0.9738 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8626/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6795 - accuracy: 0.9730 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8627/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6846 - accuracy: 0.9735 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8628/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6733 - accuracy: 0.9731 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8629/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6604 - accuracy: 0.9729 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8630/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6889 - accuracy: 0.9727 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8631/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6864 - accuracy: 0.9722 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8632/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6861 - accuracy: 0.9728 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8633/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6898 - accuracy: 0.9731 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8634/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6546 - accuracy: 0.9728 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8635/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6894 - accuracy: 0.9728 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8636/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6793 - accuracy: 0.9746 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8637/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6813 - accuracy: 0.9725 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8638/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6766 - accuracy: 0.9738 - val_loss: -0.5170 - val_accuracy: 0.9690\n",
            "Epoch 8639/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6870 - accuracy: 0.9716 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8640/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6665 - accuracy: 0.9723 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8641/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6766 - accuracy: 0.9720 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8642/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6558 - accuracy: 0.9734 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8643/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6570 - accuracy: 0.9746 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8644/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6861 - accuracy: 0.9725 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8645/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6749 - accuracy: 0.9715 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8646/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6687 - accuracy: 0.9716 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8647/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6539 - accuracy: 0.9740 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8648/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6628 - accuracy: 0.9724 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8649/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6879 - accuracy: 0.9729 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8650/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6553 - accuracy: 0.9741 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8651/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6683 - accuracy: 0.9739 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8652/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6564 - accuracy: 0.9738 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8653/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6521 - accuracy: 0.9740 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8654/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6767 - accuracy: 0.9729 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8655/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6949 - accuracy: 0.9739 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8656/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6870 - accuracy: 0.9738 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8657/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6784 - accuracy: 0.9728 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8658/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6835 - accuracy: 0.9737 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8659/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6686 - accuracy: 0.9739 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8660/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6914 - accuracy: 0.9740 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8661/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6767 - accuracy: 0.9727 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8662/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6687 - accuracy: 0.9728 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8663/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6928 - accuracy: 0.9717 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8664/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6493 - accuracy: 0.9744 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8665/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6507 - accuracy: 0.9735 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8666/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6802 - accuracy: 0.9733 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8667/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6686 - accuracy: 0.9733 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8668/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6784 - accuracy: 0.9727 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8669/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6717 - accuracy: 0.9728 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8670/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6910 - accuracy: 0.9729 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8671/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6725 - accuracy: 0.9719 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8672/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6757 - accuracy: 0.9713 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8673/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6484 - accuracy: 0.9717 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 8674/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6585 - accuracy: 0.9729 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8675/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6632 - accuracy: 0.9738 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8676/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6701 - accuracy: 0.9721 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8677/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6523 - accuracy: 0.9736 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8678/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6804 - accuracy: 0.9744 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8679/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6729 - accuracy: 0.9737 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8680/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6671 - accuracy: 0.9734 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8681/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6686 - accuracy: 0.9735 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8682/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6814 - accuracy: 0.9730 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8683/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6683 - accuracy: 0.9735 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8684/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6604 - accuracy: 0.9731 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8685/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6824 - accuracy: 0.9723 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8686/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6827 - accuracy: 0.9725 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8687/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6639 - accuracy: 0.9721 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8688/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6731 - accuracy: 0.9727 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8689/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6817 - accuracy: 0.9734 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8690/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6559 - accuracy: 0.9749 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8691/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6697 - accuracy: 0.9728 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8692/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6787 - accuracy: 0.9723 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8693/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6868 - accuracy: 0.9716 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8694/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6814 - accuracy: 0.9719 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8695/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6715 - accuracy: 0.9725 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8696/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6880 - accuracy: 0.9732 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8697/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6343 - accuracy: 0.9728 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 8698/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6782 - accuracy: 0.9714 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8699/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6679 - accuracy: 0.9725 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8700/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6624 - accuracy: 0.9718 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8701/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6835 - accuracy: 0.9721 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8702/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6956 - accuracy: 0.9734 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8703/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6494 - accuracy: 0.9733 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 8704/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6706 - accuracy: 0.9742 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8705/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6518 - accuracy: 0.9726 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8706/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6825 - accuracy: 0.9734 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8707/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6792 - accuracy: 0.9725 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8708/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6646 - accuracy: 0.9728 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8709/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6653 - accuracy: 0.9733 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8710/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6895 - accuracy: 0.9720 - val_loss: -0.5171 - val_accuracy: 0.9690\n",
            "Epoch 8711/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6766 - accuracy: 0.9737 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8712/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6647 - accuracy: 0.9739 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8713/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6853 - accuracy: 0.9715 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8714/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6762 - accuracy: 0.9726 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8715/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6832 - accuracy: 0.9733 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8716/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6599 - accuracy: 0.9743 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8717/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6640 - accuracy: 0.9737 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8718/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6694 - accuracy: 0.9724 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8719/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6751 - accuracy: 0.9733 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8720/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6852 - accuracy: 0.9724 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8721/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6703 - accuracy: 0.9735 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8722/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6272 - accuracy: 0.9741 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 8723/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6755 - accuracy: 0.9742 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8724/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6759 - accuracy: 0.9743 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8725/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6832 - accuracy: 0.9734 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8726/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6788 - accuracy: 0.9723 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8727/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6885 - accuracy: 0.9724 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8728/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6681 - accuracy: 0.9736 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8729/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6451 - accuracy: 0.9726 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 8730/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6432 - accuracy: 0.9738 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8731/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6507 - accuracy: 0.9742 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8732/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6519 - accuracy: 0.9738 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8733/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6426 - accuracy: 0.9735 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8734/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6569 - accuracy: 0.9720 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8735/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6822 - accuracy: 0.9736 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8736/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6789 - accuracy: 0.9727 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8737/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6762 - accuracy: 0.9727 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8738/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6533 - accuracy: 0.9723 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8739/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6633 - accuracy: 0.9724 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8740/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6856 - accuracy: 0.9723 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8741/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6555 - accuracy: 0.9730 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8742/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6570 - accuracy: 0.9739 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8743/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6679 - accuracy: 0.9729 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8744/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6561 - accuracy: 0.9744 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8745/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6650 - accuracy: 0.9722 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8746/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6781 - accuracy: 0.9737 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8747/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6636 - accuracy: 0.9741 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8748/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6663 - accuracy: 0.9726 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8749/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6577 - accuracy: 0.9739 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8750/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6775 - accuracy: 0.9722 - val_loss: -0.5168 - val_accuracy: 0.9690\n",
            "Epoch 8751/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6598 - accuracy: 0.9723 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8752/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6878 - accuracy: 0.9724 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8753/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6660 - accuracy: 0.9726 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8754/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6784 - accuracy: 0.9720 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8755/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6710 - accuracy: 0.9729 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8756/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6816 - accuracy: 0.9723 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8757/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6771 - accuracy: 0.9726 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8758/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6839 - accuracy: 0.9724 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8759/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6741 - accuracy: 0.9721 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8760/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6797 - accuracy: 0.9734 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8761/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6625 - accuracy: 0.9747 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8762/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6504 - accuracy: 0.9733 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8763/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6803 - accuracy: 0.9745 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8764/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6812 - accuracy: 0.9737 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8765/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6801 - accuracy: 0.9731 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8766/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6556 - accuracy: 0.9746 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8767/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6776 - accuracy: 0.9715 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8768/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6538 - accuracy: 0.9738 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8769/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6820 - accuracy: 0.9738 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8770/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6709 - accuracy: 0.9725 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8771/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6566 - accuracy: 0.9737 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8772/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6625 - accuracy: 0.9726 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8773/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6698 - accuracy: 0.9734 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8774/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6787 - accuracy: 0.9732 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8775/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6700 - accuracy: 0.9728 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8776/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6682 - accuracy: 0.9720 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8777/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6698 - accuracy: 0.9736 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8778/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6796 - accuracy: 0.9738 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8779/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6806 - accuracy: 0.9722 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8780/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6699 - accuracy: 0.9733 - val_loss: -0.5172 - val_accuracy: 0.9690\n",
            "Epoch 8781/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6660 - accuracy: 0.9730 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8782/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6664 - accuracy: 0.9733 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8783/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6714 - accuracy: 0.9740 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8784/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6685 - accuracy: 0.9730 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8785/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6935 - accuracy: 0.9726 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8786/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6847 - accuracy: 0.9728 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8787/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6886 - accuracy: 0.9716 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8788/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6385 - accuracy: 0.9724 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8789/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6715 - accuracy: 0.9738 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8790/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6698 - accuracy: 0.9727 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8791/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6642 - accuracy: 0.9731 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8792/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6737 - accuracy: 0.9732 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8793/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6915 - accuracy: 0.9733 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8794/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6848 - accuracy: 0.9710 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8795/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6734 - accuracy: 0.9734 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8796/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6603 - accuracy: 0.9731 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8797/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6780 - accuracy: 0.9724 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8798/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6808 - accuracy: 0.9721 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8799/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6687 - accuracy: 0.9721 - val_loss: -0.5175 - val_accuracy: 0.9690\n",
            "Epoch 8800/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6662 - accuracy: 0.9736 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8801/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6851 - accuracy: 0.9723 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8802/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6650 - accuracy: 0.9733 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8803/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6657 - accuracy: 0.9721 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8804/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6801 - accuracy: 0.9746 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8805/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6741 - accuracy: 0.9727 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 8806/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6843 - accuracy: 0.9726 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8807/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6707 - accuracy: 0.9734 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 8808/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6561 - accuracy: 0.9728 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8809/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6679 - accuracy: 0.9740 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8810/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6558 - accuracy: 0.9742 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8811/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6913 - accuracy: 0.9719 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8812/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6790 - accuracy: 0.9728 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8813/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6876 - accuracy: 0.9713 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8814/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6780 - accuracy: 0.9718 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8815/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6818 - accuracy: 0.9746 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8816/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6753 - accuracy: 0.9735 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8817/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6458 - accuracy: 0.9729 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8818/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6641 - accuracy: 0.9733 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8819/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6359 - accuracy: 0.9727 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8820/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6603 - accuracy: 0.9730 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8821/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6912 - accuracy: 0.9731 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8822/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6746 - accuracy: 0.9728 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8823/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6694 - accuracy: 0.9743 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8824/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6912 - accuracy: 0.9723 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8825/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6829 - accuracy: 0.9732 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8826/10000\n",
            "22/22 [==============================] - 1s 42ms/step - loss: -0.6856 - accuracy: 0.9729 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8827/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6800 - accuracy: 0.9733 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8828/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6693 - accuracy: 0.9725 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8829/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6391 - accuracy: 0.9743 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8830/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6650 - accuracy: 0.9726 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8831/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6749 - accuracy: 0.9726 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8832/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6803 - accuracy: 0.9727 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8833/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6881 - accuracy: 0.9725 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8834/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6771 - accuracy: 0.9738 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8835/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6672 - accuracy: 0.9717 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8836/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6758 - accuracy: 0.9717 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8837/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6741 - accuracy: 0.9734 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8838/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6760 - accuracy: 0.9727 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8839/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6945 - accuracy: 0.9736 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8840/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6881 - accuracy: 0.9721 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8841/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6848 - accuracy: 0.9718 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8842/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6799 - accuracy: 0.9735 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8843/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6668 - accuracy: 0.9736 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8844/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6730 - accuracy: 0.9737 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8845/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6775 - accuracy: 0.9735 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8846/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6760 - accuracy: 0.9735 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8847/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6763 - accuracy: 0.9724 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8848/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6774 - accuracy: 0.9732 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8849/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6810 - accuracy: 0.9729 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8850/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6877 - accuracy: 0.9719 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8851/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6499 - accuracy: 0.9737 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 8852/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6929 - accuracy: 0.9722 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8853/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6650 - accuracy: 0.9732 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 8854/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6746 - accuracy: 0.9727 - val_loss: -0.5169 - val_accuracy: 0.9690\n",
            "Epoch 8855/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6982 - accuracy: 0.9743 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8856/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6585 - accuracy: 0.9736 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8857/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6803 - accuracy: 0.9732 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8858/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6681 - accuracy: 0.9736 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8859/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6762 - accuracy: 0.9724 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8860/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6668 - accuracy: 0.9733 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8861/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6607 - accuracy: 0.9734 - val_loss: -0.5166 - val_accuracy: 0.9690\n",
            "Epoch 8862/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6535 - accuracy: 0.9742 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8863/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6931 - accuracy: 0.9743 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8864/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6850 - accuracy: 0.9721 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8865/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6837 - accuracy: 0.9721 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8866/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6662 - accuracy: 0.9719 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8867/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6759 - accuracy: 0.9726 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8868/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6714 - accuracy: 0.9731 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8869/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6831 - accuracy: 0.9733 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8870/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6949 - accuracy: 0.9749 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8871/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6736 - accuracy: 0.9720 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8872/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6746 - accuracy: 0.9717 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8873/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6561 - accuracy: 0.9739 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8874/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6691 - accuracy: 0.9727 - val_loss: -0.5176 - val_accuracy: 0.9690\n",
            "Epoch 8875/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6671 - accuracy: 0.9706 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8876/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6821 - accuracy: 0.9736 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8877/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6920 - accuracy: 0.9736 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8878/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6709 - accuracy: 0.9732 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8879/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6637 - accuracy: 0.9735 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8880/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6623 - accuracy: 0.9737 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8881/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6819 - accuracy: 0.9725 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8882/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6700 - accuracy: 0.9744 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8883/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6857 - accuracy: 0.9735 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8884/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6816 - accuracy: 0.9706 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8885/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6937 - accuracy: 0.9741 - val_loss: -0.5167 - val_accuracy: 0.9690\n",
            "Epoch 8886/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6703 - accuracy: 0.9733 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8887/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6856 - accuracy: 0.9733 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8888/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6536 - accuracy: 0.9723 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8889/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6648 - accuracy: 0.9727 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8890/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6721 - accuracy: 0.9726 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8891/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6640 - accuracy: 0.9730 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 8892/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6757 - accuracy: 0.9726 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8893/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6225 - accuracy: 0.9727 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 8894/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6604 - accuracy: 0.9738 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8895/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6615 - accuracy: 0.9726 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 8896/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6819 - accuracy: 0.9728 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8897/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6668 - accuracy: 0.9713 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8898/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6467 - accuracy: 0.9730 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8899/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6634 - accuracy: 0.9739 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8900/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6667 - accuracy: 0.9728 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8901/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6595 - accuracy: 0.9729 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8902/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6780 - accuracy: 0.9725 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8903/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6632 - accuracy: 0.9730 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 8904/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6747 - accuracy: 0.9738 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8905/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6731 - accuracy: 0.9721 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8906/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6760 - accuracy: 0.9716 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8907/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6679 - accuracy: 0.9722 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8908/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6894 - accuracy: 0.9716 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8909/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6766 - accuracy: 0.9740 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8910/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6446 - accuracy: 0.9745 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 8911/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6653 - accuracy: 0.9727 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8912/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6582 - accuracy: 0.9729 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8913/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6599 - accuracy: 0.9734 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8914/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6677 - accuracy: 0.9713 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8915/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6672 - accuracy: 0.9726 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 8916/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6736 - accuracy: 0.9716 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8917/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6732 - accuracy: 0.9745 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 8918/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6879 - accuracy: 0.9717 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8919/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6698 - accuracy: 0.9729 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 8920/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6733 - accuracy: 0.9728 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8921/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6751 - accuracy: 0.9711 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8922/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6468 - accuracy: 0.9726 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 8923/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6620 - accuracy: 0.9727 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8924/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6810 - accuracy: 0.9722 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8925/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6615 - accuracy: 0.9736 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8926/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6653 - accuracy: 0.9728 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8927/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6754 - accuracy: 0.9725 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8928/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6575 - accuracy: 0.9736 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8929/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6366 - accuracy: 0.9721 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 8930/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6541 - accuracy: 0.9733 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 8931/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6933 - accuracy: 0.9739 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 8932/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6733 - accuracy: 0.9734 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 8933/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6732 - accuracy: 0.9729 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8934/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6629 - accuracy: 0.9730 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 8935/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6672 - accuracy: 0.9747 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8936/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6732 - accuracy: 0.9745 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8937/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6711 - accuracy: 0.9740 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8938/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6673 - accuracy: 0.9739 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8939/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6881 - accuracy: 0.9736 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8940/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6733 - accuracy: 0.9728 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 8941/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6724 - accuracy: 0.9724 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8942/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6428 - accuracy: 0.9737 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8943/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6811 - accuracy: 0.9727 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8944/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6722 - accuracy: 0.9738 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 8945/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6774 - accuracy: 0.9733 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8946/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6715 - accuracy: 0.9731 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8947/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6731 - accuracy: 0.9725 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8948/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6869 - accuracy: 0.9732 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8949/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6877 - accuracy: 0.9732 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 8950/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6645 - accuracy: 0.9735 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8951/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6727 - accuracy: 0.9725 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8952/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6578 - accuracy: 0.9734 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 8953/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6627 - accuracy: 0.9742 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8954/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6870 - accuracy: 0.9731 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 8955/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6777 - accuracy: 0.9736 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8956/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6551 - accuracy: 0.9731 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8957/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6823 - accuracy: 0.9731 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8958/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6659 - accuracy: 0.9724 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8959/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6603 - accuracy: 0.9739 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 8960/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6658 - accuracy: 0.9728 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 8961/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6633 - accuracy: 0.9731 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 8962/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6732 - accuracy: 0.9752 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8963/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6773 - accuracy: 0.9722 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8964/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6797 - accuracy: 0.9736 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8965/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6376 - accuracy: 0.9739 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 8966/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6679 - accuracy: 0.9730 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 8967/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6736 - accuracy: 0.9723 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 8968/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6517 - accuracy: 0.9720 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8969/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6472 - accuracy: 0.9747 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 8970/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6660 - accuracy: 0.9722 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8971/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6865 - accuracy: 0.9734 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8972/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6893 - accuracy: 0.9728 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8973/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6688 - accuracy: 0.9732 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 8974/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6563 - accuracy: 0.9731 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8975/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6721 - accuracy: 0.9736 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 8976/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6620 - accuracy: 0.9725 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8977/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6775 - accuracy: 0.9741 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8978/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6602 - accuracy: 0.9733 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8979/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6508 - accuracy: 0.9728 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 8980/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6731 - accuracy: 0.9743 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8981/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6789 - accuracy: 0.9733 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8982/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6686 - accuracy: 0.9733 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 8983/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6677 - accuracy: 0.9728 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8984/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6536 - accuracy: 0.9716 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 8985/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6606 - accuracy: 0.9748 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 8986/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6762 - accuracy: 0.9729 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8987/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6745 - accuracy: 0.9728 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 8988/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6660 - accuracy: 0.9722 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8989/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6659 - accuracy: 0.9741 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8990/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6579 - accuracy: 0.9720 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 8991/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6576 - accuracy: 0.9726 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 8992/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6886 - accuracy: 0.9740 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8993/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6619 - accuracy: 0.9738 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8994/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6737 - accuracy: 0.9732 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 8995/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6764 - accuracy: 0.9724 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 8996/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6657 - accuracy: 0.9732 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 8997/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6812 - accuracy: 0.9739 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 8998/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6734 - accuracy: 0.9729 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 8999/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6840 - accuracy: 0.9722 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9000/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6874 - accuracy: 0.9728 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 9001/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6660 - accuracy: 0.9734 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9002/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6499 - accuracy: 0.9728 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9003/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6835 - accuracy: 0.9736 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9004/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6573 - accuracy: 0.9727 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9005/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6609 - accuracy: 0.9742 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9006/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6628 - accuracy: 0.9737 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9007/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6809 - accuracy: 0.9710 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 9008/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6528 - accuracy: 0.9722 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9009/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6601 - accuracy: 0.9734 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 9010/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6674 - accuracy: 0.9745 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9011/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6675 - accuracy: 0.9739 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9012/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6595 - accuracy: 0.9738 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9013/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6712 - accuracy: 0.9704 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9014/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6608 - accuracy: 0.9728 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 9015/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6733 - accuracy: 0.9744 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9016/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6761 - accuracy: 0.9728 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9017/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6822 - accuracy: 0.9733 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 9018/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6732 - accuracy: 0.9729 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9019/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6672 - accuracy: 0.9733 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9020/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6695 - accuracy: 0.9746 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9021/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6567 - accuracy: 0.9733 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9022/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6795 - accuracy: 0.9748 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 9023/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6765 - accuracy: 0.9719 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9024/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6809 - accuracy: 0.9731 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9025/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6737 - accuracy: 0.9720 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9026/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6712 - accuracy: 0.9724 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 9027/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6856 - accuracy: 0.9718 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 9028/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6743 - accuracy: 0.9727 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9029/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6879 - accuracy: 0.9718 - val_loss: -0.5165 - val_accuracy: 0.9690\n",
            "Epoch 9030/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6526 - accuracy: 0.9728 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9031/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6842 - accuracy: 0.9721 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 9032/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6698 - accuracy: 0.9745 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9033/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6478 - accuracy: 0.9742 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9034/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6808 - accuracy: 0.9731 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 9035/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6668 - accuracy: 0.9730 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 9036/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6613 - accuracy: 0.9732 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 9037/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6818 - accuracy: 0.9736 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9038/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.7013 - accuracy: 0.9732 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9039/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6800 - accuracy: 0.9714 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9040/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6741 - accuracy: 0.9743 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9041/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6595 - accuracy: 0.9732 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9042/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6474 - accuracy: 0.9729 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9043/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6657 - accuracy: 0.9728 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 9044/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6816 - accuracy: 0.9733 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9045/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6699 - accuracy: 0.9737 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9046/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6804 - accuracy: 0.9726 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 9047/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6623 - accuracy: 0.9725 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9048/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6687 - accuracy: 0.9730 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9049/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6706 - accuracy: 0.9732 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9050/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6779 - accuracy: 0.9736 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9051/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6897 - accuracy: 0.9713 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9052/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6834 - accuracy: 0.9745 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9053/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6788 - accuracy: 0.9715 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9054/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6687 - accuracy: 0.9739 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9055/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6731 - accuracy: 0.9738 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9056/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6884 - accuracy: 0.9718 - val_loss: -0.5161 - val_accuracy: 0.9690\n",
            "Epoch 9057/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6832 - accuracy: 0.9729 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9058/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6915 - accuracy: 0.9752 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 9059/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6620 - accuracy: 0.9725 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9060/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6777 - accuracy: 0.9731 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9061/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6647 - accuracy: 0.9734 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9062/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6830 - accuracy: 0.9746 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9063/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6755 - accuracy: 0.9725 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9064/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6772 - accuracy: 0.9728 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9065/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6818 - accuracy: 0.9719 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9066/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6643 - accuracy: 0.9737 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9067/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6803 - accuracy: 0.9726 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9068/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6721 - accuracy: 0.9728 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9069/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6815 - accuracy: 0.9734 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9070/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6500 - accuracy: 0.9714 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9071/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6880 - accuracy: 0.9726 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9072/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6692 - accuracy: 0.9741 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9073/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6925 - accuracy: 0.9721 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9074/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6681 - accuracy: 0.9731 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9075/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6412 - accuracy: 0.9736 - val_loss: -0.5163 - val_accuracy: 0.9690\n",
            "Epoch 9076/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6695 - accuracy: 0.9731 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9077/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6717 - accuracy: 0.9739 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9078/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6868 - accuracy: 0.9727 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9079/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6644 - accuracy: 0.9746 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9080/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6840 - accuracy: 0.9717 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9081/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6846 - accuracy: 0.9738 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9082/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6767 - accuracy: 0.9722 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9083/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6653 - accuracy: 0.9729 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9084/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6565 - accuracy: 0.9731 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9085/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6647 - accuracy: 0.9724 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 9086/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6670 - accuracy: 0.9740 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 9087/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6726 - accuracy: 0.9733 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 9088/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6759 - accuracy: 0.9738 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9089/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6765 - accuracy: 0.9736 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9090/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6511 - accuracy: 0.9727 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9091/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6867 - accuracy: 0.9728 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9092/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6637 - accuracy: 0.9719 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9093/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6491 - accuracy: 0.9721 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9094/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6541 - accuracy: 0.9734 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9095/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6768 - accuracy: 0.9749 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9096/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6543 - accuracy: 0.9737 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9097/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6937 - accuracy: 0.9725 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9098/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6565 - accuracy: 0.9730 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9099/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6787 - accuracy: 0.9725 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9100/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6564 - accuracy: 0.9733 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9101/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6765 - accuracy: 0.9735 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9102/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6726 - accuracy: 0.9741 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9103/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6567 - accuracy: 0.9740 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9104/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6710 - accuracy: 0.9726 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9105/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6795 - accuracy: 0.9735 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9106/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6814 - accuracy: 0.9720 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9107/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6649 - accuracy: 0.9714 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9108/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6691 - accuracy: 0.9735 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9109/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6900 - accuracy: 0.9742 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9110/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6517 - accuracy: 0.9736 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9111/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6781 - accuracy: 0.9736 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9112/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6742 - accuracy: 0.9746 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9113/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6684 - accuracy: 0.9736 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9114/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6820 - accuracy: 0.9725 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9115/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6769 - accuracy: 0.9732 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9116/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6763 - accuracy: 0.9720 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9117/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6494 - accuracy: 0.9732 - val_loss: -0.5137 - val_accuracy: 0.9690\n",
            "Epoch 9118/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6515 - accuracy: 0.9742 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9119/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6834 - accuracy: 0.9737 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9120/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6605 - accuracy: 0.9730 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9121/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6786 - accuracy: 0.9727 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9122/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6700 - accuracy: 0.9733 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9123/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6864 - accuracy: 0.9730 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9124/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6735 - accuracy: 0.9735 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9125/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6715 - accuracy: 0.9721 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9126/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6588 - accuracy: 0.9727 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9127/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6782 - accuracy: 0.9733 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9128/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6712 - accuracy: 0.9730 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9129/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6826 - accuracy: 0.9726 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9130/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6788 - accuracy: 0.9705 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9131/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6743 - accuracy: 0.9731 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9132/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6786 - accuracy: 0.9735 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9133/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6669 - accuracy: 0.9743 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9134/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6626 - accuracy: 0.9738 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9135/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6853 - accuracy: 0.9736 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9136/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6687 - accuracy: 0.9727 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9137/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6554 - accuracy: 0.9727 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9138/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6494 - accuracy: 0.9720 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9139/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6718 - accuracy: 0.9741 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9140/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6667 - accuracy: 0.9738 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9141/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6911 - accuracy: 0.9733 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9142/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6926 - accuracy: 0.9722 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9143/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6653 - accuracy: 0.9723 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9144/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6756 - accuracy: 0.9712 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9145/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6714 - accuracy: 0.9718 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9146/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6564 - accuracy: 0.9724 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9147/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6715 - accuracy: 0.9730 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9148/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6748 - accuracy: 0.9741 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9149/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6630 - accuracy: 0.9736 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9150/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6932 - accuracy: 0.9730 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9151/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6930 - accuracy: 0.9733 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9152/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6501 - accuracy: 0.9742 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9153/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6807 - accuracy: 0.9721 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9154/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6717 - accuracy: 0.9737 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9155/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6899 - accuracy: 0.9730 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9156/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6803 - accuracy: 0.9731 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9157/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6813 - accuracy: 0.9747 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9158/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6882 - accuracy: 0.9733 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9159/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6672 - accuracy: 0.9725 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9160/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6677 - accuracy: 0.9737 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9161/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6826 - accuracy: 0.9740 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9162/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6769 - accuracy: 0.9718 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9163/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6655 - accuracy: 0.9742 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9164/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6746 - accuracy: 0.9743 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9165/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6777 - accuracy: 0.9738 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9166/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6614 - accuracy: 0.9731 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9167/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6756 - accuracy: 0.9714 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9168/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6677 - accuracy: 0.9727 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9169/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6531 - accuracy: 0.9733 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9170/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6728 - accuracy: 0.9730 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9171/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6910 - accuracy: 0.9744 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9172/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6934 - accuracy: 0.9735 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9173/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6774 - accuracy: 0.9716 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9174/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6952 - accuracy: 0.9724 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9175/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6597 - accuracy: 0.9731 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9176/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6752 - accuracy: 0.9733 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9177/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6597 - accuracy: 0.9731 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9178/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6585 - accuracy: 0.9738 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9179/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6565 - accuracy: 0.9738 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9180/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6672 - accuracy: 0.9731 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 9181/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6695 - accuracy: 0.9739 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9182/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6794 - accuracy: 0.9733 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9183/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6721 - accuracy: 0.9736 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9184/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6704 - accuracy: 0.9741 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9185/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6453 - accuracy: 0.9739 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9186/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6918 - accuracy: 0.9725 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9187/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6718 - accuracy: 0.9742 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9188/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6737 - accuracy: 0.9725 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9189/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6622 - accuracy: 0.9725 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9190/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6540 - accuracy: 0.9730 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9191/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6808 - accuracy: 0.9737 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9192/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6637 - accuracy: 0.9734 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9193/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6737 - accuracy: 0.9731 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9194/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6825 - accuracy: 0.9732 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9195/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6963 - accuracy: 0.9742 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9196/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6580 - accuracy: 0.9736 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9197/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6832 - accuracy: 0.9731 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9198/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6787 - accuracy: 0.9734 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9199/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6769 - accuracy: 0.9740 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9200/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6880 - accuracy: 0.9731 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9201/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6640 - accuracy: 0.9727 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9202/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6906 - accuracy: 0.9723 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9203/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6696 - accuracy: 0.9742 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9204/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6389 - accuracy: 0.9747 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9205/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6839 - accuracy: 0.9733 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9206/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6619 - accuracy: 0.9733 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9207/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6669 - accuracy: 0.9734 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9208/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6843 - accuracy: 0.9742 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9209/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6709 - accuracy: 0.9719 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9210/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6882 - accuracy: 0.9726 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 9211/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6775 - accuracy: 0.9718 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9212/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6690 - accuracy: 0.9742 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9213/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6640 - accuracy: 0.9728 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9214/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6890 - accuracy: 0.9721 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9215/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6724 - accuracy: 0.9741 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9216/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6892 - accuracy: 0.9734 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9217/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6640 - accuracy: 0.9741 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9218/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6860 - accuracy: 0.9727 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 9219/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6795 - accuracy: 0.9732 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9220/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6808 - accuracy: 0.9746 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9221/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6728 - accuracy: 0.9719 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9222/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6701 - accuracy: 0.9735 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9223/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6474 - accuracy: 0.9729 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9224/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6780 - accuracy: 0.9747 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9225/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6744 - accuracy: 0.9730 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9226/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6765 - accuracy: 0.9734 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9227/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6844 - accuracy: 0.9721 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9228/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6808 - accuracy: 0.9730 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9229/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6787 - accuracy: 0.9725 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9230/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6613 - accuracy: 0.9739 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9231/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6696 - accuracy: 0.9724 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9232/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6711 - accuracy: 0.9732 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9233/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6736 - accuracy: 0.9742 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9234/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6877 - accuracy: 0.9743 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9235/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6432 - accuracy: 0.9745 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9236/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6898 - accuracy: 0.9722 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9237/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6597 - accuracy: 0.9745 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9238/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6749 - accuracy: 0.9730 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9239/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6437 - accuracy: 0.9739 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9240/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6768 - accuracy: 0.9729 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9241/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6600 - accuracy: 0.9734 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9242/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6713 - accuracy: 0.9743 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9243/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6743 - accuracy: 0.9732 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9244/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6876 - accuracy: 0.9742 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9245/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6815 - accuracy: 0.9730 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9246/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6570 - accuracy: 0.9744 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9247/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6993 - accuracy: 0.9744 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9248/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6670 - accuracy: 0.9732 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9249/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6355 - accuracy: 0.9743 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9250/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6642 - accuracy: 0.9740 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9251/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6666 - accuracy: 0.9743 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9252/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6757 - accuracy: 0.9733 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9253/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6722 - accuracy: 0.9727 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9254/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6725 - accuracy: 0.9733 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9255/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6866 - accuracy: 0.9745 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9256/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6795 - accuracy: 0.9740 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9257/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6780 - accuracy: 0.9742 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9258/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6779 - accuracy: 0.9740 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9259/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6657 - accuracy: 0.9727 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9260/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6631 - accuracy: 0.9733 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9261/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6867 - accuracy: 0.9729 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9262/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6861 - accuracy: 0.9725 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9263/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6847 - accuracy: 0.9745 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9264/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6752 - accuracy: 0.9730 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9265/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6752 - accuracy: 0.9724 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9266/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6622 - accuracy: 0.9743 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9267/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6924 - accuracy: 0.9727 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9268/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6915 - accuracy: 0.9730 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9269/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6696 - accuracy: 0.9731 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9270/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6700 - accuracy: 0.9739 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9271/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6842 - accuracy: 0.9715 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9272/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6903 - accuracy: 0.9734 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9273/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6825 - accuracy: 0.9725 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9274/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6806 - accuracy: 0.9727 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9275/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6731 - accuracy: 0.9725 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9276/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6876 - accuracy: 0.9723 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9277/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6595 - accuracy: 0.9736 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9278/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6735 - accuracy: 0.9743 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9279/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6492 - accuracy: 0.9735 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9280/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6713 - accuracy: 0.9728 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9281/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6657 - accuracy: 0.9730 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9282/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6690 - accuracy: 0.9731 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9283/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6803 - accuracy: 0.9732 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9284/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6917 - accuracy: 0.9728 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9285/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6565 - accuracy: 0.9731 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9286/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6546 - accuracy: 0.9733 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9287/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6526 - accuracy: 0.9735 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9288/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6619 - accuracy: 0.9734 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9289/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6946 - accuracy: 0.9729 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9290/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6727 - accuracy: 0.9726 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9291/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6773 - accuracy: 0.9724 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9292/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6710 - accuracy: 0.9730 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9293/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6771 - accuracy: 0.9722 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9294/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6639 - accuracy: 0.9740 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9295/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6881 - accuracy: 0.9726 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9296/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6639 - accuracy: 0.9715 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9297/10000\n",
            "22/22 [==============================] - 1s 42ms/step - loss: -0.6503 - accuracy: 0.9723 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9298/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6456 - accuracy: 0.9722 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9299/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6625 - accuracy: 0.9742 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9300/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6864 - accuracy: 0.9722 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9301/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6861 - accuracy: 0.9732 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9302/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6842 - accuracy: 0.9729 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9303/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6319 - accuracy: 0.9750 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9304/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6785 - accuracy: 0.9722 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9305/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6620 - accuracy: 0.9728 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9306/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6882 - accuracy: 0.9726 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9307/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6700 - accuracy: 0.9733 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9308/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6723 - accuracy: 0.9727 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9309/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6718 - accuracy: 0.9739 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9310/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6488 - accuracy: 0.9741 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9311/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6854 - accuracy: 0.9729 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9312/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6730 - accuracy: 0.9731 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9313/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6686 - accuracy: 0.9732 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9314/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6811 - accuracy: 0.9738 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9315/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6872 - accuracy: 0.9739 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9316/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6791 - accuracy: 0.9726 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9317/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6811 - accuracy: 0.9737 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9318/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6866 - accuracy: 0.9726 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9319/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6795 - accuracy: 0.9727 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9320/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6873 - accuracy: 0.9728 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9321/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6765 - accuracy: 0.9729 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9322/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6736 - accuracy: 0.9726 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9323/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6749 - accuracy: 0.9742 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9324/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6818 - accuracy: 0.9736 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9325/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6795 - accuracy: 0.9727 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9326/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6896 - accuracy: 0.9715 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9327/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6931 - accuracy: 0.9725 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9328/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6766 - accuracy: 0.9723 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9329/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6889 - accuracy: 0.9722 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9330/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6701 - accuracy: 0.9731 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9331/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6794 - accuracy: 0.9719 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9332/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6607 - accuracy: 0.9740 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9333/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6687 - accuracy: 0.9741 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9334/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6822 - accuracy: 0.9737 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9335/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6522 - accuracy: 0.9735 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9336/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6884 - accuracy: 0.9729 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9337/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6839 - accuracy: 0.9732 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9338/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6815 - accuracy: 0.9729 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9339/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6781 - accuracy: 0.9726 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9340/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6775 - accuracy: 0.9740 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9341/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6823 - accuracy: 0.9735 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9342/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6742 - accuracy: 0.9729 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9343/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6943 - accuracy: 0.9710 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9344/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6724 - accuracy: 0.9718 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9345/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6736 - accuracy: 0.9718 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9346/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6661 - accuracy: 0.9738 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9347/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6731 - accuracy: 0.9736 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9348/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6923 - accuracy: 0.9737 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9349/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6864 - accuracy: 0.9729 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9350/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6856 - accuracy: 0.9730 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9351/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6704 - accuracy: 0.9731 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9352/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6802 - accuracy: 0.9734 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9353/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6930 - accuracy: 0.9722 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9354/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6787 - accuracy: 0.9738 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9355/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6532 - accuracy: 0.9725 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9356/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.7035 - accuracy: 0.9726 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9357/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6573 - accuracy: 0.9743 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9358/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6641 - accuracy: 0.9735 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9359/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6686 - accuracy: 0.9721 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9360/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6565 - accuracy: 0.9734 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9361/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6605 - accuracy: 0.9735 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9362/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6872 - accuracy: 0.9719 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9363/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6697 - accuracy: 0.9724 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9364/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6824 - accuracy: 0.9733 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9365/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6745 - accuracy: 0.9733 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9366/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6885 - accuracy: 0.9724 - val_loss: -0.5139 - val_accuracy: 0.9690\n",
            "Epoch 9367/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6774 - accuracy: 0.9737 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9368/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6638 - accuracy: 0.9717 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9369/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6936 - accuracy: 0.9732 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9370/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6960 - accuracy: 0.9735 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9371/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6638 - accuracy: 0.9734 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9372/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6697 - accuracy: 0.9728 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9373/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6817 - accuracy: 0.9735 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9374/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6735 - accuracy: 0.9730 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9375/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6587 - accuracy: 0.9737 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9376/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6846 - accuracy: 0.9734 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9377/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6899 - accuracy: 0.9741 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9378/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6890 - accuracy: 0.9727 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9379/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6823 - accuracy: 0.9732 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9380/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6929 - accuracy: 0.9744 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9381/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6788 - accuracy: 0.9714 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9382/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6498 - accuracy: 0.9730 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9383/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6667 - accuracy: 0.9732 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9384/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6643 - accuracy: 0.9739 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9385/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6699 - accuracy: 0.9716 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9386/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6898 - accuracy: 0.9707 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9387/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6453 - accuracy: 0.9734 - val_loss: -0.5137 - val_accuracy: 0.9690\n",
            "Epoch 9388/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6821 - accuracy: 0.9735 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9389/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6714 - accuracy: 0.9735 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9390/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6699 - accuracy: 0.9741 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9391/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6603 - accuracy: 0.9743 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9392/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6625 - accuracy: 0.9719 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9393/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6853 - accuracy: 0.9724 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9394/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6947 - accuracy: 0.9739 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9395/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6650 - accuracy: 0.9738 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9396/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6669 - accuracy: 0.9733 - val_loss: -0.5162 - val_accuracy: 0.9690\n",
            "Epoch 9397/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6871 - accuracy: 0.9729 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9398/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6694 - accuracy: 0.9736 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9399/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.7049 - accuracy: 0.9737 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9400/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6828 - accuracy: 0.9718 - val_loss: -0.5139 - val_accuracy: 0.9690\n",
            "Epoch 9401/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6329 - accuracy: 0.9737 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9402/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6809 - accuracy: 0.9725 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9403/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6810 - accuracy: 0.9722 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9404/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6810 - accuracy: 0.9732 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9405/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6703 - accuracy: 0.9730 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9406/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6519 - accuracy: 0.9734 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9407/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6821 - accuracy: 0.9728 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9408/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6516 - accuracy: 0.9727 - val_loss: -0.5136 - val_accuracy: 0.9690\n",
            "Epoch 9409/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6791 - accuracy: 0.9730 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9410/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6668 - accuracy: 0.9731 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9411/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6741 - accuracy: 0.9728 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9412/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6774 - accuracy: 0.9726 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9413/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6511 - accuracy: 0.9731 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9414/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6863 - accuracy: 0.9727 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9415/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6709 - accuracy: 0.9732 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9416/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6869 - accuracy: 0.9736 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9417/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6822 - accuracy: 0.9734 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9418/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6759 - accuracy: 0.9729 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9419/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6541 - accuracy: 0.9735 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9420/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6601 - accuracy: 0.9731 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9421/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6956 - accuracy: 0.9741 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9422/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6450 - accuracy: 0.9723 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9423/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6712 - accuracy: 0.9728 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9424/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6763 - accuracy: 0.9728 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9425/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6433 - accuracy: 0.9738 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9426/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6760 - accuracy: 0.9724 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9427/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6469 - accuracy: 0.9738 - val_loss: -0.5127 - val_accuracy: 0.9690\n",
            "Epoch 9428/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6800 - accuracy: 0.9727 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9429/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6672 - accuracy: 0.9726 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9430/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6636 - accuracy: 0.9747 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9431/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6590 - accuracy: 0.9734 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9432/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6884 - accuracy: 0.9722 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9433/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6483 - accuracy: 0.9741 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9434/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6822 - accuracy: 0.9738 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9435/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6942 - accuracy: 0.9713 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9436/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6773 - accuracy: 0.9722 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9437/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6903 - accuracy: 0.9720 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9438/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6867 - accuracy: 0.9728 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9439/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6805 - accuracy: 0.9730 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9440/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6788 - accuracy: 0.9725 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9441/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6888 - accuracy: 0.9726 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9442/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6838 - accuracy: 0.9728 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9443/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6657 - accuracy: 0.9739 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9444/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6561 - accuracy: 0.9731 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9445/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.7011 - accuracy: 0.9741 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9446/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6723 - accuracy: 0.9737 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9447/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6877 - accuracy: 0.9740 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9448/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6658 - accuracy: 0.9734 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9449/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6701 - accuracy: 0.9725 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9450/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6731 - accuracy: 0.9715 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9451/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6722 - accuracy: 0.9748 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9452/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6739 - accuracy: 0.9735 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9453/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6226 - accuracy: 0.9742 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9454/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6848 - accuracy: 0.9733 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9455/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6854 - accuracy: 0.9731 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9456/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6399 - accuracy: 0.9747 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9457/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6661 - accuracy: 0.9743 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9458/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6745 - accuracy: 0.9724 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9459/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6969 - accuracy: 0.9721 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9460/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6869 - accuracy: 0.9727 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9461/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6792 - accuracy: 0.9733 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9462/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6458 - accuracy: 0.9725 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9463/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6890 - accuracy: 0.9726 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9464/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6781 - accuracy: 0.9713 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9465/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6687 - accuracy: 0.9723 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9466/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6695 - accuracy: 0.9733 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9467/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6828 - accuracy: 0.9731 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9468/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6569 - accuracy: 0.9722 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9469/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6725 - accuracy: 0.9718 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9470/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6444 - accuracy: 0.9723 - val_loss: -0.5136 - val_accuracy: 0.9690\n",
            "Epoch 9471/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6533 - accuracy: 0.9731 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9472/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6557 - accuracy: 0.9739 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9473/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6883 - accuracy: 0.9715 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9474/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6925 - accuracy: 0.9713 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9475/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6829 - accuracy: 0.9735 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9476/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6848 - accuracy: 0.9735 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9477/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6706 - accuracy: 0.9723 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9478/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6757 - accuracy: 0.9719 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9479/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6702 - accuracy: 0.9747 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9480/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6563 - accuracy: 0.9735 - val_loss: -0.5137 - val_accuracy: 0.9690\n",
            "Epoch 9481/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6614 - accuracy: 0.9737 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9482/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6856 - accuracy: 0.9733 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9483/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6654 - accuracy: 0.9734 - val_loss: -0.5138 - val_accuracy: 0.9690\n",
            "Epoch 9484/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6731 - accuracy: 0.9725 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9485/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6788 - accuracy: 0.9737 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9486/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6794 - accuracy: 0.9721 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9487/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6661 - accuracy: 0.9737 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9488/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6723 - accuracy: 0.9725 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9489/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6678 - accuracy: 0.9721 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9490/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6752 - accuracy: 0.9726 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9491/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6703 - accuracy: 0.9749 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9492/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6803 - accuracy: 0.9730 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9493/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6598 - accuracy: 0.9738 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9494/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6668 - accuracy: 0.9736 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9495/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6577 - accuracy: 0.9740 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9496/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6782 - accuracy: 0.9728 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9497/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6781 - accuracy: 0.9727 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9498/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6810 - accuracy: 0.9752 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9499/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6828 - accuracy: 0.9734 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9500/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6542 - accuracy: 0.9748 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9501/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6891 - accuracy: 0.9728 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9502/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.7023 - accuracy: 0.9723 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9503/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6983 - accuracy: 0.9734 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9504/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6728 - accuracy: 0.9739 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9505/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6942 - accuracy: 0.9732 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9506/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6759 - accuracy: 0.9744 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9507/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6760 - accuracy: 0.9727 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9508/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6849 - accuracy: 0.9722 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9509/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6859 - accuracy: 0.9747 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9510/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6786 - accuracy: 0.9733 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9511/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6815 - accuracy: 0.9709 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9512/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6632 - accuracy: 0.9724 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9513/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6925 - accuracy: 0.9727 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9514/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6778 - accuracy: 0.9714 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9515/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6665 - accuracy: 0.9724 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9516/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6703 - accuracy: 0.9740 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9517/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6639 - accuracy: 0.9736 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9518/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6559 - accuracy: 0.9741 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9519/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6886 - accuracy: 0.9746 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9520/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6789 - accuracy: 0.9737 - val_loss: -0.5138 - val_accuracy: 0.9690\n",
            "Epoch 9521/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6692 - accuracy: 0.9721 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9522/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6901 - accuracy: 0.9720 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9523/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6678 - accuracy: 0.9725 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9524/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6182 - accuracy: 0.9738 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9525/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6821 - accuracy: 0.9725 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9526/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6614 - accuracy: 0.9743 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9527/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6920 - accuracy: 0.9726 - val_loss: -0.5164 - val_accuracy: 0.9690\n",
            "Epoch 9528/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6736 - accuracy: 0.9720 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9529/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6598 - accuracy: 0.9711 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9530/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6722 - accuracy: 0.9734 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9531/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6788 - accuracy: 0.9730 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9532/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6881 - accuracy: 0.9719 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9533/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6918 - accuracy: 0.9731 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9534/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6771 - accuracy: 0.9732 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9535/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6795 - accuracy: 0.9717 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 9536/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6615 - accuracy: 0.9715 - val_loss: -0.5135 - val_accuracy: 0.9690\n",
            "Epoch 9537/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6829 - accuracy: 0.9720 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9538/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6776 - accuracy: 0.9726 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9539/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6754 - accuracy: 0.9723 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9540/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6652 - accuracy: 0.9722 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9541/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6800 - accuracy: 0.9732 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9542/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6640 - accuracy: 0.9722 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9543/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6484 - accuracy: 0.9732 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9544/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6722 - accuracy: 0.9724 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9545/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6550 - accuracy: 0.9733 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9546/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6947 - accuracy: 0.9734 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9547/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6951 - accuracy: 0.9728 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9548/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6798 - accuracy: 0.9720 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9549/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6680 - accuracy: 0.9724 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9550/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6545 - accuracy: 0.9739 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9551/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6739 - accuracy: 0.9737 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9552/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6539 - accuracy: 0.9729 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 9553/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6679 - accuracy: 0.9741 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9554/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6689 - accuracy: 0.9725 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9555/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6855 - accuracy: 0.9732 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9556/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6631 - accuracy: 0.9728 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9557/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6763 - accuracy: 0.9734 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9558/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6728 - accuracy: 0.9740 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9559/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6799 - accuracy: 0.9730 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9560/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6541 - accuracy: 0.9728 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9561/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6723 - accuracy: 0.9735 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9562/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6567 - accuracy: 0.9740 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9563/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6776 - accuracy: 0.9729 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9564/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6593 - accuracy: 0.9735 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9565/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6568 - accuracy: 0.9730 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9566/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6707 - accuracy: 0.9728 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9567/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6790 - accuracy: 0.9735 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9568/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6845 - accuracy: 0.9729 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9569/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6920 - accuracy: 0.9712 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9570/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6747 - accuracy: 0.9726 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9571/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6461 - accuracy: 0.9744 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9572/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6839 - accuracy: 0.9730 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9573/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6751 - accuracy: 0.9731 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9574/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6814 - accuracy: 0.9736 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9575/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6736 - accuracy: 0.9726 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9576/10000\n",
            "22/22 [==============================] - 1s 42ms/step - loss: -0.6798 - accuracy: 0.9732 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9577/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6918 - accuracy: 0.9736 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9578/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6796 - accuracy: 0.9724 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9579/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6769 - accuracy: 0.9721 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9580/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6854 - accuracy: 0.9728 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9581/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6826 - accuracy: 0.9744 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9582/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6808 - accuracy: 0.9739 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9583/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6749 - accuracy: 0.9737 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9584/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6806 - accuracy: 0.9713 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 9585/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6710 - accuracy: 0.9726 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9586/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6753 - accuracy: 0.9728 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9587/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6631 - accuracy: 0.9737 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9588/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6727 - accuracy: 0.9725 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9589/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6406 - accuracy: 0.9744 - val_loss: -0.5134 - val_accuracy: 0.9690\n",
            "Epoch 9590/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6766 - accuracy: 0.9738 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9591/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6807 - accuracy: 0.9711 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9592/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6510 - accuracy: 0.9729 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9593/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6693 - accuracy: 0.9726 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9594/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6608 - accuracy: 0.9728 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9595/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6786 - accuracy: 0.9730 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9596/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6934 - accuracy: 0.9734 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 9597/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6729 - accuracy: 0.9713 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9598/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6728 - accuracy: 0.9739 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9599/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6679 - accuracy: 0.9733 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9600/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6679 - accuracy: 0.9720 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9601/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6826 - accuracy: 0.9740 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9602/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6722 - accuracy: 0.9730 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9603/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6814 - accuracy: 0.9728 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9604/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6814 - accuracy: 0.9723 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9605/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6855 - accuracy: 0.9717 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9606/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6656 - accuracy: 0.9736 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9607/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6514 - accuracy: 0.9724 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9608/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6810 - accuracy: 0.9733 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9609/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6841 - accuracy: 0.9733 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9610/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6742 - accuracy: 0.9737 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9611/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6838 - accuracy: 0.9719 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9612/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6668 - accuracy: 0.9728 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9613/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6830 - accuracy: 0.9722 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9614/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6750 - accuracy: 0.9712 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9615/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6858 - accuracy: 0.9734 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9616/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6867 - accuracy: 0.9734 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9617/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6755 - accuracy: 0.9724 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9618/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6821 - accuracy: 0.9724 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9619/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6745 - accuracy: 0.9721 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9620/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6751 - accuracy: 0.9737 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9621/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6845 - accuracy: 0.9729 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9622/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6891 - accuracy: 0.9726 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9623/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6797 - accuracy: 0.9720 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9624/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6817 - accuracy: 0.9727 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9625/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6661 - accuracy: 0.9727 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9626/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6726 - accuracy: 0.9731 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9627/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6771 - accuracy: 0.9734 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9628/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6848 - accuracy: 0.9732 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9629/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6950 - accuracy: 0.9717 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9630/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6724 - accuracy: 0.9737 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9631/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6611 - accuracy: 0.9718 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9632/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6827 - accuracy: 0.9721 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9633/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6692 - accuracy: 0.9733 - val_loss: -0.5137 - val_accuracy: 0.9690\n",
            "Epoch 9634/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6846 - accuracy: 0.9717 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9635/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6744 - accuracy: 0.9727 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9636/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6733 - accuracy: 0.9723 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9637/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6867 - accuracy: 0.9735 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9638/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6704 - accuracy: 0.9736 - val_loss: -0.5158 - val_accuracy: 0.9690\n",
            "Epoch 9639/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6836 - accuracy: 0.9731 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9640/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6728 - accuracy: 0.9731 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9641/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6854 - accuracy: 0.9738 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9642/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6862 - accuracy: 0.9731 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9643/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6351 - accuracy: 0.9747 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9644/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6701 - accuracy: 0.9722 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9645/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6702 - accuracy: 0.9730 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9646/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6674 - accuracy: 0.9748 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9647/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6769 - accuracy: 0.9730 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9648/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6884 - accuracy: 0.9733 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9649/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6802 - accuracy: 0.9719 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9650/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6846 - accuracy: 0.9722 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9651/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6557 - accuracy: 0.9724 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9652/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6735 - accuracy: 0.9746 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9653/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6725 - accuracy: 0.9734 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9654/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6940 - accuracy: 0.9728 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9655/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6764 - accuracy: 0.9738 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9656/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6475 - accuracy: 0.9740 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9657/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6350 - accuracy: 0.9732 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9658/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6810 - accuracy: 0.9716 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9659/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6820 - accuracy: 0.9743 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9660/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6805 - accuracy: 0.9721 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9661/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6669 - accuracy: 0.9734 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9662/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6532 - accuracy: 0.9735 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9663/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6701 - accuracy: 0.9746 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9664/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6713 - accuracy: 0.9735 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9665/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6590 - accuracy: 0.9740 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9666/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6759 - accuracy: 0.9717 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9667/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6802 - accuracy: 0.9724 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9668/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6785 - accuracy: 0.9737 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9669/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6701 - accuracy: 0.9738 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9670/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6880 - accuracy: 0.9720 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9671/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6818 - accuracy: 0.9724 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9672/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6812 - accuracy: 0.9745 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9673/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6705 - accuracy: 0.9720 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9674/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6774 - accuracy: 0.9738 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9675/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6581 - accuracy: 0.9721 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9676/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6778 - accuracy: 0.9735 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9677/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6771 - accuracy: 0.9731 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9678/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6584 - accuracy: 0.9725 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9679/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6701 - accuracy: 0.9734 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9680/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6808 - accuracy: 0.9744 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9681/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6894 - accuracy: 0.9724 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9682/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6627 - accuracy: 0.9742 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9683/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6835 - accuracy: 0.9730 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9684/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6655 - accuracy: 0.9721 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9685/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6687 - accuracy: 0.9748 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9686/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6771 - accuracy: 0.9738 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9687/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6746 - accuracy: 0.9744 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9688/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6680 - accuracy: 0.9729 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9689/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6727 - accuracy: 0.9722 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9690/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6521 - accuracy: 0.9740 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9691/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6565 - accuracy: 0.9740 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9692/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6857 - accuracy: 0.9731 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9693/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6575 - accuracy: 0.9734 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9694/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6775 - accuracy: 0.9742 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9695/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6747 - accuracy: 0.9723 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9696/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6530 - accuracy: 0.9722 - val_loss: -0.5139 - val_accuracy: 0.9690\n",
            "Epoch 9697/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6499 - accuracy: 0.9740 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9698/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6682 - accuracy: 0.9722 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9699/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6729 - accuracy: 0.9721 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9700/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6949 - accuracy: 0.9733 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9701/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6741 - accuracy: 0.9734 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9702/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6861 - accuracy: 0.9734 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9703/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6839 - accuracy: 0.9739 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9704/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6754 - accuracy: 0.9736 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9705/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6780 - accuracy: 0.9723 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9706/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6751 - accuracy: 0.9722 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9707/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6794 - accuracy: 0.9737 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9708/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6617 - accuracy: 0.9738 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9709/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6680 - accuracy: 0.9729 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9710/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6677 - accuracy: 0.9736 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9711/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6725 - accuracy: 0.9745 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9712/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6683 - accuracy: 0.9733 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9713/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6705 - accuracy: 0.9735 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9714/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6850 - accuracy: 0.9738 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9715/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6809 - accuracy: 0.9720 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9716/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6804 - accuracy: 0.9722 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9717/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6716 - accuracy: 0.9748 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 9718/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6685 - accuracy: 0.9735 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9719/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6738 - accuracy: 0.9739 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9720/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6736 - accuracy: 0.9727 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9721/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6869 - accuracy: 0.9728 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9722/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6691 - accuracy: 0.9746 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9723/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6834 - accuracy: 0.9720 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9724/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6881 - accuracy: 0.9719 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9725/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6609 - accuracy: 0.9727 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9726/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6702 - accuracy: 0.9730 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9727/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6564 - accuracy: 0.9730 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 9728/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6780 - accuracy: 0.9721 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9729/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6489 - accuracy: 0.9725 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9730/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6709 - accuracy: 0.9730 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9731/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6710 - accuracy: 0.9728 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9732/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6506 - accuracy: 0.9729 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9733/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6667 - accuracy: 0.9726 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9734/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6713 - accuracy: 0.9736 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9735/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6796 - accuracy: 0.9741 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9736/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6719 - accuracy: 0.9741 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9737/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6657 - accuracy: 0.9739 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9738/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6847 - accuracy: 0.9740 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9739/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6566 - accuracy: 0.9729 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9740/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6268 - accuracy: 0.9755 - val_loss: -0.5138 - val_accuracy: 0.9690\n",
            "Epoch 9741/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6672 - accuracy: 0.9739 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9742/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6635 - accuracy: 0.9736 - val_loss: -0.5139 - val_accuracy: 0.9690\n",
            "Epoch 9743/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6522 - accuracy: 0.9728 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9744/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6789 - accuracy: 0.9724 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9745/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6788 - accuracy: 0.9736 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9746/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6894 - accuracy: 0.9717 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9747/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6960 - accuracy: 0.9733 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9748/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6796 - accuracy: 0.9715 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9749/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6753 - accuracy: 0.9732 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9750/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6868 - accuracy: 0.9719 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9751/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6790 - accuracy: 0.9731 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9752/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6690 - accuracy: 0.9735 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9753/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6930 - accuracy: 0.9724 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9754/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6631 - accuracy: 0.9736 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9755/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6746 - accuracy: 0.9738 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9756/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6726 - accuracy: 0.9744 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9757/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6716 - accuracy: 0.9716 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9758/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6958 - accuracy: 0.9717 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9759/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6666 - accuracy: 0.9733 - val_loss: -0.5136 - val_accuracy: 0.9690\n",
            "Epoch 9760/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6746 - accuracy: 0.9734 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9761/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6753 - accuracy: 0.9719 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9762/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6439 - accuracy: 0.9733 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9763/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6704 - accuracy: 0.9735 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9764/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6807 - accuracy: 0.9711 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9765/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6877 - accuracy: 0.9732 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9766/10000\n",
            "22/22 [==============================] - 1s 37ms/step - loss: -0.6728 - accuracy: 0.9735 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9767/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6856 - accuracy: 0.9732 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9768/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6713 - accuracy: 0.9724 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9769/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6804 - accuracy: 0.9730 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9770/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6852 - accuracy: 0.9736 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9771/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6799 - accuracy: 0.9729 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9772/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6739 - accuracy: 0.9733 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9773/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6865 - accuracy: 0.9727 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9774/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.7068 - accuracy: 0.9744 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9775/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6682 - accuracy: 0.9737 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9776/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6751 - accuracy: 0.9729 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9777/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6742 - accuracy: 0.9717 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9778/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6820 - accuracy: 0.9729 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9779/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6697 - accuracy: 0.9729 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9780/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6868 - accuracy: 0.9726 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9781/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6768 - accuracy: 0.9725 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9782/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6728 - accuracy: 0.9734 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9783/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6847 - accuracy: 0.9746 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9784/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6600 - accuracy: 0.9724 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9785/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6413 - accuracy: 0.9733 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9786/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6732 - accuracy: 0.9727 - val_loss: -0.5138 - val_accuracy: 0.9690\n",
            "Epoch 9787/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6665 - accuracy: 0.9732 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9788/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6723 - accuracy: 0.9723 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9789/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6796 - accuracy: 0.9725 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9790/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6841 - accuracy: 0.9730 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9791/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6877 - accuracy: 0.9730 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9792/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6776 - accuracy: 0.9732 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9793/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6911 - accuracy: 0.9730 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9794/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6754 - accuracy: 0.9730 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9795/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6814 - accuracy: 0.9716 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9796/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6643 - accuracy: 0.9730 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9797/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6901 - accuracy: 0.9745 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9798/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6671 - accuracy: 0.9726 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9799/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6716 - accuracy: 0.9744 - val_loss: -0.5139 - val_accuracy: 0.9690\n",
            "Epoch 9800/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6746 - accuracy: 0.9717 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9801/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6677 - accuracy: 0.9739 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9802/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6565 - accuracy: 0.9724 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9803/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6643 - accuracy: 0.9726 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9804/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6870 - accuracy: 0.9749 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9805/10000\n",
            "22/22 [==============================] - 1s 42ms/step - loss: -0.6332 - accuracy: 0.9735 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9806/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6892 - accuracy: 0.9726 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9807/10000\n",
            "22/22 [==============================] - 1s 42ms/step - loss: -0.6901 - accuracy: 0.9722 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9808/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6760 - accuracy: 0.9719 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9809/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6727 - accuracy: 0.9739 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9810/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6865 - accuracy: 0.9722 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9811/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6817 - accuracy: 0.9720 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9812/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6637 - accuracy: 0.9743 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9813/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6953 - accuracy: 0.9718 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9814/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6868 - accuracy: 0.9730 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9815/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6584 - accuracy: 0.9730 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9816/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6780 - accuracy: 0.9728 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9817/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6900 - accuracy: 0.9727 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9818/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6691 - accuracy: 0.9737 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9819/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6830 - accuracy: 0.9739 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9820/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6639 - accuracy: 0.9721 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9821/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6739 - accuracy: 0.9733 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9822/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6795 - accuracy: 0.9743 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9823/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6684 - accuracy: 0.9738 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9824/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6685 - accuracy: 0.9741 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9825/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6939 - accuracy: 0.9731 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9826/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6836 - accuracy: 0.9736 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9827/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6813 - accuracy: 0.9710 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9828/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6753 - accuracy: 0.9744 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9829/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6828 - accuracy: 0.9719 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9830/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6874 - accuracy: 0.9738 - val_loss: -0.5156 - val_accuracy: 0.9690\n",
            "Epoch 9831/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6646 - accuracy: 0.9739 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9832/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6624 - accuracy: 0.9725 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9833/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6736 - accuracy: 0.9740 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9834/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6726 - accuracy: 0.9716 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9835/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6723 - accuracy: 0.9740 - val_loss: -0.5135 - val_accuracy: 0.9690\n",
            "Epoch 9836/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6856 - accuracy: 0.9729 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9837/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6923 - accuracy: 0.9739 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9838/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6791 - accuracy: 0.9732 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9839/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6644 - accuracy: 0.9729 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9840/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6939 - accuracy: 0.9725 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9841/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6793 - accuracy: 0.9717 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9842/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6711 - accuracy: 0.9737 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9843/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6818 - accuracy: 0.9733 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9844/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6918 - accuracy: 0.9729 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9845/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6586 - accuracy: 0.9724 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9846/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6820 - accuracy: 0.9737 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9847/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6777 - accuracy: 0.9741 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9848/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6787 - accuracy: 0.9735 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9849/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6514 - accuracy: 0.9736 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9850/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6825 - accuracy: 0.9740 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9851/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6768 - accuracy: 0.9733 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9852/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6951 - accuracy: 0.9739 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9853/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6929 - accuracy: 0.9740 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9854/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6823 - accuracy: 0.9747 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9855/10000\n",
            "22/22 [==============================] - 1s 42ms/step - loss: -0.6809 - accuracy: 0.9731 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9856/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6675 - accuracy: 0.9725 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9857/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6747 - accuracy: 0.9729 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9858/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6743 - accuracy: 0.9742 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9859/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6739 - accuracy: 0.9741 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9860/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6851 - accuracy: 0.9717 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9861/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6694 - accuracy: 0.9729 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9862/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6721 - accuracy: 0.9726 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9863/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6775 - accuracy: 0.9734 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9864/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6842 - accuracy: 0.9731 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9865/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6870 - accuracy: 0.9744 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9866/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6736 - accuracy: 0.9730 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9867/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6762 - accuracy: 0.9731 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9868/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6704 - accuracy: 0.9735 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9869/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6767 - accuracy: 0.9727 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9870/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6873 - accuracy: 0.9725 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9871/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6593 - accuracy: 0.9740 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9872/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6930 - accuracy: 0.9726 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9873/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6690 - accuracy: 0.9736 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9874/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6827 - accuracy: 0.9715 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9875/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6719 - accuracy: 0.9729 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9876/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6821 - accuracy: 0.9731 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9877/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6485 - accuracy: 0.9740 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9878/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6872 - accuracy: 0.9725 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9879/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6870 - accuracy: 0.9723 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9880/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6965 - accuracy: 0.9720 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9881/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6785 - accuracy: 0.9730 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9882/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6657 - accuracy: 0.9732 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9883/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6718 - accuracy: 0.9742 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9884/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6959 - accuracy: 0.9746 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9885/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6833 - accuracy: 0.9740 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9886/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6773 - accuracy: 0.9742 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9887/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6730 - accuracy: 0.9730 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9888/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6804 - accuracy: 0.9734 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9889/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6949 - accuracy: 0.9728 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9890/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6642 - accuracy: 0.9737 - val_loss: -0.5139 - val_accuracy: 0.9690\n",
            "Epoch 9891/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6803 - accuracy: 0.9742 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9892/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6849 - accuracy: 0.9742 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9893/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6616 - accuracy: 0.9724 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9894/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.7012 - accuracy: 0.9731 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9895/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6838 - accuracy: 0.9742 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9896/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6740 - accuracy: 0.9746 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9897/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6532 - accuracy: 0.9744 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9898/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6913 - accuracy: 0.9730 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9899/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6745 - accuracy: 0.9734 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9900/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6941 - accuracy: 0.9739 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9901/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6698 - accuracy: 0.9736 - val_loss: -0.5139 - val_accuracy: 0.9690\n",
            "Epoch 9902/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6567 - accuracy: 0.9753 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9903/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6459 - accuracy: 0.9738 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9904/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6764 - accuracy: 0.9729 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9905/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6691 - accuracy: 0.9739 - val_loss: -0.5138 - val_accuracy: 0.9690\n",
            "Epoch 9906/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6548 - accuracy: 0.9725 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9907/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6875 - accuracy: 0.9719 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9908/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6838 - accuracy: 0.9723 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9909/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6833 - accuracy: 0.9706 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9910/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6900 - accuracy: 0.9714 - val_loss: -0.5154 - val_accuracy: 0.9690\n",
            "Epoch 9911/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6760 - accuracy: 0.9713 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9912/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6888 - accuracy: 0.9730 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9913/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6696 - accuracy: 0.9732 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9914/10000\n",
            "22/22 [==============================] - 1s 42ms/step - loss: -0.6816 - accuracy: 0.9733 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9915/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6889 - accuracy: 0.9736 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9916/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6809 - accuracy: 0.9717 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9917/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6806 - accuracy: 0.9724 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9918/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6963 - accuracy: 0.9735 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9919/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6838 - accuracy: 0.9732 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9920/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6582 - accuracy: 0.9743 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9921/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6840 - accuracy: 0.9731 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9922/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6726 - accuracy: 0.9739 - val_loss: -0.5136 - val_accuracy: 0.9690\n",
            "Epoch 9923/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6776 - accuracy: 0.9730 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9924/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6710 - accuracy: 0.9730 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9925/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6833 - accuracy: 0.9724 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9926/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6724 - accuracy: 0.9734 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9927/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6846 - accuracy: 0.9728 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9928/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6472 - accuracy: 0.9728 - val_loss: -0.5141 - val_accuracy: 0.9690\n",
            "Epoch 9929/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6892 - accuracy: 0.9740 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9930/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6694 - accuracy: 0.9734 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9931/10000\n",
            "22/22 [==============================] - 1s 42ms/step - loss: -0.6907 - accuracy: 0.9739 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9932/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6637 - accuracy: 0.9724 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9933/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6568 - accuracy: 0.9736 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9934/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6622 - accuracy: 0.9724 - val_loss: -0.5139 - val_accuracy: 0.9690\n",
            "Epoch 9935/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6715 - accuracy: 0.9728 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9936/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6856 - accuracy: 0.9746 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9937/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6681 - accuracy: 0.9724 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9938/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6728 - accuracy: 0.9746 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9939/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6614 - accuracy: 0.9740 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9940/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6823 - accuracy: 0.9735 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9941/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6701 - accuracy: 0.9732 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9942/10000\n",
            "22/22 [==============================] - 1s 42ms/step - loss: -0.6715 - accuracy: 0.9727 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9943/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6763 - accuracy: 0.9723 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9944/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6870 - accuracy: 0.9733 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9945/10000\n",
            "22/22 [==============================] - 1s 42ms/step - loss: -0.6523 - accuracy: 0.9720 - val_loss: -0.5137 - val_accuracy: 0.9690\n",
            "Epoch 9946/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6707 - accuracy: 0.9733 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9947/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6566 - accuracy: 0.9732 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9948/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6852 - accuracy: 0.9750 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9949/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6744 - accuracy: 0.9729 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9950/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6726 - accuracy: 0.9732 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9951/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6685 - accuracy: 0.9729 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9952/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6728 - accuracy: 0.9742 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9953/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6759 - accuracy: 0.9739 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9954/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6708 - accuracy: 0.9729 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9955/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6737 - accuracy: 0.9745 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9956/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6696 - accuracy: 0.9726 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9957/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6839 - accuracy: 0.9737 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9958/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6828 - accuracy: 0.9728 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9959/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6492 - accuracy: 0.9742 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9960/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6838 - accuracy: 0.9726 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9961/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6840 - accuracy: 0.9741 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9962/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6664 - accuracy: 0.9732 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9963/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6914 - accuracy: 0.9738 - val_loss: -0.5147 - val_accuracy: 0.9690\n",
            "Epoch 9964/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6826 - accuracy: 0.9729 - val_loss: -0.5159 - val_accuracy: 0.9690\n",
            "Epoch 9965/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6516 - accuracy: 0.9742 - val_loss: -0.5139 - val_accuracy: 0.9690\n",
            "Epoch 9966/10000\n",
            "22/22 [==============================] - 1s 41ms/step - loss: -0.6763 - accuracy: 0.9724 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9967/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6730 - accuracy: 0.9739 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9968/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6849 - accuracy: 0.9730 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9969/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6646 - accuracy: 0.9736 - val_loss: -0.5143 - val_accuracy: 0.9690\n",
            "Epoch 9970/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6767 - accuracy: 0.9738 - val_loss: -0.5149 - val_accuracy: 0.9690\n",
            "Epoch 9971/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6724 - accuracy: 0.9727 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9972/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6747 - accuracy: 0.9749 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9973/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6666 - accuracy: 0.9735 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9974/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6644 - accuracy: 0.9734 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9975/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6956 - accuracy: 0.9729 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9976/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6551 - accuracy: 0.9728 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9977/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6732 - accuracy: 0.9730 - val_loss: -0.5153 - val_accuracy: 0.9690\n",
            "Epoch 9978/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6757 - accuracy: 0.9741 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9979/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6879 - accuracy: 0.9732 - val_loss: -0.5155 - val_accuracy: 0.9690\n",
            "Epoch 9980/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6738 - accuracy: 0.9741 - val_loss: -0.5146 - val_accuracy: 0.9690\n",
            "Epoch 9981/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6760 - accuracy: 0.9726 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9982/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6729 - accuracy: 0.9725 - val_loss: -0.5145 - val_accuracy: 0.9690\n",
            "Epoch 9983/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6576 - accuracy: 0.9728 - val_loss: -0.5144 - val_accuracy: 0.9690\n",
            "Epoch 9984/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6930 - accuracy: 0.9730 - val_loss: -0.5151 - val_accuracy: 0.9690\n",
            "Epoch 9985/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6668 - accuracy: 0.9741 - val_loss: -0.5139 - val_accuracy: 0.9690\n",
            "Epoch 9986/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6250 - accuracy: 0.9727 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9987/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6651 - accuracy: 0.9739 - val_loss: -0.5160 - val_accuracy: 0.9690\n",
            "Epoch 9988/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6481 - accuracy: 0.9741 - val_loss: -0.5140 - val_accuracy: 0.9690\n",
            "Epoch 9989/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6886 - accuracy: 0.9726 - val_loss: -0.5148 - val_accuracy: 0.9690\n",
            "Epoch 9990/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6802 - accuracy: 0.9733 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9991/10000\n",
            "22/22 [==============================] - 1s 38ms/step - loss: -0.6865 - accuracy: 0.9727 - val_loss: -0.5142 - val_accuracy: 0.9690\n",
            "Epoch 9992/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6641 - accuracy: 0.9737 - val_loss: -0.5139 - val_accuracy: 0.9690\n",
            "Epoch 9993/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6887 - accuracy: 0.9731 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 9994/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6787 - accuracy: 0.9729 - val_loss: -0.5138 - val_accuracy: 0.9690\n",
            "Epoch 9995/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6504 - accuracy: 0.9726 - val_loss: -0.5157 - val_accuracy: 0.9690\n",
            "Epoch 9996/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6665 - accuracy: 0.9743 - val_loss: -0.5138 - val_accuracy: 0.9690\n",
            "Epoch 9997/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6800 - accuracy: 0.9728 - val_loss: -0.5150 - val_accuracy: 0.9690\n",
            "Epoch 9998/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6704 - accuracy: 0.9727 - val_loss: -0.5135 - val_accuracy: 0.9690\n",
            "Epoch 9999/10000\n",
            "22/22 [==============================] - 1s 40ms/step - loss: -0.6763 - accuracy: 0.9732 - val_loss: -0.5152 - val_accuracy: 0.9690\n",
            "Epoch 10000/10000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: -0.6406 - accuracy: 0.9742 - val_loss: -0.5130 - val_accuracy: 0.9690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsz8tQtLxOGm",
        "outputId": "e0bc9e50-cb33-424d-c24f-54a289ed93b6"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "cROrlxCNxPbI",
        "outputId": "22ba213a-72fd-42d8-e754-e9778b51793d"
      },
      "source": [
        "# \"Loss\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "1XB5VM4zxa1-",
        "outputId": "44559c60-ff29-4bef-86bf-755a436d8c7d"
      },
      "source": [
        "#  \"Accuracy\"\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0OxFWo3YZQs"
      },
      "source": [
        "model.save_weights('weights.h5')\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ttCdb_EYcnQ"
      },
      "source": [
        "pred = model.predict(x[:50])\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "1mt_jPnvYid0",
        "outputId": "2b6fc524-c9dc-4d4a-8ba7-100e4067accb"
      },
      "source": [
        "import random as r\n",
        "num = int(x.shape[1]/2)\n",
        "for n in range(3):\n",
        "    i = int(r.random() * pred.shape[0])\n",
        "    plt.figure(figsize=(15,10))\n",
        "\n",
        "    plt.subplot(131)\n",
        "    plt.title('Input')\n",
        "    plt.imshow(x[i, num, :, :, 0])\n",
        "\n",
        "    plt.subplot(132)\n",
        "    plt.title('Ground Truth')\n",
        "    plt.imshow(y[i, num, :, :, 0])\n",
        "\n",
        "    plt.subplot(133)\n",
        "    plt.title('Prediction')\n",
        "    plt.imshow(pred[i, num, :, :, 0])\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}