{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq+PUvrx3e5xUKaS3ofGoL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divsal009/div/blob/master/HOME1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/DD.csv')\n",
        "\n",
        "# Combine 'Assistive Technology' and 'Customized Housing Design' into a single column for multiclass prediction\n",
        "df['Assistive_Cust_Design'] = df['Assistive Technology'] + ' + ' + df['Customized Housing Design']\n",
        "\n",
        "# Drop unnecessary columns\n",
        "X = df[['Specific Disease', 'Body Functions', 'Activities and Participation', 'Home Functions']]\n",
        "y = df['Assistive_Cust_Design']\n",
        "\n",
        "# Apply one-hot encoding to categorical columns in X\n",
        "X = pd.get_dummies(X, columns=['Specific Disease', 'Body Functions', 'Activities and Participation', 'Home Functions'])\n",
        "\n",
        "# Convert all columns in X to float to avoid issues with SMOTE\n",
        "X = X.astype(float)\n",
        "\n",
        "# Encode the target variable (y) using LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "target_encoder = LabelEncoder()\n",
        "y = target_encoder.fit_transform(y)\n",
        "\n",
        "# Handle imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize XGBoost classifier\n",
        "xgb_clf = xgb.XGBClassifier()\n",
        "\n",
        "# Define hyperparameter search space\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'subsample': [0.7, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'reg_lambda': [1, 1.5, 2],\n",
        "    'reg_alpha': [0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# Use RandomizedSearchCV to find the best hyperparameters\n",
        "random_search = RandomizedSearchCV(estimator=xgb_clf, param_distributions=param_dist, n_iter=50,\n",
        "                                   cv=3, verbose=2, n_jobs=-1, random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters from the search\n",
        "print(f\"Best parameters: {random_search.best_params_}\")\n",
        "\n",
        "# Use the best estimator for predictions\n",
        "best_xgb = random_search.best_estimator_\n",
        "\n",
        "# Evaluate the model using cross-validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "cv_scores = cross_val_score(best_xgb, X_train, y_train, cv=5)\n",
        "print(f\"Cross-validation scores: {cv_scores}\")\n",
        "print(f\"Mean cross-validation score: {cv_scores.mean() * 100:.2f}%\")\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Function to safely encode new input data\n",
        "def predict_assistive_and_design(specific_disease, body_functions, activities, home_functions):\n",
        "    input_data = pd.DataFrame({\n",
        "        'Specific Disease': [specific_disease],\n",
        "        'Body Functions': [body_functions],\n",
        "        'Activities and Participation': [activities],\n",
        "        'Home Functions': [home_functions]\n",
        "    })\n",
        "\n",
        "    # Apply one-hot encoding to the input data\n",
        "    input_data = pd.get_dummies(input_data)\n",
        "\n",
        "    # Align the columns with the training data to avoid dimension mismatches\n",
        "    input_data = input_data.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    # Predict\n",
        "    prediction = best_xgb.predict(input_data)\n",
        "\n",
        "    # Decode the prediction back to original label\n",
        "    return target_encoder.inverse_transform(prediction)[0]\n",
        "\n",
        "# Example prediction\n",
        "print(predict_assistive_and_design('Parkinsons Disease', 'Hearing functions (b230)', 'Limited mobility (d455)', 'Old building (e150)'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHhODwE96gNP",
        "outputId": "8f3569ec-d252-4b09-9691-414fd2cf22cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "Best parameters: {'subsample': 0.8, 'reg_lambda': 2, 'reg_alpha': 0, 'n_estimators': 300, 'max_depth': 15, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.7}\n",
            "Cross-validation scores: [0.19  0.145 0.1   0.185 0.14 ]\n",
            "Mean cross-validation score: 15.20%\n",
            "Test accuracy: 12.80%\n",
            "Voice-activated devices (e120) + Enhanced lighting (e155)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/DD.csv')\n",
        "\n",
        "# Drop unnecessary columns and separate the tasks\n",
        "X = df[['Specific Disease', 'Body Functions', 'Activities and Participation', 'Home Functions']]\n",
        "y_assistive = df['Assistive Technology']  # Separate the target for Assistive Technology\n",
        "y_housing = df['Customized Housing Design']  # Separate the target for Customized Housing Design\n",
        "\n",
        "# Apply one-hot encoding to categorical columns in X\n",
        "X = pd.get_dummies(X, columns=['Specific Disease', 'Body Functions', 'Activities and Participation', 'Home Functions'])\n",
        "\n",
        "# Convert all columns in X to float\n",
        "X = X.astype(float)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Handle imbalance using SMOTE for Assistive Technology\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled_assistive, y_resampled_assistive = smote.fit_resample(X_scaled, y_assistive)\n",
        "\n",
        "# Handle imbalance using SMOTE for Customized Housing Design\n",
        "X_resampled_housing, y_resampled_housing = smote.fit_resample(X_scaled, y_housing)\n",
        "\n",
        "# Split the dataset into training and testing sets for both tasks\n",
        "X_train_assistive, X_test_assistive, y_train_assistive, y_test_assistive = train_test_split(X_resampled_assistive, y_resampled_assistive, test_size=0.2, random_state=42)\n",
        "X_train_housing, X_test_housing, y_train_housing, y_test_housing = train_test_split(X_resampled_housing, y_resampled_housing, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_clf_assistive = RandomForestClassifier(random_state=42)\n",
        "rf_clf_housing = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define hyperparameter search space for Random Forest (Assistive Technology)\n",
        "param_dist_assistive = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Define hyperparameter search space for Random Forest (Customized Housing Design)\n",
        "param_dist_housing = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Use RandomizedSearchCV to find the best hyperparameters for Assistive Technology\n",
        "random_search_assistive = RandomizedSearchCV(estimator=rf_clf_assistive, param_distributions=param_dist_assistive, n_iter=50,\n",
        "                                             cv=3, verbose=2, n_jobs=-1, random_state=42)\n",
        "random_search_assistive.fit(X_train_assistive, y_train_assistive)\n",
        "\n",
        "# Use RandomizedSearchCV to find the best hyperparameters for Customized Housing Design\n",
        "random_search_housing = RandomizedSearchCV(estimator=rf_clf_housing, param_distributions=param_dist_housing, n_iter=50,\n",
        "                                           cv=3, verbose=2, n_jobs=-1, random_state=42)\n",
        "random_search_housing.fit(X_train_housing, y_train_housing)\n",
        "\n",
        "# Best parameters from the search (Assistive Technology)\n",
        "print(f\"Best parameters for Assistive Technology: {random_search_assistive.best_params_}\")\n",
        "\n",
        "# Best parameters from the search (Customized Housing Design)\n",
        "print(f\"Best parameters for Customized Housing Design: {random_search_housing.best_params_}\")\n",
        "\n",
        "# Use the best estimator for Assistive Technology predictions\n",
        "best_rf_assistive = random_search_assistive.best_estimator_\n",
        "\n",
        "# Use the best estimator for Customized Housing Design predictions\n",
        "best_rf_housing = random_search_housing.best_estimator_\n",
        "\n",
        "# Make predictions on the test set using the best model for Assistive Technology\n",
        "y_pred_assistive = best_rf_assistive.predict(X_test_assistive)\n",
        "\n",
        "# Make predictions on the test set using the best model for Customized Housing Design\n",
        "y_pred_housing = best_rf_housing.predict(X_test_housing)\n",
        "\n",
        "# Evaluate the model for Assistive Technology\n",
        "accuracy_assistive = accuracy_score(y_test_assistive, y_pred_assistive)\n",
        "print(f\"Test accuracy for Assistive Technology: {accuracy_assistive * 100:.2f}%\")\n",
        "\n",
        "# Evaluate the model for Customized Housing Design\n",
        "accuracy_housing = accuracy_score(y_test_housing, y_pred_housing)\n",
        "print(f\"Test accuracy for Customized Housing Design: {accuracy_housing * 100:.2f}%\")\n",
        "\n",
        "# Function to safely predict Assistive Technology and Housing Design separately\n",
        "def predict_assistive_and_design(specific_disease, body_functions, activities, home_functions):\n",
        "    input_data = pd.DataFrame({\n",
        "        'Specific Disease': [specific_disease],\n",
        "        'Body Functions': [body_functions],\n",
        "        'Activities and Participation': [activities],\n",
        "        'Home Functions': [home_functions]\n",
        "    })\n",
        "\n",
        "    # Apply one-hot encoding to the input data\n",
        "    input_data = pd.get_dummies(input_data)\n",
        "\n",
        "    # Align the columns with the training data to avoid dimension mismatches\n",
        "    input_data = input_data.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    # Scale the input data\n",
        "    input_data_scaled = scaler.transform(input_data)\n",
        "\n",
        "    # Predict Assistive Technology\n",
        "    prediction_assistive = best_rf_assistive.predict(input_data_scaled)\n",
        "\n",
        "    # Predict Customized Housing Design\n",
        "    prediction_housing = best_rf_housing.predict(input_data_scaled)\n",
        "\n",
        "    return prediction_assistive[0], prediction_housing[0]\n",
        "\n",
        "# Example prediction\n",
        "assistive_pred, housing_pred = predict_assistive_and_design('Parkinsons Disease', 'Hearing functions (b230)', 'Limited mobility (d455)', 'Old building (e150)')\n",
        "print(f\"Predicted Assistive Technology: {assistive_pred}\")\n",
        "print(f\"Predicted Customized Housing Design: {housing_pred}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo872CeM9-HY",
        "outputId": "e20ffac1-ba57-4a6d-93fb-becf09fe1381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "Best parameters for Assistive Technology: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 30, 'bootstrap': False}\n",
            "Best parameters for Customized Housing Design: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 10, 'bootstrap': True}\n",
            "Test accuracy for Assistive Technology: 23.53%\n",
            "Test accuracy for Customized Housing Design: 23.04%\n",
            "Predicted Assistive Technology: Voice-activated devices (e120)\n",
            "Predicted Customized Housing Design: Smart Home Integration (e155)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/DD.csv')\n",
        "\n",
        "# Drop unnecessary columns and separate the tasks\n",
        "X = df[['Specific Disease', 'Body Functions', 'Activities and Participation', 'Home Functions']]\n",
        "y_assistive = df['Assistive Technology']  # Separate the target for Assistive Technology\n",
        "y_housing = df['Customized Housing Design']  # Separate the target for Customized Housing Design\n",
        "\n",
        "# Apply one-hot encoding to categorical columns in X\n",
        "X = pd.get_dummies(X, columns=['Specific Disease', 'Body Functions', 'Activities and Participation', 'Home Functions'])\n",
        "\n",
        "# Convert all columns in X to float\n",
        "X = X.astype(float)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# **Encode the target variables (Assistive Technology and Customized Housing Design)**\n",
        "le_assistive = LabelEncoder()\n",
        "y_assistive_encoded = le_assistive.fit_transform(y_assistive)\n",
        "\n",
        "le_housing = LabelEncoder()\n",
        "y_housing_encoded = le_housing.fit_transform(y_housing)\n",
        "\n",
        "# Handle imbalance using SMOTE for Assistive Technology\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled_assistive, y_resampled_assistive = smote.fit_resample(X_scaled, y_assistive_encoded)\n",
        "\n",
        "# Handle imbalance using SMOTE for Customized Housing Design\n",
        "X_resampled_housing, y_resampled_housing = smote.fit_resample(X_scaled, y_housing_encoded)\n",
        "\n",
        "# Split the dataset into training and testing sets for both tasks\n",
        "X_train_assistive, X_test_assistive, y_train_assistive, y_test_assistive = train_test_split(X_resampled_assistive, y_resampled_assistive, test_size=0.2, random_state=42)\n",
        "X_train_housing, X_test_housing, y_train_housing, y_test_housing = train_test_split(X_resampled_housing, y_resampled_housing, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize XGBoost classifier for Assistive Technology\n",
        "xgb_clf_assistive = XGBClassifier(random_state=42)\n",
        "\n",
        "# Initialize XGBoost classifier for Customized Housing Design\n",
        "xgb_clf_housing = XGBClassifier(random_state=42)\n",
        "\n",
        "# Define hyperparameter search space for XGBoost (Assistive Technology)\n",
        "param_dist_assistive = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'max_depth': [5, 10, 20],\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'subsample': [0.7, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# Define hyperparameter search space for XGBoost (Customized Housing Design)\n",
        "param_dist_housing = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'max_depth': [5, 10, 20],\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'subsample': [0.7, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# Use RandomizedSearchCV to find the best hyperparameters for Assistive Technology\n",
        "random_search_assistive = RandomizedSearchCV(estimator=xgb_clf_assistive, param_distributions=param_dist_assistive, n_iter=50,\n",
        "                                             cv=3, verbose=2, n_jobs=-1, random_state=42)\n",
        "random_search_assistive.fit(X_train_assistive, y_train_assistive)\n",
        "\n",
        "# Use RandomizedSearchCV to find the best hyperparameters for Customized Housing Design\n",
        "random_search_housing = RandomizedSearchCV(estimator=xgb_clf_housing, param_distributions=param_dist_housing, n_iter=50,\n",
        "                                           cv=3, verbose=2, n_jobs=-1, random_state=42)\n",
        "random_search_housing.fit(X_train_housing, y_train_housing)\n",
        "\n",
        "# Best parameters from the search (Assistive Technology)\n",
        "print(f\"Best parameters for Assistive Technology: {random_search_assistive.best_params_}\")\n",
        "\n",
        "# Best parameters from the search (Customized Housing Design)\n",
        "print(f\"Best parameters for Customized Housing Design: {random_search_housing.best_params_}\")\n",
        "\n",
        "# Use the best estimator for Assistive Technology predictions\n",
        "best_xgb_assistive = random_search_assistive.best_estimator_\n",
        "\n",
        "# Use the best estimator for Customized Housing Design predictions\n",
        "best_xgb_housing = random_search_housing.best_estimator_\n",
        "\n",
        "# Make predictions on the test set using the best model for Assistive Technology\n",
        "y_pred_assistive = best_xgb_assistive.predict(X_test_assistive)\n",
        "\n",
        "# Make predictions on the test set using the best model for Customized Housing Design\n",
        "y_pred_housing = best_xgb_housing.predict(X_test_housing)\n",
        "\n",
        "# Evaluate the model for Assistive Technology\n",
        "accuracy_assistive = accuracy_score(y_test_assistive, y_pred_assistive)\n",
        "print(f\"Test accuracy for Assistive Technology: {accuracy_assistive * 100:.2f}%\")\n",
        "\n",
        "# Evaluate the model for Customized Housing Design\n",
        "accuracy_housing = accuracy_score(y_test_housing, y_pred_housing)\n",
        "print(f\"Test accuracy for Customized Housing Design: {accuracy_housing * 100:.2f}%\")\n",
        "\n",
        "# Function to predict Assistive Technology and Housing Design separately\n",
        "def predict_assistive_and_design(specific_disease, body_functions, activities, home_functions):\n",
        "    input_data = pd.DataFrame({\n",
        "        'Specific Disease': [specific_disease],\n",
        "        'Body Functions': [body_functions],\n",
        "        'Activities and Participation': [activities],\n",
        "        'Home Functions': [home_functions]\n",
        "    })\n",
        "\n",
        "    # Apply one-hot encoding to the input data\n",
        "    input_data = pd.get_dummies(input_data)\n",
        "\n",
        "    # Align the columns with the training data to avoid dimension mismatches\n",
        "    input_data = input_data.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    # Scale the input data\n",
        "    input_data_scaled = scaler.transform(input_data)\n",
        "\n",
        "    # Predict Assistive Technology\n",
        "    prediction_assistive = best_xgb_assistive.predict(input_data_scaled)\n",
        "\n",
        "    # Predict Customized Housing Design\n",
        "    prediction_housing = best_xgb_housing.predict(input_data_scaled)\n",
        "\n",
        "    return le_assistive.inverse_transform([prediction_assistive[0]]), le_housing.inverse_transform([prediction_housing[0]])\n",
        "\n",
        "# Example prediction\n",
        "assistive_pred, housing_pred = predict_assistive_and_design('Parkinsons Disease', 'Hearing functions (b230)', 'Limited mobility (d455)', 'Old building (e150)')\n",
        "print(f\"Predicted Assistive Technology: {assistive_pred[0]}\")\n",
        "print(f\"Predicted Customized Housing Design: {housing_pred[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTmhV8zL_HSV",
        "outputId": "8bd1ca0d-5839-4d26-d752-eda6b3448576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "Best parameters for Assistive Technology: {'subsample': 0.7, 'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.7}\n",
            "Best parameters for Customized Housing Design: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1.0}\n",
            "Test accuracy for Assistive Technology: 26.24%\n",
            "Test accuracy for Customized Housing Design: 20.59%\n",
            "Predicted Assistive Technology: Voice-activated devices (e120)\n",
            "Predicted Customized Housing Design: Smart Home Integration (e155)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wgv9ydcjASF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/DD.csv')\n",
        "\n",
        "# Drop unnecessary columns and separate the tasks\n",
        "X = df[['Specific Disease', 'Body Functions', 'Activities and Participation', 'Home Functions']]\n",
        "y_assistive = df['Assistive Technology']  # Separate the target for Assistive Technology\n",
        "y_housing = df['Customized Housing Design']  # Separate the target for Customized Housing Design\n",
        "\n",
        "# Apply one-hot encoding to categorical columns in X\n",
        "X = pd.get_dummies(X, columns=['Specific Disease', 'Body Functions', 'Activities and Participation', 'Home Functions'])\n",
        "\n",
        "# List the one-hot encoded columns for 'Specific Disease' and 'Body Functions'\n",
        "disease_columns = [col for col in X.columns if 'Specific Disease_' in col]\n",
        "body_func_columns = [col for col in X.columns if 'Body Functions_' in col]\n",
        "activity_columns = [col for col in X.columns if 'Activities and Participation_' in col]\n",
        "\n",
        "# Create interaction features using one-hot encoded columns\n",
        "for disease_col in disease_columns:\n",
        "    for body_col in body_func_columns:\n",
        "        X[f'{disease_col}_x_{body_col}'] = X[disease_col] * X[body_col]\n",
        "\n",
        "for body_col in body_func_columns:\n",
        "    for activity_col in activity_columns:\n",
        "        X[f'{body_col}_x_{activity_col}'] = X[body_col] * X[activity_col]\n",
        "\n",
        "# Convert all columns in X to float\n",
        "X = X.astype(float)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Encode the target variables (Assistive Technology and Customized Housing Design)\n",
        "le_assistive = LabelEncoder()\n",
        "y_assistive_encoded = le_assistive.fit_transform(y_assistive)\n",
        "\n",
        "le_housing = LabelEncoder()\n",
        "y_housing_encoded = le_housing.fit_transform(y_housing)\n",
        "\n",
        "# Handle imbalance using SMOTE for Assistive Technology\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled_assistive, y_resampled_assistive = smote.fit_resample(X_scaled, y_assistive_encoded)\n",
        "\n",
        "# Handle imbalance using SMOTE for Customized Housing Design\n",
        "X_resampled_housing, y_resampled_housing = smote.fit_resample(X_scaled, y_housing_encoded)\n",
        "\n",
        "# Split the dataset into training and testing sets for both tasks\n",
        "X_train_assistive, X_test_assistive, y_train_assistive, y_test_assistive = train_test_split(X_resampled_assistive, y_resampled_assistive, test_size=0.2, random_state=42)\n",
        "X_train_housing, X_test_housing, y_train_housing, y_test_housing = train_test_split(X_resampled_housing, y_resampled_housing, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize base models\n",
        "xgb_clf = XGBClassifier(random_state=42)\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Create a Stacking Classifier with XGBoost, Random Forest, and Logistic Regression\n",
        "stacking_clf_assistive = StackingClassifier(estimators=[\n",
        "    ('rf', rf_clf),\n",
        "    ('xgb', xgb_clf),\n",
        "    ('log_reg', log_reg)\n",
        "], final_estimator=LogisticRegression(max_iter=1000))\n",
        "\n",
        "# Use GridSearchCV to tune parameters for the Stacking model (Assistive Technology)\n",
        "param_grid_assistive = {\n",
        "    'xgb__n_estimators': [100, 200],\n",
        "    'xgb__max_depth': [5, 10],\n",
        "    'rf__n_estimators': [100, 200],\n",
        "    'final_estimator__C': [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "grid_search_assistive = GridSearchCV(estimator=stacking_clf_assistive, param_grid=param_grid_assistive, cv=3, verbose=2, n_jobs=-1)\n",
        "grid_search_assistive.fit(X_train_assistive, y_train_assistive)\n",
        "\n",
        "# Use GridSearchCV to tune parameters for the Stacking model (Customized Housing Design)\n",
        "stacking_clf_housing = StackingClassifier(estimators=[\n",
        "    ('rf', rf_clf),\n",
        "    ('xgb', xgb_clf),\n",
        "    ('log_reg', log_reg)\n",
        "], final_estimator=LogisticRegression(max_iter=1000))\n",
        "\n",
        "param_grid_housing = {\n",
        "    'xgb__n_estimators': [100, 200],\n",
        "    'xgb__max_depth': [5, 10],\n",
        "    'rf__n_estimators': [100, 200],\n",
        "    'final_estimator__C': [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "grid_search_housing = GridSearchCV(estimator=stacking_clf_housing, param_grid=param_grid_housing, cv=3, verbose=2, n_jobs=-1)\n",
        "grid_search_housing.fit(X_train_housing, y_train_housing)\n",
        "\n",
        "# Best parameters from the search\n",
        "print(f\"Best parameters for Assistive Technology: {grid_search_assistive.best_params_}\")\n",
        "print(f\"Best parameters for Customized Housing Design: {grid_search_housing.best_params_}\")\n",
        "\n",
        "# Use the best estimator for predictions\n",
        "best_stacking_assistive = grid_search_assistive.best_estimator_\n",
        "best_stacking_housing = grid_search_housing.best_estimator_\n",
        "\n",
        "# Make predictions on the test set using the best models\n",
        "y_pred_assistive = best_stacking_assistive.predict(X_test_assistive)\n",
        "y_pred_housing = best_stacking_housing.predict(X_test_housing)\n",
        "\n",
        "# Evaluate the model for Assistive Technology\n",
        "accuracy_assistive = accuracy_score(y_test_assistive, y_pred_assistive)\n",
        "print(f\"Test accuracy for Assistive Technology: {accuracy_assistive * 100:.2f}%\")\n",
        "\n",
        "# Evaluate the model for Customized Housing Design\n",
        "accuracy_housing = accuracy_score(y_test_housing, y_pred_housing)\n",
        "print(f\"Test accuracy for Customized Housing Design: {accuracy_housing * 100:.2f}%\")\n",
        "\n",
        "# Function to predict Assistive Technology and Housing Design separately\n",
        "def predict_assistive_and_design(specific_disease, body_functions, activities, home_functions):\n",
        "    input_data = pd.DataFrame({\n",
        "        'Specific Disease': [specific_disease],\n",
        "        'Body Functions': [body_functions],\n",
        "        'Activities and Participation': [activities],\n",
        "        'Home Functions': [home_functions]\n",
        "    })\n",
        "\n",
        "    # Apply one-hot encoding to the input data\n",
        "    input_data = pd.get_dummies(input_data)\n",
        "\n",
        "    # Create interaction features using one-hot encoded columns\n",
        "    for disease_col in disease_columns:\n",
        "        for body_col in body_func_columns:\n",
        "            input_data[f'{disease_col}_x_{body_col}'] = input_data.get(disease_col, 0) * input_data.get(body_col, 0)\n",
        "\n",
        "    for body_col in body_func_columns:\n",
        "        for activity_col in activity_columns:\n",
        "            input_data[f'{body_col}_x_{activity_col}'] = input_data.get(body_col, 0) * input_data.get(activity_col, 0)\n",
        "\n",
        "    # Align the columns with the training data to avoid dimension mismatches\n",
        "    input_data = input_data.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    # Scale the input data\n",
        "    input_data_scaled = scaler.transform(input_data)\n",
        "\n",
        "    # Predict Assistive Technology\n",
        "    prediction_assistive = best_stacking_assistive.predict(input_data_scaled)\n",
        "\n",
        "    # Predict Customized Housing Design\n",
        "    prediction_housing = best_stacking_housing.predict(input_data_scaled)\n",
        "\n",
        "    return le_assistive.inverse_transform([prediction_assistive[0]]), le_housing.inverse_transform([prediction_housing[0]])\n",
        "\n",
        "# Example prediction\n",
        "assistive_pred, housing_pred = predict_assistive_and_design('Parkinsons Disease', 'Hearing functions (b230)', 'Limited mobility (d455)', 'Old building (e150)')\n",
        "print(f\"Predicted Assistive Technology: {assistive_pred[0]}\")\n",
        "print(f\"Predicted Customized Housing Design: {housing_pred[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXXEXQvkAakm",
        "outputId": "120ac7dd-21df-4af8-dc92-b4d8ac5748ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Best parameters for Assistive Technology: {'final_estimator__C': 1, 'rf__n_estimators': 200, 'xgb__max_depth': 10, 'xgb__n_estimators': 100}\n",
            "Best parameters for Customized Housing Design: {'final_estimator__C': 1, 'rf__n_estimators': 200, 'xgb__max_depth': 10, 'xgb__n_estimators': 100}\n",
            "Test accuracy for Assistive Technology: 22.62%\n",
            "Test accuracy for Customized Housing Design: 17.65%\n",
            "Predicted Assistive Technology: Cognitive Assistance Device (e125)\n",
            "Predicted Customized Housing Design: Enhanced lighting (e155)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/DD.csv')\n",
        "\n",
        "# Drop unnecessary columns and separate the tasks\n",
        "X = df[['Specific Disease', 'Body Functions', 'Activities and Participation', 'Home Functions']]\n",
        "y_assistive = df['Assistive Technology']  # Separate the target for Assistive Technology\n",
        "y_housing = df['Customized Housing Design']  # Separate the target for Customized Housing Design\n",
        "\n",
        "# Apply one-hot encoding to categorical columns in X\n",
        "X = pd.get_dummies(X, columns=['Specific Disease', 'Body Functions', 'Activities and Participation', 'Home Functions'])\n",
        "\n",
        "# Convert all columns in X to float\n",
        "X = X.astype(float)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Encode the target variables (Assistive Technology and Customized Housing Design)\n",
        "le_assistive = LabelEncoder()\n",
        "y_assistive_encoded = le_assistive.fit_transform(y_assistive)\n",
        "\n",
        "le_housing = LabelEncoder()\n",
        "y_housing_encoded = le_housing.fit_transform(y_housing)\n",
        "\n",
        "# Handle imbalance using SMOTE for Assistive Technology\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled_assistive, y_resampled_assistive = smote.fit_resample(X_scaled, y_assistive_encoded)\n",
        "\n",
        "# Handle imbalance using SMOTE for Customized Housing Design\n",
        "X_resampled_housing, y_resampled_housing = smote.fit_resample(X_scaled, y_housing_encoded)\n",
        "\n",
        "# Split the dataset into training and testing sets for both tasks\n",
        "X_train_assistive, X_test_assistive, y_train_assistive, y_test_assistive = train_test_split(X_resampled_assistive, y_resampled_assistive, test_size=0.2, random_state=42)\n",
        "X_train_housing, X_test_housing, y_train_housing, y_test_housing = train_test_split(X_resampled_housing, y_resampled_housing, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize base models\n",
        "xgb_clf = XGBClassifier(random_state=42)\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Feature Selection using Recursive Feature Elimination (RFE) with RandomForest\n",
        "rfe = RFE(estimator=rf_clf, n_features_to_select=20)  # Select top 20 features\n",
        "X_train_assistive_rfe = rfe.fit_transform(X_train_assistive, y_train_assistive)\n",
        "X_test_assistive_rfe = rfe.transform(X_test_assistive)\n",
        "\n",
        "X_train_housing_rfe = rfe.fit_transform(X_train_housing, y_train_housing)\n",
        "X_test_housing_rfe = rfe.transform(X_test_housing)\n",
        "\n",
        "# Create a Voting Classifier for Assistive Technology with soft voting\n",
        "voting_clf_assistive = VotingClassifier(estimators=[\n",
        "    ('rf', rf_clf),\n",
        "    ('xgb', xgb_clf)\n",
        "], voting='soft')\n",
        "\n",
        "# Use GridSearchCV to tune parameters for the Voting model (Assistive Technology)\n",
        "param_grid_assistive = {\n",
        "    'xgb__n_estimators': [100, 200],\n",
        "    'xgb__max_depth': [5, 10],\n",
        "    'rf__n_estimators': [100, 200],\n",
        "    'rf__max_depth': [10, 20]\n",
        "}\n",
        "\n",
        "grid_search_assistive = GridSearchCV(estimator=voting_clf_assistive, param_grid=param_grid_assistive, cv=3, verbose=2, n_jobs=-1)\n",
        "grid_search_assistive.fit(X_train_assistive_rfe, y_train_assistive)\n",
        "\n",
        "# Create a Voting Classifier for Customized Housing Design with soft voting\n",
        "voting_clf_housing = VotingClassifier(estimators=[\n",
        "    ('rf', rf_clf),\n",
        "    ('xgb', xgb_clf)\n",
        "], voting='soft')\n",
        "\n",
        "# Use GridSearchCV to tune parameters for the Voting model (Customized Housing Design)\n",
        "param_grid_housing = {\n",
        "    'xgb__n_estimators': [100, 200],\n",
        "    'xgb__max_depth': [5, 10],\n",
        "    'rf__n_estimators': [100, 200],\n",
        "    'rf__max_depth': [10, 20]\n",
        "}\n",
        "\n",
        "grid_search_housing = GridSearchCV(estimator=voting_clf_housing, param_grid=param_grid_housing, cv=3, verbose=2, n_jobs=-1)\n",
        "grid_search_housing.fit(X_train_housing_rfe, y_train_housing)\n",
        "\n",
        "# Best parameters from the search\n",
        "print(f\"Best parameters for Assistive Technology: {grid_search_assistive.best_params_}\")\n",
        "print(f\"Best parameters for Customized Housing Design: {grid_search_housing.best_params_}\")\n",
        "\n",
        "# Use the best estimator for predictions\n",
        "best_voting_assistive = grid_search_assistive.best_estimator_\n",
        "best_voting_housing = grid_search_housing.best_estimator_\n",
        "\n",
        "# Make predictions on the test set using the best models\n",
        "y_pred_assistive = best_voting_assistive.predict(X_test_assistive_rfe)\n",
        "y_pred_housing = best_voting_housing.predict(X_test_housing_rfe)\n",
        "\n",
        "# Evaluate the model for Assistive Technology\n",
        "accuracy_assistive = accuracy_score(y_test_assistive, y_pred_assistive)\n",
        "print(f\"Test accuracy for Assistive Technology: {accuracy_assistive * 100:.2f}%\")\n",
        "\n",
        "# Evaluate the model for Customized Housing Design\n",
        "accuracy_housing = accuracy_score(y_test_housing, y_pred_housing)\n",
        "print(f\"Test accuracy for Customized Housing Design: {accuracy_housing * 100:.2f}%\")\n",
        "\n",
        "# Function to predict Assistive Technology and Housing Design separately\n",
        "def predict_assistive_and_design(specific_disease, body_functions, activities, home_functions):\n",
        "    input_data = pd.DataFrame({\n",
        "        'Specific Disease': [specific_disease],\n",
        "        'Body Functions': [body_functions],\n",
        "        'Activities and Participation': [activities],\n",
        "        'Home Functions': [home_functions]\n",
        "    })\n",
        "\n",
        "    # Apply one-hot encoding to the input data\n",
        "    input_data = pd.get_dummies(input_data)\n",
        "\n",
        "    # Align the columns with the training data to avoid dimension mismatches\n",
        "    input_data = input_data.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    # Scale the input data\n",
        "    input_data_scaled = scaler.transform(input_data)\n",
        "\n",
        "    # Select features using RFE\n",
        "    input_data_rfe = rfe.transform(input_data_scaled)\n",
        "\n",
        "    # Predict Assistive Technology\n",
        "    prediction_assistive = best_voting_assistive.predict(input_data_rfe)\n",
        "\n",
        "    # Predict Customized Housing Design\n",
        "    prediction_housing = best_voting_housing.predict(input_data_rfe)\n",
        "\n",
        "    return le_assistive.inverse_transform([prediction_assistive[0]]), le_housing.inverse_transform([prediction_housing[0]])\n",
        "\n",
        "# Example prediction\n",
        "assistive_pred, housing_pred = predict_assistive_and_design('Parkinsons Disease', 'Hearing functions (b230)', 'Limited mobility (d455)', 'Old building (e150)')\n",
        "print(f\"Predicted Assistive Technology: {assistive_pred[0]}\")\n",
        "print(f\"Predicted Customized Housing Design: {housing_pred[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlwpW9j5NxJS",
        "outputId": "d6049293-cbf0-4a2d-a01c-bfe9fff0e4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
            "Best parameters for Assistive Technology: {'rf__max_depth': 10, 'rf__n_estimators': 200, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
            "Best parameters for Customized Housing Design: {'rf__max_depth': 20, 'rf__n_estimators': 200, 'xgb__max_depth': 10, 'xgb__n_estimators': 100}\n",
            "Test accuracy for Assistive Technology: 25.79%\n",
            "Test accuracy for Customized Housing Design: 19.61%\n",
            "Predicted Assistive Technology: Voice-activated devices (e120)\n",
            "Predicted Customized Housing Design: Smart Home Integration (e155)\n"
          ]
        }
      ]
    }
  ]
}